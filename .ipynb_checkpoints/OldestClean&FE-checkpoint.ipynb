{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "import datetime\n",
    "gc.collect()\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:30<00:00,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2031893, 41)\n",
      "2031893 plays were loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load play by play & drive data\n",
    "years = list(range(2005, int(datetime.datetime.now().year)))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year in tqdm(years):\n",
    "    path = './output/'+str(year)+'/'+str(year)+'_pbp.csv'\n",
    "    sea_df = pd.read_csv(path)\n",
    "    \n",
    "    drive_path = './output/'+str(year)+'/'+str(year)+'_drives.csv'\n",
    "    drive_df = pd.read_csv(drive_path)\n",
    "    \n",
    "    drive_df = drive_df.rename(columns={'id':'drive_id'})\n",
    "    \n",
    "    sea_df = pd.merge(left=sea_df, right=drive_df, how='left', on=['drive_id','drive_id'])\n",
    "    df = pd.concat([df,sea_df])\n",
    "\n",
    "num_plays = len(df)\n",
    "print(df.shape)\n",
    "print(str(num_plays) + \" plays were loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix clock data first so drives can be figured out\n",
    "time_cols = ['clock.minutes','clock.seconds','start_time.minutes','start_time.seconds',\n",
    "            'end_time.minutes','end_time.seconds']\n",
    "for tc in time_cols:\n",
    "    df[tc] = df[tc].fillna(0)\n",
    "\n",
    "# get time remaining in game\n",
    "df['tr_game'] = (4-df['period']) * 900 + (df['clock.minutes'] * 60) + df['clock.seconds']\n",
    "df['tr_half'] = np.where(df['period']>2,df['tr_game'], df['tr_game']-1800)\n",
    "\n",
    "df = df.drop(columns=['clock.minutes','clock.seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "51929                     End of half, clock 00:00.\n",
      "65245                     End of half, clock 00:00.\n",
      "86881                     End of half, clock 00:00.\n",
      "95268                     End of half, clock 00:00.\n",
      "106328                    End of half, clock 15:00.\n",
      "14553                     End of half, clock 00:00.\n",
      "14768     BOWLING GREEN drive start at 15:00 (OT ).\n",
      "18425            PURDUE drive start at 15:00 (OT ).\n",
      "22311                                  Clock 15:00.\n",
      "28877                     End of half, clock 00:00.\n",
      "Name: play_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# fix uncategorized\n",
    "uncat = df.loc[df['play_type']=='Uncategorized']\n",
    "print(len(uncat))\n",
    "print(uncat.play_text.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Punt' 'Rush' 'Pass' 'Penalty' 'Kickoff' 'Extra Point Good' 'Timeout'\n",
      " 'Field Goal Good' 'Field Goal Missed' 'Extra Point Missed' 'End Period'\n",
      " 'Safety' 'Uncategorized' 'Pass Incompletion' 'Pass Completion'\n",
      " 'Pass Interception' 'Sack' 'Fumble Return Touchdown'\n",
      " 'Punt Return Touchdown' '2pt Conversion' 'Offensive 1pt Safety'\n",
      " 'Kickoff Return (Offense)' 'Pass Reception' 'Fumble Recovery (Opponent)'\n",
      " 'Fumble Recovery (Own)' 'Passing Touchdown' 'Rushing Touchdown'\n",
      " 'Pass Interception Return' 'Interception Return Touchdown' 'End of Half'\n",
      " 'Blocked Field Goal' 'Blocked Punt' 'End of Game'\n",
      " 'Kickoff Return Touchdown' 'Blocked Field Goal Touchdown'\n",
      " 'Defensive 2pt Conversion' 'Blocked Punt Touchdown'\n",
      " 'Missed Field Goal Return' 'Interception'\n",
      " 'Missed Field Goal Return Touchdown']\n"
     ]
    }
   ],
   "source": [
    "print(df.play_type.unique())\n",
    "def fix_uncat(play_type, play_text):\n",
    "    if play_type != 'Uncategorized':\n",
    "        return play_type\n",
    "    else:\n",
    "        if isinstance(play_text,str):\n",
    "            if \"Start of the 2nd quarter.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"Start of the 3rd quarter.\" in play_text:\n",
    "                return \"End of Half\"\n",
    "            elif \"Start of the 4th quarter.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"Start of overtime.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"End of the game.\" in play_text:\n",
    "                return \"End of Game\"\n",
    "            elif \"Extra point\" in play_text:\n",
    "                if \"is good\" in play_text:\n",
    "                    return \"Extra Point Good\"\n",
    "                elif \"is no good.\" in play_text[-13:]:\n",
    "                    return \"Extra Point Missed\"\n",
    "                else:\n",
    "                    return play_type\n",
    "            elif \"field goal\" in play_text:\n",
    "                if \"is good\" in play_text:\n",
    "                    return \"Field Goal Good\"\n",
    "                elif \"is no good.\" in play_text[-13:]:\n",
    "                    return \"Field Goal Missed\"\n",
    "                else:\n",
    "                    print(play_text)\n",
    "                    return play_type\n",
    "            elif \"missed PAT returned.\" in play_text:\n",
    "                return \"Extra Point Missed\"\n",
    "            elif \"took lateral and rushed\" in play_text:\n",
    "                return \"Rush\"\n",
    "            # mostly fumbled snaps recovered by own team\n",
    "            elif \"fumbled\" in play_text:\n",
    "                return \"Fumble Recovery (Own)\"\n",
    "            elif \"return for\" in play_text:\n",
    "                return \"Punt Return\"\n",
    "            elif \"End of\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"run for\" in play_text:\n",
    "                return \"Rush\"\n",
    "            elif \"SAFETY\" in play_text:\n",
    "                return \"Safety\"\n",
    "            elif \"Penalty\" in play_text:\n",
    "                return \"Penalty\"\n",
    "            else:\n",
    "                return play_type\n",
    "    return play_type\n",
    "\n",
    "df['play_type'] = df.apply(lambda row: fix_uncat(row['play_type'], row['play_text']),axis=1)\n",
    "\n",
    "# uncat = df.loc[df.play_type=='Uncategorized']\n",
    "# print(len(uncat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate extra point attempts\n",
    "xp_cats = ['Two Point Pass','Two Point Rush','Blocked PAT','Extra Point Good','Extra Point Missed', '2pt Conversion',\n",
    "          'Offensive 1pt Safety','Defensive 2pt Conversion']\n",
    "xps = df.loc[df['play_type'].isin(xp_cats)]\n",
    "df = df.loc[~df['play_type'].isin(xp_cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate kickoffs\n",
    "kickoffs_cats = ['Kickoff Return (Offense)', 'Kickoff Return Touchdown', 'Kickoff Return (Defense)', 'Kickoff']\n",
    "kickoff_penalty_plays = ['KICKOFF', 'KICKOFF RETURN TD']\n",
    "kickoffs = df.loc[(df['play_type'].isin(kickoffs_cats)) | (df['drive_result']).isin(kickoff_penalty_plays)]\n",
    "df = df.loc[~df['play_type'].isin(kickoffs_cats)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate OT\n",
    "ot = df.loc[(df['period'] > 4) | (df['drive_result'] == 'POSSESSION (FOR OT DRIVES)')]\n",
    "df = df.loc[(df['period'] <= 4) & (df['period'] >0)]\n",
    "df = df.loc[df.drive_result != 'POSSESSION (FOR OT DRIVES)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop end of period plays\n",
    "\n",
    "eop = ['End of Game','End of Half','End Period']\n",
    "df = df.loc[~df['play_type'].isin(eop)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate\n",
    "# bad = df.loc[df['offense_x']!=df['offense_y']]\n",
    "# print(bad[['tr_game','play_text','offense_x','offense_y']].head(25))\n",
    "# offense_x seems to be correct while offense_y is not\n",
    "\n",
    "df = df.drop(columns=['defense_y','defense_conference_y','offense_y','offense_conference_y'])\n",
    "\n",
    "df = df.rename(columns={'defense_x':'defense','defense_conference_x':'defense_conference','offense_x':'offense','offense_conference_x':'offense_conference'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix bad distances\n",
    "\n",
    "zeros = df.loc[df['distance'] == 0]\n",
    "# print(len(zeros))\n",
    "# print(zeros.groupby(['play_type'])['distance'].count())\n",
    "# print(zeros.play_text.tail(50))\n",
    "\n",
    "# drop negative distances. change 0 distances to 0.5 yard\n",
    "df = df.loc[df['distance']>=0]\n",
    "\n",
    "df = df.rename(columns={'distance':'wrong_distance'})\n",
    "df['distance'] = np.where(df['wrong_distance']>0,df['wrong_distance'],0.5)\n",
    "df = df.drop(columns=['wrong_distance'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# fix bad downs\n",
    "zero_down = df.loc[df['down']==0]\n",
    "print(len(zero_down))\n",
    "\n",
    "# impute down + 1 from previous play, to max of 4\n",
    "df['down'] = np.where(df['down']>0,df['down'],df['down'].shift()+1)\n",
    "# still 18 bad\n",
    "\n",
    "df = df.loc[(df['down']>0)&(df['down']<5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clock\n",
    "Also, sometimes clock data is wrong. I messed with trying to predict time per play based on play type, but the data was prohibitively messy. Instead I'll just assume every play takes up the same percentage of drive time. The worst effect this will have is it will make incompletions look worse in late game situations, because incompletions will have the same time elapsed as completion. I guess this matters less in college football, because the clock stops on a first down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['away', 'defense', 'defense_conference', 'defense_score', 'down', 'drive_id', 'home', 'id', 'offense', 'offense_conference', 'offense_score', 'period', 'play_text', 'play_type', 'yard_line', 'yards_gained', 'season', 'week', 'season_type', 'drive_result', 'elapsed.minutes', 'elapsed.seconds', 'end_period', 'end_time.minutes', 'end_time.seconds', 'end_yardline', 'game_id', 'plays', 'scoring', 'start_period', 'start_time.minutes', 'start_time.seconds', 'start_yardline', 'yards', 'tr_game', 'tr_half', 'distance', 'drive_time']\n"
     ]
    }
   ],
   "source": [
    "# fix negative drive times first, they mostly contain actual plays\n",
    "df['elapsed.minutes'] = df['elapsed.minutes'].copy().fillna(0)\n",
    "df['elapsed.seconds'] = df['elapsed.seconds'].copy().fillna(0)\n",
    "df['drive_time'] = 60*df['elapsed.minutes'] + df['elapsed.seconds']\n",
    "cols = list(df)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can't find systematic error, just going to reverse start and end time. the reversed data\n",
    "# seems to make sense\n",
    "\n",
    "\n",
    "negs = df.loc[df.drive_time < 0].copy()\n",
    "negs = negs[cols]\n",
    "neg_ids = list(negs.drive_id.unique())\n",
    "df = df.loc[~df.drive_id.isin(neg_ids)]\n",
    "\n",
    "negs = negs.rename(columns={'elapsed.minutes':'wrong_em','elapsed.seconds':'wrong_es',\n",
    "                            'start_time.minutes':'wrong_sm','start_time.seconds':'wrong_ss',\n",
    "                            'end_time.minutes':'wrong_etm','end_time.seconds':'wrong_ets',\n",
    "                            'drive_time':'wrong_dt'\n",
    "                           })\n",
    "\n",
    "negs['start_time.minutes'] = negs['wrong_etm'].copy()\n",
    "negs['start_time.seconds'] = negs['wrong_ets'].copy()\n",
    "\n",
    "negs['end_time.minutes'] = negs['wrong_sm'].copy()\n",
    "negs['end_time.seconds'] = negs['wrong_ss'].copy()\n",
    "\n",
    "negs['elapsed.minutes'] = negs['wrong_em'].copy().abs()\n",
    "negs['elapsed.seconds'] = negs['wrong_es'].copy().abs()\n",
    "negs['drive_time'] = negs['wrong_dt'].copy().abs()\n",
    "\n",
    "drop_cols = ['wrong_em','wrong_es','wrong_sm','wrong_ss','wrong_etm','wrong_ets','wrong_dt']\n",
    "negs = negs.drop(columns=drop_cols)\n",
    "\n",
    "negs = negs[cols]\n",
    "df = pd.concat([df,negs],sort=False)\n",
    "df = df.sort_values(by=['game_id','tr_game','drive_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now work on fixing nan drive timea\n",
    "df['drive_time'] = 60*df['elapsed.minutes'] + df['elapsed.seconds']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = df.loc[df.drive_time == 0]\n",
    "zgb = zeros.groupby(['plays'])['start_time.minutes'].count()\n",
    "\n",
    "# zero play drives are fumble recoveries by the other team or punt returns\n",
    "# fumble recoveries are on the first play of the drive and are actually correct\n",
    "# need to fix punt returns\n",
    "\n",
    "# print(zplay.drive_id.head())\n",
    "\n",
    "zpunts = zeros.loc[(zeros.plays==0)&(zeros.play_type=='Punt Return')]\n",
    "\n",
    "\n",
    "\n",
    "zp_dids = list(zpunts.drive_id.unique())\n",
    "zp_mo = [(x-1) for x in zp_dids]\n",
    "\n",
    "if len(zp_dids) > 0:\n",
    "    df['did-1'] = df['drive_id'] - 1\n",
    "    df['drive_id'] = np.where(df['drive_id'].isin(zp_dids),df['did-1'], df['drive_id'])\n",
    "    df.loc[df.drive_id.isin(zp_mo), 'drive_result'] = 'PUNT'\n",
    "    df.loc[df.drive_id.isin(zp_mo), 'drive_time'] = 150\n",
    "    \n",
    "    \n",
    "    \n",
    "# do the same for drive result == 'punt return td td'\n",
    "prtt = df.loc[df.drive_result=='PUNT RETURN TD TD']\n",
    "prtt_dids = list(prtt.drive_id.unique())\n",
    "prtt_mo = [(x-1) for x in prtt_dids]\n",
    "\n",
    "if len(prtt_dids) > 0:\n",
    "    df['drive_id'] = np.where(df['drive_id'].isin(prtt_dids),df['did-1'], df['drive_id'])\n",
    "    df.loc[df.drive_id.isin(prtt_mo), 'drive_result'] = 'PUNT RETURN TD'\n",
    "    df = df.drop(columns=['did-1'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to fix drive times of zero seconds with more than zero plays. My idea was get the time remaining of the next drive, and subtract that from the time remaining of the current drive. Unfortunately that only worked for about half the drives. And, most of the drives it did work on, only resulted in drive times of under a minute. That seemed off and I didn't see an obvious reason why. I decided just to drop these drives. That's about 3% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1846914\n",
      "1799493\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df.loc[df['drive_time']>0]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Bad Drive Results, Standardize Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix drive result kickoffs\n",
    "kos = df.loc[(df['drive_result']=='KICKOFF')]\n",
    "dids = list(kos.drive_id.unique())\n",
    "\n",
    "fgs = df.loc[(df['drive_id'].isin(dids))&df['play_text'].str.contains('Field Goal')]\n",
    "fg_ids = list(fgs.drive_id.unique())\n",
    "\n",
    "df.loc[df.drive_id.isin(fg_ids), 'drive_result'] = 'FG GOOD'\n",
    "\n",
    "\n",
    "punts = [4005483434]\n",
    "end_of_half = [40054770815]\n",
    "\n",
    "df.loc[df.drive_id.isin(punts), 'drive_result'] = 'PUNT'\n",
    "df.loc[df.drive_id.isin(end_of_half), 'drive_result'] = 'END OF HALF'\n",
    "\n",
    "# special cases\n",
    "\n",
    "df.loc[df.drive_id == 24269009911, 'drive_result'] = 'RUSHING TD'\n",
    "df.loc[df.drive_id == 24269009911, 'drive_id'] = 24269009912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix Fg missed TDs\n",
    "brt = df.loc[(df['drive_result']=='FG MISSED TD')&df['play_text'].str.contains('BLOCKED')]\n",
    "brt_ids = list(brt.drive_id.unique())\n",
    "\n",
    "df.loc[df['drive_id'].isin(brt_ids), 'drive_result'] = 'BLOCKED FG (TD) TD'\n",
    "\n",
    "brt = df.loc[(df['drive_result']=='FG MISSED TD')&df['play_text'].str.contains('blocked')]\n",
    "brt_ids = list(brt.drive_id.unique())\n",
    "\n",
    "df.loc[df['drive_id'].isin(brt_ids), 'drive_result'] = 'BLOCKED FG (TD) TD'\n",
    "\n",
    "brt = df.loc[(df['drive_result']=='FG MISSED TD')&df['play_text'].str.contains('blocked,')]\n",
    "brt_ids = list(brt.drive_id.unique())\n",
    "\n",
    "df.loc[df['drive_id'].isin(brt_ids), 'drive_result'] = 'BLOCKED FG (TD) TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 'FG' and 'FG GOOD'\n",
    "df.loc[df['drive_result']=='FG', 'drive_result'] = 'FG GOOD' \n",
    "df.loc[df['drive_result']=='MADE FG', 'drive_result'] = 'FG GOOD' \n",
    "\n",
    "df.loc[df['drive_result']=='MISSED FG', 'drive_result'] = 'FG MISSED' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix 'end of half TD'\n",
    "end_of_half = [29290230615,29304013515,32259006215,32308025415,32315015219,33250230613,33285263815,33327000821,40060388027]\n",
    "fumble_tds = [30279211614]\n",
    "int_tds = [30282006815,40079088219]\n",
    "rush_tds = [30247263316,30268006217,32243211716,32301000917,40054794315]\n",
    "pass_tds = [30324002112,32329023512]\n",
    "block_fg_td = [40054834612]\n",
    "\n",
    "df.loc[df['drive_id'].isin(end_of_half), 'drive_result'] = 'END OF HALF'\n",
    "df.loc[df['drive_id'].isin(fumble_tds), 'drive_result'] = 'FUMBLE RETURN TD'\n",
    "df.loc[df['drive_id'].isin(int_tds), 'drive_result'] = 'INT TD'\n",
    "df.loc[df['drive_id'].isin(rush_tds), 'drive_result'] = 'RUSHING TD'\n",
    "df.loc[df['drive_id'].isin(pass_tds), 'drive_result'] = 'PASSING TD'\n",
    "df.loc[df['drive_id'].isin(block_fg_td), 'drive_result'] = 'BLOCKED FG (TD) TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix \"end of game TD\"\n",
    "int_tds = [30324020406,40087609227]\n",
    "fumble_tds = [40076354226,40086912120]\n",
    "end_of_game = [40078746229,40094526122]\n",
    "\n",
    "df.loc[df['drive_id'].isin(int_tds), 'drive_result'] = 'INT TD'\n",
    "df.loc[df['drive_id'].isin(fumble_tds), 'drive_result'] = 'FUMBLE RETURN TD'\n",
    "df.loc[df['drive_id'].isin(end_of_game), 'drive_result'] = 'END OF GAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix \"downs TD\"\n",
    "passing_tds = [40054825721,4007635338,40076343011,40086953320,4010133465,4010128564]\n",
    "rushing_tds = [40054786022,40060392118,40086953316]\n",
    "interception_tds = [4005482704,40075690213,40076355220,4008696135,40086963817]\n",
    "\n",
    "df.loc[df['drive_id'].isin(passing_tds), 'drive_result'] = 'PASSING TD'\n",
    "df.loc[df['drive_id'].isin(rushing_tds), 'drive_result'] = 'RUSHING TD'\n",
    "df.loc[df['drive_id'].isin(interception_tds), 'drive_result'] = 'INT TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix 'FG TD' drive result\n",
    "df.loc[((df.drive_id == 40054786811)&(df.offense=='Baylor')), 'drive_result'] = 'FG GOOD'\n",
    "df.loc[((df.drive_id == 40054786811)&(df.offense=='Baylor')), 'drive_id'] = 4005478681100\n",
    "\n",
    "df.loc[(df.drive_id == 40054786811), 'drive_result'] = 'RUSHING TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix \"end of 4th\"\n",
    "df.loc[df['drive_result']=='END OF 4TH QUARTER', 'drive_result'] = 'END OF GAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more blocked field goals\n",
    "bfg_ids = [242550275,242760259,243250150,243250344]\n",
    "bfg_dids = [24255027512,24276025916,24325015008,24325034420]\n",
    "to_fix = [(x-1) for x in bfg_dids]\n",
    "\n",
    "df.loc[df['drive_id'].isin(to_fix), 'drive_result'] = 'BLOCKED FG (TD) TD' \n",
    "df['did-1'] = df['drive_id'] - 1\n",
    "df['drive_id'] = np.where(df['drive_id'].isin(bfg_dids),df['did-1'], df['drive_id'])\n",
    "df = df.drop(columns=['did-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocked punts\n",
    "bps = list(df.loc[df['drive_result']=='BLOCKED PUNT TD'].drive_id.unique())\n",
    "to_fix = [(x-1) for x in bps]\n",
    "\n",
    "df.loc[df['drive_id'].isin(to_fix), 'drive_result'] = 'BLOCKED PUNT TD' \n",
    "df['did-1'] = df['drive_id'] - 1\n",
    "df['drive_id'] = np.where(df['drive_id'].isin(bps),df['did-1'], df['drive_id'])\n",
    "df = df.drop(columns=['did-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the drive data in these games seems very off\n",
    "bad_ids = [252602572,272560120,272562005]\n",
    "df = df.loc[~df.game_id.isin(bad_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix 'FG GOOD TD'\n",
    "# for text in list(cat.tr_game.values):\n",
    "#     print(text)\n",
    "fgs = [30282005814]\n",
    "rush_tds = [32252239316, 32266019408]\n",
    "\n",
    "df.loc[df.drive_id==30282005814, 'drive_result'] = 'FG GOOD'\n",
    "\n",
    "df.loc[df.drive_id.isin(rush_tds), 'drive_result'] = 'RUSHING TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drives labelled \"FG MISSED TD\" are actually made field goals, ensuing kickoff returned for TD\n",
    "\n",
    "df.loc[df.drive_result=='FG MISSED TD', 'drive_result'] = 'FG GOOD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for incompletes, if there is barely any time left, drive result = end of half or end of game. \n",
    "# otherwise turnover on downs\n",
    "\n",
    "incomp = df.loc[df.drive_result == 'INCOMPLETE']\n",
    "\n",
    "icb = incomp.groupby(['drive_id'])['tr_game'].min().reset_index()\n",
    "\n",
    "eofg = icb.loc[icb.tr_game < 30]\n",
    "eofg_ids = list(eofg.drive_id.values)\n",
    "\n",
    "incomp = incomp.loc[~incomp.drive_id.isin(eofg_ids)]\n",
    "\n",
    "icb = incomp.groupby(['drive_id'])['tr_half'].min().reset_index()\n",
    "eofh = icb.loc[icb.tr_half < 30]\n",
    "eofh_ids = list(eofh.drive_id.values)\n",
    "\n",
    "incomp = incomp.loc[~incomp.drive_id.isin(eofh_ids)]\n",
    "\n",
    "down_ids = list(incomp.drive_id.values)\n",
    "\n",
    "df.loc[df.drive_id.isin(eofg_ids), 'drive_result'] = 'END OF GAME'\n",
    "df.loc[df.drive_id.isin(eofh_ids), 'drive_result'] = 'END OF HALF'\n",
    "df.loc[df.drive_id.isin(down_ids), 'drive_result'] = 'TURNOVER ON DOWNS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same with completes\n",
    "\n",
    "comp = df.loc[df.drive_result == 'PASS COMPLETE']\n",
    "\n",
    "ccb = comp.groupby(['drive_id'])['tr_game'].min().reset_index()\n",
    "\n",
    "eofg = ccb.loc[ccb.tr_game < 30]\n",
    "eofg_ids = list(eofg.drive_id.values)\n",
    "\n",
    "comp = comp.loc[~comp.drive_id.isin(eofg_ids)]\n",
    "\n",
    "ccb = comp.groupby(['drive_id'])['tr_half'].min().reset_index()\n",
    "eofh = ccb.loc[ccb.tr_half < 30]\n",
    "eofh_ids = list(eofh.drive_id.values)\n",
    "\n",
    "comp = comp.loc[~comp.drive_id.isin(eofh_ids)]\n",
    "\n",
    "down_ids = list(comp.drive_id.values)\n",
    "\n",
    "df.loc[df.drive_id.isin(eofg_ids), 'drive_result'] = 'END OF GAME'\n",
    "df.loc[df.drive_id.isin(eofh_ids), 'drive_result'] = 'END OF HALF'\n",
    "df.loc[df.drive_id.isin(down_ids), 'drive_result'] = 'TURNOVER ON DOWNS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same with penalties\n",
    "\n",
    "pens = df.loc[df.drive_result == 'PENALTY']\n",
    "\n",
    "pcb = pens.groupby(['drive_id'])['tr_game'].min().reset_index()\n",
    "\n",
    "eofg = pcb.loc[pcb.tr_game < 30]\n",
    "eofg_ids = list(eofg.drive_id.values)\n",
    "\n",
    "pens = pens.loc[~pens.drive_id.isin(eofg_ids)]\n",
    "\n",
    "pcb = pens.groupby(['drive_id'])['tr_half'].min().reset_index()\n",
    "eofh = pcb.loc[pcb.tr_half < 30]\n",
    "eofh_ids = list(eofh.drive_id.values)\n",
    "\n",
    "pens = pens.loc[~pens.drive_id.isin(eofh_ids)]\n",
    "\n",
    "down_ids = list(pens.drive_id.values)\n",
    "\n",
    "df.loc[df.drive_id.isin(eofg_ids), 'drive_result'] = 'END OF GAME'\n",
    "df.loc[df.drive_id.isin(eofh_ids), 'drive_result'] = 'END OF HALF'\n",
    "df.loc[df.drive_id.isin(down_ids), 'drive_result'] = 'TURNOVER ON DOWNS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for drive result == kickoffs, if there is barely any time remain in half, end of half\n",
    "# otherwise, i think they are just random plays out of other drives. dropping them\n",
    "\n",
    "kos = df.loc[df.drive_result == 'KICKOFF']\n",
    "\n",
    "kgb = kos.groupby(['drive_id'])['tr_half'].min().reset_index()\n",
    "\n",
    "eofh = kgb.loc[kgb.tr_half <= 60]\n",
    "eofh_ids = list(eofh.drive_id.values)\n",
    "\n",
    "kos = kos.loc[~kos.drive_id.isin(eofh_ids)]\n",
    "drops = list(kos.drive_id.values)\n",
    "\n",
    "df.loc[df.drive_id.isin(eofh_ids), 'drive_result'] = 'END OF HALF'\n",
    "\n",
    "df = df.loc[~df.drive_id.isin(drops)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop these, they're kickoff penalties\n",
    "df = df.loc[df.drive_result != 'KICKOFF RETURN TD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rushing TD TD often is two drives with same ids\n",
    "\n",
    "df.loc[((df.drive_id == 24318000805)&(df.offense=='Ole Miss')), 'drive_id'] = 2431800080500\n",
    "\n",
    "df.loc[((df.drive_id == 24339003820)&(df.offense=='Colorado')), 'drive_id'] = 2433900382000\n",
    "\n",
    "df.loc[((df.drive_id == 24276002413)&(df.offense=='Stanford')), 'drive_id'] = 2427600241300\n",
    "\n",
    "df.loc[df.drive_id==2431800080500, 'drive_time'] = 150\n",
    "df.loc[df.drive_id==2431800080500, 'drive_result'] = 'TURNOVER ON DOWNS'\n",
    "\n",
    "df.loc[df.drive_id==2433900382000, 'drive_time'] = 100\n",
    "df.loc[df.drive_id==2433900382000, 'drive_result'] = 'TURNOVER ON DOWNS'\n",
    "\n",
    "df.loc[df.drive_id==2427600241300, 'drive_time'] = 100\n",
    "df.loc[df.drive_id==2427600241300, 'drive_result'] = 'TURNOVER ON DOWNS'\n",
    "\n",
    "df.loc[df.drive_result == 'RUSHING TD TD', 'drive_result'] = 'RUSHING TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same with PASSING TD TD (two drives with same ids)\n",
    "\n",
    "df.loc[((df.drive_id == 24248001223)&(df.offense=='Northern Arizona')), 'drive_id'] = 2424800122300\n",
    "df.loc[df.drive_id==2424800122300, 'drive_time'] = 100\n",
    "df.loc[df.drive_id==2424800122300, 'drive_result'] = 'TURNOVER ON DOWNS'\n",
    "df.loc[((df.drive_id == 24248001223)&(df.offense=='Arizona')), 'drive_result'] = 'PASSING TD'\n",
    "\n",
    "df.loc[((df.drive_id == 24255025914)&(df.offense=='Western Michigan')), 'drive_id'] = 24255025913\n",
    "df.loc[df.drive_id==24255025913, 'drive_result'] = 'FG MISSED'\n",
    "df.loc[((df.drive_id == 24255025914)&(df.offense=='Virginia Tech')), 'drive_result'] = 'PASSING TD'\n",
    "\n",
    "df.loc[((df.drive_id == 24262006614)&(df.offense=='Northern Illinois')), 'drive_id'] = 24262006616\n",
    "df.loc[((df.drive_id == 24262006616)), 'drive_result'] = 'PASSING TD'\n",
    "df.loc[((df.drive_id == 24262006614)&(df.offense=='Iowa State')), 'drive_result'] = 'PASSING TD'\n",
    "\n",
    "df.loc[((df.drive_id == 24283003001)&(df.offense=='California')), 'drive_id'] = 2428300300100\n",
    "df.loc[((df.drive_id == 2428300300100)), 'drive_result'] = 'TURNOVER ON DOWNS'\n",
    "df.loc[((df.drive_id == 24283003001)&(df.offense=='USC')), 'drive_result'] = 'PASSING TD'\n",
    "\n",
    "df.loc[((df.drive_id == 24283007707)&(df.offense=='Northwestern')), 'drive_id'] = 2428300770700\n",
    "df.loc[(df.drive_id == 2428300770700), 'drive_result'] = 'FG MISSED'\n",
    "df.loc[((df.drive_id == 24283007707)&(df.offense=='Indiana')), 'drive_result'] = 'PASSING TD'\n",
    "\n",
    "df.loc[((df.drive_id == 24295027705)&(df.offense=='Syracuse')), 'drive_id'] = 24295027704\n",
    "df.loc[df.drive_id == 24295027704, 'drive_result'] = 'FG MISSED'\n",
    "df.loc[df.drive_id == 24295027705, 'drive_result'] = 'PASSING TD'\n",
    "\n",
    "df.loc[((df.drive_id == 24304015435)&(df.offense=='Wake Forest')), 'drive_id'] = 24304015434\n",
    "df.loc[df.drive_id == 24304015434, 'drive_result'] = 'FG MISSED'\n",
    "df.loc[df.drive_id == 24304015435, 'drive_result'] = 'PASSING TD'\n",
    "\n",
    "df.loc[((df.drive_id == 24311023826)&(df.offense=='Vanderbilt')), 'drive_id'] = 24311023825\n",
    "df.loc[df.drive_id == 24311023825, 'drive_result'] = 'FG MISSED'\n",
    "df.loc[df.drive_id == 24311023826, 'drive_result'] = 'PASSING TD'\n",
    "\n",
    "df.loc[((df.drive_id == 24304257915)&(df.offense=='South Carolina')), 'drive_id'] = 2430425791500\n",
    "df.loc[df.drive_id == 2430425791500, 'drive_result'] = 'FG MISSED'\n",
    "df.loc[df.drive_id == 24304257915, 'drive_result'] = 'PASSING TD'\n",
    "\n",
    "df.loc[((df.drive_id == 24325025430)&(df.offense=='BYU')), 'drive_id'] = 2432502543000\n",
    "df.loc[df.drive_id == 2432502543000, 'drive_result'] = 'FG MISSED'\n",
    "df.loc[df.drive_id == 24325025430, 'drive_result'] = 'PASSING TD'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.drive_id==29311022818,'drive_result'] = 'RUSHING TD'\n",
    "df.loc[df.drive_id==30338222604,'drive_result'] = 'RUSHING TD'\n",
    "df.loc[df.drive_id==32252230601,'drive_result'] = 'RUSHING TD'\n",
    "df.loc[df.drive_id==32301000216,'drive_result'] = 'RUSHING TD'\n",
    "df.loc[df.drive_id==31001020115,'drive_result'] = 'INT TD'\n",
    "df.loc[df.drive_id==31281025112,'drive_result'] = 'INT TD'\n",
    "\n",
    "df.loc[df.drive_id==30254002525,'drive_id'] = 3025400252500\n",
    "df.loc[df.drive_id==3025400252500, 'drive_result'] = 'FUMBLE TD'\n",
    "df.loc[df.drive_id==30254002525,'drive_result'] = 'RUSHING TD'\n",
    "\n",
    "df.loc[((df.drive_id==30282027706)&(df.offense=='West Virginia')),'drive_result'] = 'RUSHING TD'\n",
    "df.loc[((df.drive_id==30282027706)&(df.offense=='UNLV')),'drive_id'] = 3028202770600\n",
    "df.loc[df.drive_id==3028202770600,'drive_result'] = 'INT'\n",
    "\n",
    "df.loc[((df.drive_id==31260015815)&(df.offense=='Nebraska')),'drive_result'] = 'RUSHING TD'\n",
    "df.loc[((df.drive_id==31260015815)&(df.offense=='Washington')),'drive_id'] = 3126001581500\n",
    "df.loc[df.drive_id==3126001581500,'drive_result'] = 'PUNT'\n",
    "\n",
    "df.loc[((df.drive_id==32294006809)&(df.offense=='Boise State')),'drive_result'] = 'RUSHING TD'\n",
    "df.loc[((df.drive_id==32294006809)&(df.offense=='UNLV')),'drive_id'] = 3229400680900\n",
    "df.loc[df.drive_id==3229400680900,'drive_result'] = 'INT'\n",
    "\n",
    "df.loc[((df.drive_id==32307002518)&(df.offense=='Washington')),'drive_result'] = 'PASSING TD'\n",
    "df.loc[((df.drive_id==32307002518)&(df.offense=='California')),'drive_id'] = 3230700251800\n",
    "df.loc[df.drive_id==3230700251800,'drive_result'] = 'FG GOOD'\n",
    "\n",
    "df.loc[((df.drive_id==33242224720)&(df.offense=='Samford')),'drive_result'] = 'RUSHING TD'\n",
    "df.loc[((df.drive_id==33242224720)&(df.offense=='Georgia State')),'drive_id'] = 3324222472000\n",
    "df.loc[df.drive_id==3324222472000,'drive_result'] = 'PUNT'\n",
    "\n",
    "df.loc[((df.drive_id==33311002415)&(df.offense=='Oregon')),'drive_result'] = 'PASSING TD'\n",
    "df.loc[((df.drive_id==33311002415)&(df.offense=='Stanford')),'drive_id'] = 3331100241500\n",
    "df.loc[df.drive_id==3331100241500,'drive_result'] = 'MISSED FG TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# none of these returned for a TD, i checked\n",
    "ints = df.loc[(df.drive_result=='Uncategorized')&(df.play_text.str.contains('intercepted'))]\n",
    "int_ids = list(ints.drive_id.unique())\n",
    "\n",
    "df.loc[df.drive_id.isin(int_ids), 'drive_result'] = 'INT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeties = df.loc[(df.drive_result=='Uncategorized')&(df.play_text.str.contains('SAFETY'))]\n",
    "sf_ids = list(safeties.drive_id.unique())\n",
    "\n",
    "df.loc[df.drive_id.isin(sf_ids), 'drive_result'] = 'SF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked for touchdowns, again only punts\n",
    "punts = df.loc[(df.drive_result=='Uncategorized')&(df.play_text.str.contains('punt'))]\n",
    "punt_ids = list(punts.drive_id.unique())\n",
    "\n",
    "df.loc[df.drive_id.isin(punt_ids), 'drive_result'] = 'PUNT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix uncategorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = r'^{}'\n",
    "expr = '(?=.*{})'\n",
    "words = ['field', 'goal', 'GOOD']\n",
    "fg_good = base.format(''.join(expr.format(w) for w in words))\n",
    "\n",
    "fgg = df.loc[(df.drive_result=='Uncategorized')&(df.play_text.str.contains(fg_good,regex=True))]\n",
    "fgg_ids = list(fgg.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(fgg_ids), 'drive_result'] = 'FG GOOD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['field', 'goal', 'MISSED']\n",
    "fg_missed = base.format(''.join(expr.format(w) for w in words))\n",
    "\n",
    "fgm = df.loc[(df.drive_result=='Uncategorized')&(df.play_text.str.contains(fg_missed,regex=True))]\n",
    "fgm_ids = list(fgm.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(fgm_ids), 'drive_result'] = 'FG MISSED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['field', 'goal', 'BLOCKED']\n",
    "fg_blocked = base.format(''.join(expr.format(w) for w in words))\n",
    "\n",
    "fgb = df.loc[(df.drive_result=='Uncategorized')&(df.play_text.str.contains(fg_blocked,regex=True))]\n",
    "fgb_ids = list(fgb.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(fgb_ids), 'drive_result'] = 'FG MISSED'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['rush','TOUCHDOWN']\n",
    "rtd = base.format(''.join(expr.format(w) for w in words))\n",
    "\n",
    "rush_td = df.loc[(df.drive_result=='Uncategorized')&(df.play_text.str.contains(rtd,regex=True))]\n",
    "rtd_ids = list(rush_td.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(rtd_ids), 'drive_result'] = 'RUSHING TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['pass','complete','TOUCHDOWN']\n",
    "ptd = base.format(''.join(expr.format(w) for w in words))\n",
    "\n",
    "pass_td = df.loc[(df.drive_result=='Uncategorized')&(df.play_text.str.contains(ptd,regex=True))]\n",
    "ptd_ids = list(pass_td.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(ptd_ids), 'drive_result'] = 'PASSING TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fumbles = df.loc[(df.drive_result=='Uncategorized')&(df.play_type=='Fumble Recovery (Opponent)')]\n",
    "fids = list(fumbles.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(fids), 'drive_result'] = 'FUMBLE'\n",
    "\n",
    "fumbles = df.loc[(df.drive_result=='Uncategorized')&(df.play_text.str.contains('fumble|fumbles'))&(df.play_type=='Fumble Recovery (Own)')]\n",
    "fids = list(fumbles.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(fids), 'drive_result'] = 'FUMBLE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "safeties = df.loc[(df.drive_result=='Uncategorized')&(df.play_type=='Safety')]\n",
    "sids = list(safeties.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(sids), 'drive_result'] = 'SF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_of_game = df.loc[(df.drive_result=='Uncategorized')&(df.tr_game<=60)]\n",
    "eog_ids = list(end_of_game.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(eog_ids), 'drive_result'] = 'END OF GAME'\n",
    "\n",
    "end_of_half = df.loc[(df.drive_result=='Uncategorized')&(df.tr_half<=60)]\n",
    "eoh_ids = list(end_of_half.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(eoh_ids), 'drive_result'] = 'END OF HALF'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QB kneels, end of game\n",
    "words = ['TEAM','rush']\n",
    "kneel = base.format(''.join(expr.format(w) for w in words))\n",
    "kneel_df = df.loc[(df.drive_result=='Uncategorized')&(df.play_text.str.contains(kneel,regex=True))&(df.tr_game<=1800)]\n",
    "kneel_ids = list(kneel_df.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(kneel_ids), 'drive_result'] = 'END OF GAME'\n",
    "\n",
    "words = ['TEAM','run','loss']\n",
    "kneel = base.format(''.join(expr.format(w) for w in words))\n",
    "kneel_df = df.loc[(df.drive_result=='Uncategorized')&(df.play_text.str.contains(kneel,regex=True))&(df.tr_game<=1800)]\n",
    "kneel_ids = list(kneel_df.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(kneel_ids), 'drive_result'] = 'END OF GAME'\n",
    "\n",
    "# QB kneels, end of half\n",
    "words = ['TEAM','rush']\n",
    "kneel = base.format(''.join(expr.format(w) for w in words))\n",
    "kneel_df = df.loc[(df.drive_result=='Uncategorized')&(df.play_text.str.contains(kneel,regex=True))]\n",
    "kneel_ids = list(kneel_df.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(kneel_ids), 'drive_result'] = 'END OF HALF'\n",
    "\n",
    "words = ['TEAM','run','loss']\n",
    "kneel = base.format(''.join(expr.format(w) for w in words))\n",
    "kneel_df = df.loc[(df.drive_result=='Uncategorized')&(df.play_text.str.contains(kneel,regex=True))]\n",
    "kneel_ids = list(kneel_df.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(kneel_ids), 'drive_result'] = 'END OF HALF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turnover on downs\n",
    "tod = df.loc[(df.drive_result=='Uncategorized')&(df.down==4)&df.play_text.str.contains('incomplete')]\n",
    "tod_ids = list(tod.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(tod_ids), 'drive_result'] = 'TURNOVER ON DOWNS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rest, probably got drive ids split up\n",
    "df = df.loc[df.drive_result != 'Uncategorized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize\n",
    "df.loc[df.drive_result=='FUMBLE RETURN TD', 'drive_result'] = 'FUMBLE TD'\n",
    "\n",
    "df.loc[df.drive_result=='PUNT TD', 'drive_result'] = 'PUNT RETURN TD'\n",
    "\n",
    "df.loc[df.drive_result == 'INT RETURN TOUCH', 'drive_result'] = 'INT TD'\n",
    "\n",
    "df.loc[df.drive_result == 'BLOCKED FG (TD) TD', 'drive_result'] = 'MISSED FG TD'\n",
    "\n",
    "df.loc[df.drive_result=='POSS. ON DOWNS', 'drive_result'] = 'TURNOVER ON DOWNS'\n",
    "\n",
    "# turnover on downs\n",
    "df.loc[df.drive_result == 'DOWNS', 'drive_result'] = 'TURNOVER ON DOWNS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix miscategorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "often_missed = ['TURNOVER ON DOWNS','END OF GAME','END OF HALF']\n",
    "\n",
    "om = df.loc[(df.drive_result.isin(often_missed))&(df.play_type=='Field Goal Good')]\n",
    "om_ids = list(om.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(om_ids), 'drive_result'] = 'FG GOOD'\n",
    "\n",
    "om = df.loc[(df.drive_result.isin(often_missed))&(df.play_type=='Field Goal Missed')]\n",
    "om_ids = list(om.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(om_ids), 'drive_result'] = 'FG MISSED'\n",
    "\n",
    "words = ['pass','complete','TOUCHDOWN']\n",
    "pass_td = base.format(''.join(expr.format(w) for w in words))\n",
    "pdf = df.loc[(df.drive_result.isin(often_missed))&(df.play_text.str.contains(pass_td,regex=True))]\n",
    "pids = list(pdf.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(pids), 'drive_result'] = 'PASSING TD'\n",
    "\n",
    "words = ['pass','complete','for','TD']\n",
    "pass_td = base.format(''.join(expr.format(w) for w in words))\n",
    "pdf = df.loc[(df.drive_result.isin(often_missed))&(df.play_text.str.contains(pass_td,regex=True))]\n",
    "pdf = pdf.loc[~pdf.play_text.str.contains('TTD')]\n",
    "pids = list(pdf.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(pids), 'drive_result'] = 'PASSING TD'\n",
    "\n",
    "words = ['rush','for','TOUCHDOWN']\n",
    "rush_td = base.format(''.join(expr.format(w) for w in words))\n",
    "rdf = df.loc[(df.drive_result.isin(often_missed))&(df.play_text.str.contains(rush_td,regex=True))]\n",
    "rdf = rdf.loc[~rdf.play_text.str.contains('TTD')]\n",
    "rids = list(rdf.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(rids), 'drive_result'] = 'RUSHING TD'\n",
    "\n",
    "words = ['run','for','TD']\n",
    "rush_td = base.format(''.join(expr.format(w) for w in words))\n",
    "rdf = df.loc[(df.drive_result.isin(often_missed))&(df.play_text.str.contains(rush_td,regex=True))]\n",
    "rids = list(rdf.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(rids), 'drive_result'] = 'RUSHING TD'\n",
    "\n",
    "words = ['punt','touchback']\n",
    "punt = base.format(''.join(expr.format(w) for w in words))\n",
    "punt_df = df.loc[(df.drive_result.isin(often_missed))&(df.play_text.str.contains(punt,regex=True))]\n",
    "punt_df = punt_df.loc[~punt_df.play_text.str.contains('PENALTY')]\n",
    "punt_ids = list(punt_df.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(punt_ids), 'drive_result'] = 'PUNT'\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drive_result\n",
       "END OF GAME           35159\n",
       "END OF HALF           27914\n",
       "FG GOOD              236266\n",
       "FG MISSED             86818\n",
       "FUMBLE                66236\n",
       "FUMBLE TD              3918\n",
       "INT                   89036\n",
       "INT TD                 6626\n",
       "MISSED FG TD            401\n",
       "PASSING TD           150882\n",
       "PUNT                 592493\n",
       "PUNT RETURN TD         3737\n",
       "RUSHING TD           164488\n",
       "SF                     2334\n",
       "TD                   212689\n",
       "TURNOVER ON DOWNS    118521\n",
       "Name: down, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = df.groupby(['drive_result'])['down'].count()\n",
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797518\n",
      "1797259\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df.dropna(subset=['play_text'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "### Need 6 Features:\n",
    "-Down (check)  \n",
    "-Seconds left in half (check)  \n",
    "-Alternate Clock\n",
    "-Yards to go for touchdown (log?)  \n",
    "-Yards to go for first down (log?)    \n",
    "-Goal to goal indicator  \n",
    "-Under 2 minutes indicator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['away', 'defense', 'defense_conference', 'defense_score', 'down', 'drive_id', 'home', 'id', 'offense', 'offense_conference', 'offense_score', 'period', 'play_text', 'play_type', 'yard_line', 'yards_gained', 'season', 'week', 'season_type', 'drive_result', 'elapsed.minutes', 'elapsed.seconds', 'end_period', 'end_time.minutes', 'end_time.seconds', 'end_yardline', 'game_id', 'plays', 'scoring', 'start_period', 'start_time.minutes', 'start_time.seconds', 'start_yardline', 'yards', 'tr_game', 'tr_half', 'distance', 'drive_time']\n"
     ]
    }
   ],
   "source": [
    "print(list(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clock data is unreliable because maybe 25% of the games have only have one time for each play, and that time is when the drive started. So I decided to get the total time of each drive, and then assume each play took the same amount of time. EPA shouldn't be significantly affected most of the time, i.e. a 70 yard pass will be considered a good play no matter what. The only time it might have an adverse effect is toward the end of a game, when seconds matter. I think that in college football, when the clock stops for a first down, and incompletions, that all pass plays probably do take a somewhat similar amount of time. Drives in this situation will consist mostly of the same play type, and plays of the same play type likely take similar amounts of time. I'll compare it to the clock data I do have to make sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt clock\n",
    "\n",
    "# these get the start and end time of every drive\n",
    "maxs = df.groupby(['game_id','drive_id'])['tr_game'].max().reset_index()\n",
    "mins = df.groupby(['game_id','drive_id'])['tr_game'].min().reset_index()\n",
    "maxs = maxs.rename(columns={'tr_game':'drive_start'})\n",
    "mins = mins.rename(columns={'tr_game':'drive_end'})\n",
    "\n",
    "# sometimes the drive end time is the same as the drive start. in that case, I use the next drive start\n",
    "maxs = maxs.sort_values(by=['game_id','drive_start'],ascending=False)\n",
    "next_max = maxs.groupby(['game_id'])['drive_start'].shift(-1)\n",
    "next_max = pd.Series(next_max, name='next_drive_start')\n",
    "new_max = pd.concat([maxs, next_max], axis=1)\n",
    "new_max['next_drive_start'] = new_max['next_drive_start'].fillna(0)\n",
    "\n",
    "# sometimes (rarely, 2%ish of the time) both the next drive start and the drive end are the same as the drive start\n",
    "# in that case, as a last resort, i use the next drive end time. \n",
    "# i'm fairly sure most of the time it's when a timeout or something divides the same drive into two.\n",
    "# i can explore this more in future work\n",
    "mins = mins.sort_values(by=['game_id','drive_end'],ascending=False)\n",
    "next_min = mins.groupby(['game_id'])['drive_end'].shift(-1)\n",
    "next_min = pd.Series(next_min, name='next_drive_end')\n",
    "new_min = pd.concat([mins, next_min], axis=1)\n",
    "new_min['next_drive_end'] = new_min['next_drive_end'].fillna(0)\n",
    "new_min = new_min.drop(columns='game_id')\n",
    "times = pd.merge(left=new_max,right=new_min,on=['drive_id','drive_id'],how='left')\n",
    "\n",
    "# attempt 1 (works on ~75% of data)\n",
    "times['drive_time_1'] = times['drive_start'] - times['drive_end']\n",
    "# plan b (works on 98% of data)\n",
    "times['drive_time_2'] = np.where(times['drive_time_1']>0,times['drive_time_1'],(times['drive_start']-times['next_drive_start']))\n",
    "# last resort (works on 99.3% of data)\n",
    "times['drive_time'] = np.where(times['drive_time_2']>0,times['drive_time_2'],(times['drive_start']-times['next_drive_end']))\n",
    "\n",
    "# if all 3 don't work, drop that crap\n",
    "times = times[['drive_id','drive_time']]\n",
    "times = times.rename(columns={'drive_time':'alt_drive_time'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=df,right=times,how='left',on=['drive_id','drive_id'])\n",
    "df = df.loc[df.drive_time>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to divide the drive time up amongst the plays. \n",
    "# separate timeouts and penalties\n",
    "tps = ['Timeout','Penalty']\n",
    "ts_and_ps = df.loc[df['play_type'].isin(tps)]\n",
    "\n",
    "df = df.loc[~df['play_type'].isin(tps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in my cleaning sometimes i merged or divided up drives. using my own play count.\n",
    "gb = df.groupby(['drive_id'])['down'].count().reset_index()\n",
    "gb = gb.rename(columns={'down':'alt_plays'})\n",
    "\n",
    "df = pd.merge(left=df,right=gb,how='left',on=['drive_id','drive_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              plays  alt_plays\n",
      "plays      1.000000   0.973881\n",
      "alt_plays  0.973881   1.000000\n"
     ]
    }
   ],
   "source": [
    "# validate\n",
    "print(df[['plays','alt_plays']].corr())\n",
    "\n",
    "df = df.drop(columns=['plays','drive_time'])\n",
    "df = df.rename(columns={'alt_plays':'plays', 'alt_drive_time':'drive_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time per play\n",
    "df['tpp'] = df['drive_time']/df['plays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['away', 'defense', 'defense_conference', 'defense_score', 'down', 'drive_id', 'home', 'id', 'offense', 'offense_conference', 'offense_score', 'period', 'play_text', 'play_type', 'yards_gained', 'season', 'week', 'season_type', 'drive_result', 'elapsed.minutes', 'elapsed.seconds', 'end_period', 'end_time.minutes', 'end_time.seconds', 'end_yardline', 'game_id', 'scoring', 'start_period', 'start_time.minutes', 'start_time.seconds', 'start_yardline', 'yards', 'tr_game', 'tr_half', 'distance', 'drive_time', 'plays', 'tpp', 'yard_line', 'l10_dist', 'GTG', 'UTM']\n"
     ]
    }
   ],
   "source": [
    "print(list(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you remove the game id from the play id, or the drive id, then you usually get a numbered list. if you don't, the 100th play will be sorted behind the 99th because it starts with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_len\n",
       "10         2\n",
       "12    971507\n",
       "13       127\n",
       "18    663181\n",
       "Name: drive_id, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by=['game_id','drive_id','id'],ascending=False)\n",
    "df['id_len'] = df.id.astype(str).str.len()\n",
    "# print(df[['game_id','drive_id','id','id_len','tr_game']])\n",
    "gb = df.groupby(['id_len'])['drive_id'].count()\n",
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           game_id     drive_id                  id  tr_game\n",
      "1634673  401100159  40110015926  401100159104985607    103.0\n",
      "1634675  401100159  40110015926  401100159104985605    103.0\n",
      "1634674  401100159  40110015926  401100159104985604    103.0\n",
      "1634672  401100159  40110015925  401100159104985601    103.0\n",
      "1634676  401100159  40110015925  401100159104985201    107.0\n",
      "1634677  401100159  40110015925  401100159104984801    111.0\n",
      "1634679  401100159  40110015925  401100159104976702    152.0\n",
      "1634678  401100159  40110015925  401100159104976701    152.0\n",
      "1634680  401100159  40110015925  401100159104968502    194.0\n",
      "1634681  401100159  40110015925  401100159104968501    194.0\n",
      "1634685  401100159  40110015925  401100159104954306    296.0\n",
      "1634683  401100159  40110015925  401100159104954305    296.0\n",
      "1634684  401100159  40110015925  401100159104954304    296.0\n",
      "1634682  401100159  40110015924  401100159104954301    296.0\n",
      "1634686  401100159  40110015924  401100159104928805    431.0\n",
      "1634687  401100159  40110015924  401100159104928804    431.0\n",
      "1634688  401100159  40110015924  401100159104928802    431.0\n",
      "1634689  401100159  40110015924  401100159104916603    513.0\n",
      "1634690  401100159  40110015924  401100159104916602    513.0\n",
      "1634692  401100159  40110015924  401100159104905004    589.0\n",
      "1634691  401100159  40110015924  401100159104905002    589.0\n",
      "1634693  401100159  40110015924  401100159104905001    589.0\n",
      "1634698  401100159  40110015923  401100159104877407    745.0\n",
      "1634699  401100159  40110015923  401100159104877406    745.0\n",
      "1634694  401100159  40110015923  401100159104877405    745.0\n",
      "1634695  401100159  40110015923  401100159104877404    745.0\n",
      "1634696  401100159  40110015923  401100159104877403    745.0\n",
      "1634700  401100159  40110015923  401100159104877402    745.0\n",
      "1634697  401100159  40110015923  401100159104877401    745.0\n",
      "1634701  401100159  40110015923  401100159104869801    781.0\n",
      "...            ...          ...                 ...      ...\n",
      "124      252440009  25244000904        252440009045   2890.0\n",
      "125      252440009  25244000904        252440009042   2928.0\n",
      "126      252440009  25244000904        252440009040   2933.0\n",
      "127      252440009  25244000904        252440009037   2988.0\n",
      "128      252440009  25244000904        252440009036   3012.0\n",
      "129      252440009  25244000904        252440009035   3039.0\n",
      "130      252440009  25244000903        252440009032   3056.0\n",
      "132      252440009  25244000903        252440009031   3085.0\n",
      "131      252440009  25244000903        252440009027   3085.0\n",
      "133      252440009  25244000903        252440009026   3134.0\n",
      "134      252440009  25244000903        252440009025   3169.0\n",
      "135      252440009  25244000903        252440009023   3180.0\n",
      "136      252440009  25244000903        252440009022   3201.0\n",
      "138      252440009  25244000903        252440009021   3252.0\n",
      "137      252440009  25244000903        252440009020   3252.0\n",
      "139      252440009  25244000903        252440009019   3257.0\n",
      "140      252440009  25244000903        252440009018   3263.0\n",
      "141      252440009  25244000903        252440009017   3283.0\n",
      "142      252440009  25244000903        252440009016   3316.0\n",
      "143      252440009  25244000903        252440009015   3340.0\n",
      "144      252440009  25244000902        252440009014   3355.0\n",
      "145      252440009  25244000902        252440009013   3410.0\n",
      "146      252440009  25244000902        252440009012   3420.0\n",
      "147      252440009  25244000902        252440009011   3447.0\n",
      "148      252440009  25244000902        252440009009   3500.0\n",
      "149      252440009  25244000902        252440009008   3510.0\n",
      "150      252440009  25244000901        252440009007   3526.0\n",
      "151      252440009  25244000901        252440009006   3541.0\n",
      "152      252440009  25244000901        252440009003   3562.0\n",
      "153      252440009  25244000901        252440009002   3580.0\n",
      "\n",
      "[1634817 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(by=['game_id','drive_id','id'],ascending=False)\n",
    "print(df[['game_id','drive_id','id','tr_game']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300025    Alex McGough pass complete to Alex Gardner for...\n",
       "1152823          Zach Conque run for no gain to the SFAus 20\n",
       "417104           Tim Curry rush for no gain to the NMxSt 49.\n",
       "417106      Trevor Walls pass incomplete to William Bullock.\n",
       "417108       Trevor Walls pass incomplete to Donyae Coleman.\n",
       "417107       Trevor Walls pass incomplete to Donyae Coleman.\n",
       "417105     Trevor Walls pass complete to William Bullock ...\n",
       "417113     Kyle Petersen punt for 36 yards, returned by D...\n",
       "417112     Michael Farrar rush for no gain to the UTEP 21...\n",
       "417111     Michael Farrar rush for no gain to the UTEP 21...\n",
       "417110     Tim Curry pass incomplete to Melvin Stephenson...\n",
       "417109     Trevor Walls pass complete to Kyle Nelson for ...\n",
       "417115     Trevor Walls rush for 13 yards to the UTEP 5, ...\n",
       "417116     Trevor Walls pass complete to Tonny Glynn for ...\n",
       "417117     Tonny Glynn rush for 1 yard to the UTEP 29, ta...\n",
       "417118      Trevor Walls pass incomplete to Marcus Anderson.\n",
       "417119     Tonny Glynn rush for 7 yards to the UTEP 30, t...\n",
       "417120     Trevor Walls pass complete to Tonny Glynn for ...\n",
       "417121     Seth Smith rush for a loss of 1 yard to the UT...\n",
       "417122     Seth Smith rush for 4 yards to the UTEP 42, ta...\n",
       "417114     Vernon Frazier rush for 13 yards for a TOUCHDOWN.\n",
       "417130     Trevor Vittatoe pass incomplete to Melvin Step...\n",
       "417131               Trevor Vittatoe pass incomplete to N/A.\n",
       "417129     Jason Williams rush for 3 yards to the NMxSt 1...\n",
       "417128     Jason Williams rush for 8 yards to the NMxSt 1...\n",
       "417127     Jason Williams rush for 3 yards to the NMxSt 2...\n",
       "417126        Trevor Vittatoe pass incomplete to Evan Davis.\n",
       "417125     Donald Buckram rush for 8 yards to the NMxSt 2...\n",
       "417136     Donald Buckram rush for 3 yards to the NMxSt 3...\n",
       "417124     Donald Buckram rush for 8 yards to the NMxSt 3...\n",
       "                                 ...                        \n",
       "269217     Drew Weatherford deep pass complete to Caz Piu...\n",
       "269220     Travis Baltz punt for 50 yards, returned by Pr...\n",
       "269221             Chris Turner post pass incomplete to N/A.\n",
       "269219     Chris Turner sacked by Geno Hayes at the Mary ...\n",
       "269222     Keon Lattimore rush over right guard for a los...\n",
       "269226     Brent Moody punt for 23 yards punt out-of-boun...\n",
       "269227     Drew Weatherford screen pass incomplete to Pre...\n",
       "269225     Drew Weatherford rush up the middle for 4 yard...\n",
       "269228     Preston Parker rush right for 2 yards to the F...\n",
       "269223     Chris Turner screen pass incomplete to Keon La...\n",
       "269224     Chris Turner sideline pass incomplete to Isaia...\n",
       "269270     Keon Lattimore rush over right guard for 2 yar...\n",
       "269260     Keon Lattimore rush for 4 yards to the FlaSt 3...\n",
       "269256     Chris Turner rush for 11 yards to the FlaSt 42...\n",
       "269259     Chris Turner pass complete to Darrius Heyward-...\n",
       "269258     Keon Lattimore rush for 5 yards to the Mary 27...\n",
       "269257     Keon Lattimore rush for 8 yards to the Mary 22...\n",
       "269255     Graham Gano punt for 46 yards, fair catch by C...\n",
       "269250     Drew Weatherford pass complete to Charlie Grah...\n",
       "269254     Drew Weatherford pass complete to Joslin Shaw ...\n",
       "269253     Drew Weatherford pass complete to Greg Carr fo...\n",
       "269252     Preston Parker rush for no gain to the FlaSt 1...\n",
       "269251     Drew Weatherford pass incomplete to De'Cody Fagg.\n",
       "269248     Chris Turner pass complete to Darrius Heyward-...\n",
       "269249     Chris Turner pass complete to Keon Lattimore f...\n",
       "269246     Keon Lattimore rush for no gain to the FlaSt 1...\n",
       "269247     Chris Turner pass complete to Isaiah Williams ...\n",
       "269263     Brent Moody punt for 32 yards, fair catch by C...\n",
       "269242     Drew Weatherford pass incomplete, Florida St p...\n",
       "269262     Drew Weatherford sideline pass incomplete to D...\n",
       "Name: play_text, Length: 129, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_ids = df.loc[~df['id_len'].isin([12,18])]\n",
    "bad_ids.play_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix yard_line, it's w.r.t the home team\n",
    "df = df.rename(columns={'yard_line':'wrong_yardline'})\n",
    "\n",
    "df['yard_line'] = np.where(df['offense']==df['home'],df['wrong_yardline'],100-df['wrong_yardline'])\n",
    "# print(df[['home','offense','yard_line','wrong_yardline']].head(50))\n",
    "df = df.drop(columns=['wrong_yardline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get log 10 of distance\n",
    "df['l10_dist'] = np.log10(df['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal to go\n",
    "df['GTG'] = np.where((df['yard_line']+df['distance']>=100),1,0)\n",
    "\n",
    "\n",
    "# under two min in half\n",
    "df['UTM'] = np.where(df['tr_half']<=120,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './output/processed.csv'\n",
    "df.to_csv(PATH,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
