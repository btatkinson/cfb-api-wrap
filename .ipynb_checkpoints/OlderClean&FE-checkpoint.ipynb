{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "import datetime\n",
    "gc.collect()\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:27<00:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2031893, 41)\n",
      "2031893 plays were loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load play by play & drive data\n",
    "years = list(range(2005, int(datetime.datetime.now().year)))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year in tqdm(years):\n",
    "    path = './output/'+str(year)+'/'+str(year)+'_pbp.csv'\n",
    "    sea_df = pd.read_csv(path)\n",
    "    \n",
    "    drive_path = './output/'+str(year)+'/'+str(year)+'_drives.csv'\n",
    "    drive_df = pd.read_csv(drive_path)\n",
    "    \n",
    "    drive_df = drive_df.rename(columns={'id':'drive_id'})\n",
    "    \n",
    "    sea_df = pd.merge(left=sea_df, right=drive_df, how='left', on=['drive_id','drive_id'])\n",
    "    df = pd.concat([df,sea_df])\n",
    "\n",
    "num_plays = len(df)\n",
    "print(df.shape)\n",
    "print(str(num_plays) + \" plays were loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offense_x seems to be correct while offense_y is not\n",
    "\n",
    "df = df.drop(columns=['defense_y','defense_conference_y','offense_y','offense_conference_y'])\n",
    "\n",
    "df = df.rename(columns={'defense_x':'defense','defense_conference_x':'defense_conference','offense_x':'offense','offense_conference_x':'offense_conference'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix yard_line, it's w.r.t the home team\n",
    "df = df.rename(columns={'yard_line':'wrong_yardline'})\n",
    "\n",
    "df['yard_line'] = np.where(df['offense']==df['home'],df['wrong_yardline'],100-df['wrong_yardline'])\n",
    "# print(df[['home','offense','yard_line','wrong_yardline']].head(50))\n",
    "df = df.drop(columns=['wrong_yardline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alt_game_id'] = df['game_id'].copy().astype(str)\n",
    "df['alt_drive_id'] = df['drive_id'].copy().astype(str)\n",
    "\n",
    "def replace_id(x,y):\n",
    "    return x.replace(y,'')\n",
    "df['alt_drive_id'] = df.apply(lambda row: replace_id(row['alt_drive_id'], row['alt_game_id']), axis=1)\n",
    "\n",
    "#  strip leading zeros from 1-9 drive numbers\n",
    "df['alt_drive_id'] = df['alt_drive_id'].str.lstrip(\"0\")\n",
    "\n",
    "# this also eliminates drive \"zeros\", so replace empty space with zero\n",
    "df['alt_drive_id'] = df['alt_drive_id'].replace(r'^\\s*$', '0', regex=True)\n",
    "\n",
    "# print(df.groupby(['alt_drive_id'])['down'].count().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Teams\n",
    "\n",
    "Overtimes are for future work, doing point afters last here (or maybe not at all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1986166\n"
     ]
    }
   ],
   "source": [
    "# print(len(df))\n",
    "pat = ['2pt Conversion','Offensive 1pt Safety','Defensive 2pt Conversion','Extra Point Good','Extra Point Missed']\n",
    "\n",
    "df = df.loc[~df.play_type.isin(pat)]\n",
    "\n",
    "\n",
    "# kos = ['Kickoff','Kickoff Return (Offense)','Kickoff Return Touchdown']\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979243\n"
     ]
    }
   ],
   "source": [
    "# also drop overtime\n",
    "\n",
    "df = df.loc[(df.period > 0) & (df.period <= 4)]\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly, I want to clean/aggregate kickoffs and get that out of the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df.play_type=='Kickoff Return Touchdown'].play_text\n",
    "df.loc[df['play_type']=='Kickoff Return (Offense)','play_type'] = 'Kickoff'\n",
    "\n",
    "krts = df.loc[(df['play_type']=='Kickoff') & (df['play_text'].str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "krts = krts.loc[~krts['play_text'].str.contains('TTD')]\n",
    "\n",
    "base = r'^{}'\n",
    "expr = '(?=.*{})'\n",
    "words = ['penalty', 'accepted']\n",
    "called_back = base.format(''.join(expr.format(w) for w in words))\n",
    "\n",
    "krts = krts.loc[~krts.play_text.str.contains(called_back,regex=True)]\n",
    "\n",
    "# no fumbles\n",
    "fkrt = krts.loc[krts.play_text.str.contains('fumbled')]\n",
    "# this play isn't a fumble return touchdown \n",
    "fkrt = fkrt.loc[~fkrt.play_text.str.contains('Cole Lerch')]\n",
    "# fumble return touchdowns\n",
    "frt_ids = list(fkrt.id.values)\n",
    "\n",
    "# kick return touchdowns\n",
    "krt_ids = list(krts.loc[~krts['id'].isin(frt_ids)].id.values)\n",
    "\n",
    "\n",
    "df.loc[df.id.isin(frt_ids), 'play_type'] = 'Fumble Return Touchdown (Kick Team)'\n",
    "df.loc[df.id.isin(krt_ids), 'play_type'] = 'Kickoff Return Touchdown'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drives with two kickoffs probably have a penalty on one kickoff\n",
    "# gb = df.groupby(['drive_id','play_type'])['id'].count().reset_index()\n",
    "\n",
    "# two_kos_ids = list(gb.loc[(gb['play_type']=='Kickoff')&(gb['id']>1)].drive_id.values)\n",
    "# two_kos = df.loc[df.drive_id.isin(two_kos_ids)]\n",
    "# tkos = two_kos.loc[two_kos.play_type=='Kickoff']\n",
    "\n",
    "# some duplicate kickoffs\n",
    "# print(len(tkos))\n",
    "# tkos = tkos.drop_duplicates(subset=['drive_id','offense','clock.minutes','clock.seconds'])\n",
    "# print(len(tkos))\n",
    "\n",
    "# tkos = tkos.dropna(subset=['play_text'])\n",
    "# subset = tkos.loc[tkos.play_text.str.contains('penalty')]\n",
    "# print(len(subset))\n",
    "# # subset[['drive_id','offense','clock.minutes','clock.seconds','play_text']]\n",
    "# for pt in list(subset.play_text.values):\n",
    "#     print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "onsides = df.loc[(df.play_type=='Kickoff')&(df.play_text.str.contains('on-side'))]\n",
    "os_ids = list(onsides.id.values)\n",
    "df.loc[df['id'].isin(os_ids), 'play_type'] = 'Onside Recovery'\n",
    "\n",
    "\n",
    "## need further cleaning to figure out who recovered the onside probably \n",
    "## below was my first crack at it\n",
    "# df['next_play_offense'] = df['offense'].copy().shift(-1).fillna('none')\n",
    "# df['prev_play_offense'] = df['offense'].copy().shift(1).fillna('none')\n",
    "# df[['next_play_offense','prev_play_offense','offense']]\n",
    "\n",
    "# onside_ids = list(onsides.id.values)\n",
    "# df['onside'] = np.where(df['id'].isin(onside_ids), 1, 0)\n",
    "\n",
    "# # if the onside kick is on the first play of the game, it's always assumed to be recovered by the Receiving Team (I'm being lazy)\n",
    "# df.loc[(df['onside']==1)&(df['prev_play_offense']==df['next_play_offense']), 'play_type'] = 'Onside Recovery (Kick Team)'\n",
    "# df.loc[(df['onside']==1)&(df['prev_play_offense']!=df['next_play_offense']), 'play_type'] = 'Onside Recovery (Rec Team)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb = df.groupby(['drive_id','play_type'])['id'].count().reset_index()\n",
    "# gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clock\n",
    "\n",
    "Clock data is unreliable because maybe 25% of the games have only have one time for each play, and that time is when the drive started. I played with trying to predict time per play based on play type, but the data was very messy. So I decided to get the total time of each drive, and then assume each play took the same amount of time. EPA shouldn't be significantly affected most of the time, i.e. a 70 yard pass will be considered a good play no matter what. The only time it might have an adverse effect is toward the end of a game, when seconds matter. I think that in college football, when the clock stops for a first down, and incompletions, that all pass plays probably do take a somewhat similar amount of time. Drives in this situation will consist mostly of the same play type, and plays of the same play type likely take similar amounts of time. I'll compare it to the clock data I do have to make sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix clock data first so drives can be figured out\n",
    "time_cols = ['clock.minutes','clock.seconds','start_time.minutes','start_time.seconds',\n",
    "            'end_time.minutes','end_time.seconds']\n",
    "for tc in time_cols:\n",
    "    df[tc] = df[tc].fillna(0)\n",
    "\n",
    "# get time remaining in game\n",
    "df['tr_game'] = (4-df['period']) * 900 + (df['clock.minutes'] * 60) + df['clock.seconds']\n",
    "df['tr_half'] = np.where(df['period']>2,df['tr_game'], df['tr_game']-1800)\n",
    "\n",
    "df = df.drop(columns=['clock.minutes','clock.seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill empties\n",
    "df['elapsed.minutes'] = df['elapsed.minutes'].copy().fillna(0)\n",
    "df['elapsed.seconds'] = df['elapsed.seconds'].copy().fillna(0)\n",
    "df['drive_time'] = 60*df['elapsed.minutes'] + df['elapsed.seconds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11340\n",
      "277556\n",
      "145.28465606940583\n"
     ]
    }
   ],
   "source": [
    "# a lot of those drive times are negative... and other problems. so here's an alt drive time\n",
    "# alt clock\n",
    "\n",
    "# these get the start and end time of every drive\n",
    "maxs = df.groupby(['game_id','drive_id'])['tr_game'].max().reset_index()\n",
    "mins = df.groupby(['game_id','drive_id'])['tr_game'].min().reset_index()\n",
    "maxs = maxs.rename(columns={'tr_game':'drive_start'})\n",
    "mins = mins.rename(columns={'tr_game':'drive_end'})\n",
    "\n",
    "# sometimes the drive end time is the same as the drive start. in that case, I use the next drive start\n",
    "maxs = maxs.sort_values(by=['game_id','drive_start'],ascending=False)\n",
    "next_max = maxs.groupby(['game_id'])['drive_start'].shift(-1)\n",
    "next_max = pd.Series(next_max, name='next_drive_start')\n",
    "new_max = pd.concat([maxs, next_max], axis=1)\n",
    "new_max['next_drive_start'] = new_max['next_drive_start'].fillna(0)\n",
    "\n",
    "# sometimes (rarely, 2%ish of the time) both the next drive start and the drive end are the same as the drive start\n",
    "# i can explore this more in future work\n",
    "# i'm fairly sure most of the time it's when a timeout or something divides the same drive into two.\n",
    "\n",
    "mins = mins.sort_values(by=['game_id','drive_end'],ascending=False)\n",
    "next_min = mins.groupby(['game_id'])['drive_end'].shift(-1)\n",
    "next_min = pd.Series(next_min, name='next_drive_end')\n",
    "new_min = pd.concat([mins, next_min], axis=1)\n",
    "new_min['next_drive_end'] = new_min['next_drive_end'].fillna(0)\n",
    "new_min = new_min.drop(columns='game_id')\n",
    "times = pd.merge(left=new_max,right=new_min,on=['drive_id','drive_id'],how='left')\n",
    "\n",
    "\n",
    "# attempt 1 (works on ~95.5% of data)\n",
    "times['drive_time_1'] = times['drive_start']-times['next_drive_start']\n",
    "# plan B (95.8% of data)\n",
    "times['drive_time'] = np.where(times['drive_time_1']>0,times['drive_time_1'],(times['drive_start']-times['drive_end']))\n",
    "# last resort (didn't implement)\n",
    "# times['drive_time'] = np.where(times['drive_time_2']>0,times['drive_time_2'],(times['drive_start']-times['next_drive_end']))\n",
    "\n",
    "not_good = times.loc[times.drive_time<=0]\n",
    "print(len(not_good))\n",
    "\n",
    "good = times.loc[times.drive_time>0]\n",
    "print(len(good))\n",
    "\n",
    "print(good.drive_time.mean())\n",
    "\n",
    "times = times[['drive_id','drive_time']]\n",
    "times = times.rename(columns={'drive_time':'alt_drive_time'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=df,right=times,how='left',on=['drive_id','drive_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958149\n",
      "correlation between primary and approximate drive time\n",
      "                    drive_time  alt_drive_time  correct_drive_time\n",
      "drive_time            1.000000        0.854848            0.991366\n",
      "alt_drive_time        0.854848        1.000000            0.862340\n",
      "correct_drive_time    0.991366        0.862340            1.000000\n"
     ]
    }
   ],
   "source": [
    "# longest drive in CFB history is 882. so need to drop anything above 900\n",
    "# also drop anything below or equal to 0\n",
    "\n",
    "df['correct_time_1'] = np.where(df['drive_time'] > 0, df['drive_time'], df['alt_drive_time'])\n",
    "\n",
    "df = df.loc[df['correct_time_1'] > 0]\n",
    "\n",
    "df['correct_drive_time'] = np.where(df['drive_time'] < 900, df['drive_time'], df['alt_drive_time'])\n",
    "\n",
    "df = df.loc[df['correct_drive_time'] < 900]\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "print(\"correlation between primary and approximate drive time\")\n",
    "print(df[['drive_time','alt_drive_time','correct_drive_time']].corr())\n",
    "\n",
    "df = df.drop(columns=['drive_time','alt_drive_time','correct_time_1'])\n",
    "df = df.rename(columns={'correct_drive_time':'drive_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1958149\n",
      "1957877\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df.dropna(subset=['play_text'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: examine drives so that end of half and end of game drives are the only back-to-back drives that can result in same team possessing the ball. Also muffed punts fall into this category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_offenses\n",
      "1    231865\n",
      "2     51873\n",
      "Name: game_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "gb = df.groupby(['game_id','drive_id','alt_drive_id'])['offense'].nunique().reset_index()\n",
    "gb = gb.rename(columns={'offense':'num_offenses'})\n",
    "gb = gb.groupby(['drive_id','num_offenses'])['game_id'].count().reset_index()\n",
    "print(gb.groupby(['num_offenses'])['game_id'].count())\n",
    "# about 18% of drives have two offenses\n",
    "# most of these are drives that include kickoffs with the offense & defense reverse\n",
    "# i'll choose to make the return team the offense\n",
    "two_os = gb.loc[gb.num_offenses == 2]\n",
    "to_ids = list(two_os.drive_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = df.loc[(df.drive_id.isin(to_ids))]\n",
    "\n",
    "\n",
    "kos = kos.loc[kos.play_type=='Kickoff']\n",
    "wrong_teams = list(kos.id.values)\n",
    "\n",
    "df = df.rename(columns={'offense':'wrong_offense','defense':'wrong_defense'})\n",
    "\n",
    "df['offense'] = np.where(df['id'].isin(wrong_teams),df['wrong_defense'],df['wrong_offense'])\n",
    "df['defense'] = np.where(df['id'].isin(wrong_teams),df['wrong_offense'],df['wrong_defense'])\n",
    "\n",
    "\n",
    "df = df.drop(columns=['wrong_offense','wrong_defense'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_offenses\n",
      "1    281883\n",
      "2      1855\n",
      "Name: game_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# switching kickoffs fixes vast majority\n",
    "gb = df.groupby(['game_id','drive_id','alt_drive_id'])['offense'].nunique().reset_index()\n",
    "gb = gb.rename(columns={'offense':'num_offenses'})\n",
    "gb = gb.groupby(['drive_id','num_offenses'])['game_id'].count().reset_index()\n",
    "print(gb.groupby(['num_offenses'])['game_id'].count())\n",
    "\n",
    "\n",
    "two_os = gb.loc[gb.num_offenses == 2]\n",
    "to_ids = list(two_os.drive_id.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can switch \"no play\" penalties as well\n",
    "tos = df.loc[(df.drive_id.isin(to_ids))]\n",
    "\n",
    "tos.loc[:,'drive_id'] = tos['drive_id'].astype(str)\n",
    "tos.loc[:,'comb_id'] = tos['offense'].copy()+tos['drive_id'].copy()\n",
    "\n",
    "gb = tos.groupby(['drive_id','offense'])['down'].count().reset_index()\n",
    "gb.loc[:,'comb_id'] = gb['offense'].copy()+gb['drive_id'].copy()\n",
    "\n",
    "op = gb.loc[gb['down']==1]\n",
    "\n",
    "one_plays = list(op.comb_id.values)\n",
    "\n",
    "switch = tos.loc[(tos['comb_id'].isin(one_plays))&(tos['play_type']=='Penalty')]\n",
    "wrong_teams = list(switch.id.values)\n",
    "\n",
    "df = df.rename(columns={'offense':'wrong_offense','defense':'wrong_defense'})\n",
    "\n",
    "df['offense'] = np.where(df['id'].isin(wrong_teams),df['wrong_defense'],df['wrong_offense'])\n",
    "df['defense'] = np.where(df['id'].isin(wrong_teams),df['wrong_offense'],df['wrong_defense'])\n",
    "\n",
    "\n",
    "df = df.drop(columns=['wrong_offense','wrong_defense'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gb = df.groupby(['game_id','drive_id','alt_drive_id'])['offense'].nunique().reset_index()\n",
    "gb = gb.rename(columns={'offense':'num_offenses'})\n",
    "gb = gb.groupby(['drive_id','num_offenses'])['game_id'].count().reset_index()\n",
    "\n",
    "two_os = gb.loc[gb.num_offenses == 2]\n",
    "to_ids = list(two_os.drive_id.unique())\n",
    "df['multiple_offenses'] = np.where(df['drive_id'].isin(to_ids),1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempting to fix drives with multiple offenses sucks.\n",
    "\n",
    "mos = df.loc[df.multiple_offenses == 1].copy()\n",
    "# mos[['drive_id','play_type','offense','last_offense','last_di','tr_game','off_switch']].head(50)\n",
    "# some of the problems are end of periods and end of halfs\n",
    "bad = ['End Period','End of Half']\n",
    "mos = mos.loc[~mos.play_type.isin(bad)]\n",
    "\n",
    "# drop drives that only have one now\n",
    "gb = mos.groupby(['drive_id'])['offense'].nunique().reset_index()\n",
    "gb = gb.loc[gb.offense==1]\n",
    "# end of half or end of period drive ids\n",
    "gb_ids = list(gb.drive_id.unique())\n",
    "mos = mos.loc[~mos.drive_id.isin(gb_ids)]\n",
    "\n",
    "mos = mos.sort_values(by=['drive_id','tr_game','offense'],ascending=False)\n",
    "mos['last_offense'] = mos['offense'].shift(1)\n",
    "mos['last_di'] = mos['drive_id'].shift(1).fillna(0).astype(int)\n",
    "# mark every time the offense switches with a 1\n",
    "mos['off_switch'] = np.where(((mos['offense']!=mos['last_offense'])&(mos['drive_id']==mos['last_di'])),1,0)\n",
    "\n",
    "\n",
    "gb = mos.groupby(['drive_id'])['off_switch'].sum().reset_index()\n",
    "targs = gb.loc[gb['off_switch']==1]\n",
    "\n",
    "# focus on drives with just one switch between offenses\n",
    "targ_ids = list(targs.drive_id.values)\n",
    "can_fix = mos.loc[mos.drive_id.isin(targ_ids)]\n",
    "\n",
    "\n",
    "df.loc[:,'mo_identifier'] = df['drive_id'].astype(str) + '_' + df['offense']\n",
    "can_fix.loc[:,'mo_identifier'] = can_fix['drive_id'].astype(str) + '_' + can_fix['offense']\n",
    "\n",
    "cf_ids = list(can_fix.loc[can_fix['off_switch']==1].mo_identifier.values)\n",
    "# need to make drive results uncategorized\n",
    "all_cf_ids = list(can_fix.drive_id.values)\n",
    "\n",
    "df.loc[df.drive_id.isin(all_cf_ids), 'drive_result'] = 'Uncategorized'\n",
    "\n",
    "df['alt_drive_id'] = df['alt_drive_id'].astype(float)\n",
    "df['drive_id'] = np.where(df['mo_identifier'].isin(cf_ids),df['drive_id']+0.5, df['drive_id'])\n",
    "df['alt_drive_id'] = np.where(df['mo_identifier'].isin(cf_ids),df['alt_drive_id']+0.5, df['alt_drive_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can attempt to figure out other multiple offenses later\n",
    "# timeouts seem to be an issue, try switching them\n",
    "\n",
    "mos = mos.loc[~mos.drive_id.isin(all_cf_ids)]\n",
    "\n",
    "mos.groupby('play_type')['down'].count()\n",
    "mos = mos.rename(columns={'offense':'wrong_offense','defense':'wrong_defense'})\n",
    "mos['offense'] = np.where(mos['play_type']=='Timeout', mos['wrong_defense'], mos['wrong_offense'])\n",
    "mos['defense'] = np.where(mos['play_type']=='Timeout', mos['wrong_offense'], mos['wrong_defense'])\n",
    "\n",
    "mos = mos.drop(columns=['wrong_offense','wrong_defense'])\n",
    "\n",
    "gb = mos.groupby(['drive_id'])['offense'].nunique().sort_values().reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = mos.loc[mos.drive_id.isin(list(gb.loc[gb.offense==1].drive_id.values))]\n",
    "\n",
    "targ_ids = list(ones.drive_id.values)\n",
    "# print(ones[['drive_id','offense','play_type']].head(5))\n",
    "\n",
    "# go ahead and fix these\n",
    "df = df.rename(columns={'offense':'wrong_offense','defense':'wrong_defense'})\n",
    "df['offense'] = np.where(((df['drive_id'].isin(targ_ids))&(df['play_type']=='Timeout')),df['defense'],df['offense'])\n",
    "df['defense'] = np.where(((df['drive_id'].isin(targ_ids))&(df['play_type']=='Timeout')),df['offense'],df['defense'])\n",
    "\n",
    "# print(len(df.loc[df['drive_id'].isin(targ_ids)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos = mos.loc[mos.drive_id.isin(list(gb.loc[gb.offense!=1].drive_id.values))]\n",
    "\n",
    "#mark these that I havent fixed with a 1\n",
    "mos_ids = list(mos.drive_id.values)\n",
    "\n",
    "df['multiple_offenses'] = np.where(df['drive_id'].isin(mos_ids),1,0)\n",
    "\n",
    "# mos['last_offense'] = mos['offense'].shift(1)\n",
    "# mos['last_di'] = mos['drive_id'].shift(1).fillna(0).astype(int)\n",
    "# # mark every time the offense switches with a 1\n",
    "# mos['off_switch'] = np.where(((mos['offense']!=mos['last_offense'])&(mos['drive_id']==mos['last_di'])),1,0)\n",
    "\n",
    "\n",
    "# # mos[['drive_id','offense','tr_game','play_type','off_switch','play_text']]\n",
    "\n",
    "# len(mos.loc[(mos.play_type=='Kickoff')&(mos.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some objectives\n",
    "\n",
    "1) fix \"uncategorized\" play type  \n",
    "2) aggregate, clean, validate all play types  \n",
    "3) fix \"uncategorized\" drive results  \n",
    "4) aggregate, clean, validate all drive results  \n",
    "5) compare play types to drive results to make sure they match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing uncategorized play types\n",
    "\n",
    "base = r'^{}'\n",
    "expr = '(?=.*{})'\n",
    "words = ['End', 'of', 'Half']\n",
    "end_period = base.format(''.join(expr.format(w) for w in words))\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains(end_period,regex=True)), 'play_type'] = 'End of Half'\n",
    "\n",
    "words = ['End', 'of', 'Quarter']\n",
    "end_period = base.format(''.join(expr.format(w) for w in words))\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains(end_period,regex=True)), 'play_type'] = 'End of Half'\n",
    "\n",
    "words = ['fumbled','run', 'for']\n",
    "fumbles = base.format(''.join(expr.format(w) for w in words))\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains(fumbles,regex=True)), 'play_type'] = 'Fumble Recovery (Own)'\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains('Penalty')), 'play_type'] = 'Penalty'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many uncategorized plays are left?\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# fix individual\n",
    "# many of the ones left are fumbles, and then something\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains('recovered by UTEP Aaron Jones')), 'play_type'] = 'Penalty'\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains('intercepted')), 'play_type'] = 'Pass Interception'\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains('SAFETY')), 'play_type'] = 'Safety'\n",
    "\n",
    "words = ['fumbled','pass', 'complete']\n",
    "complete = base.format(''.join(expr.format(w) for w in words))\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains(complete,regex=True)), 'play_type'] = 'Pass Completion'\n",
    "\n",
    "words = ['TD','punt', 'blocked']\n",
    "td_pb = base.format(''.join(expr.format(w) for w in words))\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains(td_pb,regex=True)), 'play_type'] = 'Blocked Punt Touchdown'\n",
    "\n",
    "\n",
    "words = ['run','for', 'TD']\n",
    "run_td = base.format(''.join(expr.format(w) for w in words))\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains(run_td,regex=True)), 'play_type'] = 'Rushing Touchdown'\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.down==4), 'play_type'] = 'Punt'\n",
    "\n",
    "words = ['return','for', 'TD']\n",
    "fumb_td = base.format(''.join(expr.format(w) for w in words))\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains(fumb_td,regex=True)), 'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&df.play_text.str.contains('return for'), 'play_type'] = 'Fumble Recovery (Opponent)'\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&df.play_text.str.contains('run for'), 'play_type'] = 'Rush'\n",
    "\n",
    "print(\"how many uncategorized plays are left?\")\n",
    "print(len(df.loc[df['play_type']=='Uncategorized']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: play_text, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['play_type']=='Uncategorized'].play_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the next objective is to aggregate/clean all play types. I can mostly do that at this point. However, I'd like to try to account for every possession transition first, because this helps identify things like which team recovered a fumble. The only time when two consecutive drive ids should have the same offense is 1) end of half and 2) muffed punts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = df.groupby(['game_id','drive_id','alt_drive_id'])['offense','drive_result','multiple_offenses'].last().reset_index()\n",
    "gb['alt_drive_id'] = gb['alt_drive_id'].astype(int)\n",
    "gb = gb.sort_values(by=['game_id','alt_drive_id'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb['last_offense'] = gb['offense'].shift(1)\n",
    "gb['prev_drive_result'] = gb['drive_result'].shift(1)\n",
    "gb.loc[gb['alt_drive_id']==1, 'last_offense'] = 'Start of Game'\n",
    "gb.loc[gb['alt_drive_id']==1, 'prev_drive_result'] = 'Start of Game'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5078\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5079\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \"\"\"\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5062\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 5063\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute '_name'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-c75d340719b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'offense'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_offense'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prev_drive_result'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'END OF HALF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prev_drive_result'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'END OF HALF TD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2899\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2901\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2902\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2903\u001b[0m             \u001b[0;31m# The TypeError correctly catches non hashable \"key\" (e.g. list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3060\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3061\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3062\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3063\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_as_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_box_item_values\u001b[0;34m(self, key, values)\u001b[0m\n\u001b[1;32m   3345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3346\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3347\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_col_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_box_col_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_box_col_values\u001b[0;34m(self, values, items)\u001b[0m\n\u001b[1;32m   3352\u001b[0m         \"\"\"\n\u001b[1;32m   3353\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5078\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5079\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5081\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bad = gb.loc[(gb['offense'] == gb['last_offense'])]\n",
    "print(len(bad))\n",
    "bad = bad.loc[gb['prev_drive_result'] != 'END OF HALF']\n",
    "bad = bad.loc[gb['prev_drive_result'] != 'END OF HALF TD']\n",
    "print(len(bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's examine some of these problems\n",
    "\n",
    "bad_ids = list(bad.drive_id.unique())\n",
    "bdf = df.loc[df.drive_id.isin(bad_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bdf.groupby(['drive_result'])['down'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looked up the kicker on this one play -- it was a muffed kickoff\n",
    "df.loc[df.drive_result=='NETRCV', 'drive_result'] = 'KICKOFF FUMBLE RECOVERY (KICK TEAM)'\n",
    "\n",
    "# looked up this guy too\n",
    "df.loc[df.id==400934568104999803, 'drive_result'] = 'ONSIDE KICK RECOVERY (KICK TEAM)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the biggie here is identifying muffed punts\n",
    "punts = bdf.loc[(bdf.play_type=='Punt')|(bdf.play_text.str.contains('punt'))]\n",
    "muffed_punts = punts.loc[punts.play_text.str.contains('fumble')]\n",
    "\n",
    "muff_ids = list(muffed_punts.drive_id.unique())\n",
    "df.loc[df.drive_id.isin(muff_ids), 'drive_result'] = 'MUFFED PUNT (PUNT TEAM REC)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop drives that are the last drive in the half.\n",
    "end_of_half = bdf.loc[bdf.play_text=='End of 2nd Quarter']\n",
    "eoh_ids = list(end_of_half.drive_id.values)\n",
    "bad = bad.loc[~bad.drive_id.isin(eoh_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = list(bad.drive_id.unique())\n",
    "bdf = df.loc[df.drive_id.isin(bad_ids)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf.groupby(['drive_result'])['down'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for pt in list(bdf.loc[bdf.multiple_offenses==1].play_text.values):\n",
    "#     print(pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these plays don't have anything important\n",
    "nah_part_2 = ['End Period','End of Half','End of Game']\n",
    "bs = df.loc[df.play_type.isin(nah_part_2)&df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD')]\n",
    "del bs\n",
    "df = df.loc[~df.play_type.isin(nah_part_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize\n",
    "df.loc[df.play_type=='Interception', 'play_type'] = 'Pass Interception'\n",
    "df.loc[df.play_type=='Pass Interception Return', 'play_type'] = 'Pass Interception'\n",
    "\n",
    "df.loc[df.play_type=='Pass Reception', 'play_type'] = 'Pass Completion'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = df.groupby(['play_type'])['down'].count()\n",
    "gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) fix uncategorized play type (check)  \n",
    "2) clean/validate/aggregate play types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with the top: blocked FG. make sure none are touchdowns\n",
    "bfg = df.loc[(df.play_type=='Blocked Field Goal')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "print(\"There are a few!\")\n",
    "print(len(bfg))\n",
    "print(\"All are defensive scores\")\n",
    "\n",
    "df.loc[((df.play_type=='Blocked Field Goal')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))), 'play_type']='Blocked Field Goal Touchdown'\n",
    "\n",
    "del bfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing for blocked punt\n",
    "bp = df.loc[(df.play_type=='Blocked Punt')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "print(len(bp))\n",
    "print(\"punts to fix\")\n",
    "\n",
    "# pretty safe to assume these are all defensive\n",
    "df.loc[((df.play_type=='Blocked Punt')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))), 'play_type']='Blocked Punt Touchdown'\n",
    "\n",
    "print('fixed')\n",
    "del bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Fumble Recovery (Opponent)\n",
    "fro = df.loc[(df.play_type=='Fumble Recovery (Opponent)')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "print(len(fro))\n",
    "print(\"fumble recoveries that were TDs\")\n",
    "\n",
    "# i think all but 1 or two are defensive, don't know a good way to sort those out\n",
    "df.loc[(df.play_type=='Fumble Recovery (Opponent)')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD')), 'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "del fro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fro = df.loc[(df.play_type=='Fumble Recovery (Own)')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "print(len(fro))\n",
    "print(\"own fumble recoveries that were TDs\")\n",
    "\n",
    "df.loc[(df.play_type=='Fumble Recovery (Own)')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD')), 'play_type'] = 'Rushing Touchdown'\n",
    "\n",
    "# missed field goal returns are gucci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide 'pass' play type into subcategories\n",
    "pa = df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "#TTD is a team abbreviation that gets picked up\n",
    "pa = pa.loc[(~pa.play_text.str.contains('intercepted|Intercepted|INTERCEPTED'))&\n",
    "            (~pa.play_text.str.contains('fumbled'))&\n",
    "            (~pa.play_text.str.contains('Penalty|PENALTY|penalty'))&\n",
    "            (~pa.play_text.str.contains('TTD'))]\n",
    "\n",
    "pa_ids = list(pa.id.values)\n",
    "\n",
    "df.loc[df.id.isin(pa_ids), 'play_type'] = 'Passing Touchdown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "pa = pa.loc[((pa.play_text.str.contains('Penalty|PENALTY|penalty'))&\n",
    "        (pa.play_text.str.contains('ACCEPTED|accepted|Accepted')))]\n",
    "\n",
    "pa_ids = list(pa.id.values)\n",
    "df.loc[df.id.isin(pa_ids), 'play_type'] = 'Penalty'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "pa = pa.loc[pa.play_text.str.contains('intercepted|Intercepted|INTERCEPTED')]\n",
    "\n",
    "pa_ids = list(pa.id.values)\n",
    "df.loc[df.id.isin(pa_ids), 'play_type'] = 'Interception Return Touchdown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "pa = pa.loc[pa.play_text.str.contains('fumbled')]\n",
    "\n",
    "fbr_ids = list(pa.loc[pa.drive_result=='FUMBLE RETURN TD'].id.values)\n",
    "df.loc[df.id.isin(fbr_ids),'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "fbr_ids = list(pa.loc[pa.drive_result=='PASSING TD'].id.values)\n",
    "df.loc[df.id.isin(fbr_ids),'play_type'] = 'Passing Touchdown'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "pa = pa.loc[pa.play_text.str.contains('fumbled')]\n",
    "\n",
    "# slightly guessing but i think it's right\n",
    "\n",
    "ptd = pa.loc[pa.play_text.str.contains('pass complete')]\n",
    "ptd_ids = list(ptd.id.values)\n",
    "df.loc[df.id.isin(ptd_ids), 'play_type'] = 'Passing Touchdown'\n",
    "\n",
    "pa = df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "pa_ids = list(pa.id.values)\n",
    "df.loc[df.id.isin(pa_ids), 'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "del pa\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change rushing tds categorized as 'rush' to rushing tds\n",
    "rush = df.loc[(df.play_type=='Rush')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "# for penalties that don't stop a touchdown\n",
    "words = ['0 yard','accepted']\n",
    "pens = base.format(''.join(expr.format(w) for w in words))\n",
    "rush_tds = rush.loc[(~rush.play_text.str.contains('Penalty|PENALTY|penalty')) | (rush.play_text.str.contains('declined|DECLINED') | (rush.play_text.str.contains(pens)))]\n",
    "rush_tds = rush_tds.loc[~rush.play_text.str.contains('fumbled')]\n",
    "rtd_ids = list(rush_tds.id.values)\n",
    "df.loc[df.id.isin(rtd_ids),'play_type'] = 'Rushing Touchdown'\n",
    "\n",
    "del rush_tds\n",
    "# rtd_ids = list(rush_tds.id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some fumble 6 rushes that need to be categorized as such\n",
    "\n",
    "rush = df.loc[(df.play_type=='Rush')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "words = ['fumbled','returned by']\n",
    "ftds = base.format(''.join(expr.format(w) for w in words))\n",
    "fumble_tds = rush.loc[(rush.play_text.str.contains(ftds))]\n",
    "\n",
    "fbtd_ids = list(fumble_tds.id.values)\n",
    "df.loc[df.id.isin(fbtd_ids),'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "words = ['fumbled','loss of']\n",
    "ftds = base.format(''.join(expr.format(w) for w in words))\n",
    "fumble_tds = rush.loc[(rush.play_text.str.contains(ftds))]\n",
    "\n",
    "fbtd_ids = list(fumble_tds.id.values)\n",
    "df.loc[df.id.isin(fbtd_ids),'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "# subset of fumble 6s always say 'to the {other team} 0' \n",
    "words = ['to the','0']\n",
    "ftds = base.format(''.join(expr.format(w) for w in words))\n",
    "fumble_tds = rush.loc[(rush.play_text.str.contains(ftds))]\n",
    "\n",
    "fbtd_ids = list(fumble_tds.id.values)\n",
    "df.loc[df.id.isin(fbtd_ids),'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "df.loc[((df.play_type=='Rush')&(df.play_text.str.contains('penalty|PENALTY|Penalty'))), 'play_type'] = 'Penalty'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard to determine which fumbles go for offensive TD vs defensive TD from just play text\n",
    "# lean on drive result\n",
    "\n",
    "df.loc[(df.play_type=='Rush')&(df.drive_result=='RUSHING TD'), 'play_type'] = 'Rushing Touchdown'\n",
    "\n",
    "df.loc[(df.play_type=='Rush')&(df.drive_result=='FUMBLE RETURN TD'), 'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "# i verified these\n",
    "df.loc[((df.play_type=='Rush')&(df.yard_line>90)&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))), 'play_type'] = 'Rushing Touchdown'\n",
    "\n",
    "# rest seem to be defensive. might be one or two offensive that leaked through\n",
    "df.loc[((df.play_type=='Rush')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))), 'play_type'] = 'Fumble Return Touchdown'\n",
    "                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = ['Pass','Rush']\n",
    "sa = df.loc[(df.play_type.isin(clean))&(df.play_text.str.contains('Safety|safety|SAFETY'))]\n",
    "sa_ids = list(sa.id.values)\n",
    "print(len(sa))\n",
    "df.loc[df.id.isin(sa_ids), 'play_type'] = 'Safety'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide up the \"pass\" play type\n",
    "df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('incomplete')), 'play_type'] = 'Pass Incompletion'\n",
    "df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('complete')), 'play_type'] = 'Pass Completion'\n",
    "df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('intercepted')), 'play_type'] = 'Interception'\n",
    "df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('sacked')), 'play_type'] = 'Sack'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = df.loc[(df.play_type=='Pass')]\n",
    "\n",
    "# only things left are fumbles\n",
    "# lean on drive result, tough to know who recovered fumble \n",
    "\n",
    "li = ['FUMBLE','Uncategorized']\n",
    "\n",
    "fro = pa.loc[~pa.drive_result.isin(li)]\n",
    "fro_ids = list(fro.id.values)\n",
    "df.loc[df.id.isin(fro_ids), 'play_type'] = 'Fumble Recovery (Own)'\n",
    "\n",
    "fum = pa.loc[pa.drive_result == 'FUMBLE']\n",
    "fum_ids = list(fum.id.values)\n",
    "df.loc[df.id.isin(fum_ids), 'play_type'] = 'Fumble Recovery (Opponent)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncategorized\n",
    "pa = df.loc[(df.play_type=='Pass')]\n",
    "\n",
    "df.loc[df.id==253370030087, 'play_type'] = 'Fumble Recovery (Opponent)'\n",
    "df = df.loc[df.id != 262590259175]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = ['FUMBLE RETURN TD','FUMBLE TD']\n",
    "\n",
    "td = df.loc[(df.play_type == 'Sack') & (df.play_text.str.contains('fumbled')) & (df.drive_result.isin(tds))]\n",
    "td_ids = list(td.id.values)\n",
    "\n",
    "df.loc[df.id.isin(td_ids), 'play_type'] = 'Fumble Return Touchdown'\n",
    "del tds\n",
    "\n",
    "sa = df.loc[(df.play_type == 'Sack') & (df.play_text.str.contains('fumbled'))]\n",
    "\n",
    "li = ['FUMBLE','Uncategorized']\n",
    "\n",
    "fro = sa.loc[~sa.drive_result.isin(li)]\n",
    "fro_ids = list(fro.id.values)\n",
    "df.loc[df.id.isin(fro_ids), 'play_type'] = 'Fumble Recovery (Own)'\n",
    "\n",
    "fum = sa.loc[sa.drive_result == 'FUMBLE']\n",
    "fum_ids = list(fum.id.values)\n",
    "df.loc[df.id.isin(fum_ids), 'play_type'] = 'Fumble Recovery (Opponent)'\n",
    "\n",
    "sa = df.loc[(df.play_type=='Sack')&(df.play_text.str.contains('fumbled'))]\n",
    "\n",
    "# only recovery by the defense\n",
    "df.loc[df.id==322450120161, 'play_type'] = 'Fumble Recovery (Opponent)'\n",
    "\n",
    "df.loc[(df.play_type=='Sack')&(df.play_text.str.contains('fumbled')), 'play_type'] = 'Fumble Recovery (Own)'\n",
    "\n",
    "del sa\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = df.loc[(df.play_type == 'Pass Completion') & (df.play_text.str.contains('fumbled')) & (df.drive_result=='FUMBLE TD')]\n",
    "\n",
    "words = ['to the','0']\n",
    "ftds = base.format(''.join(expr.format(w) for w in words))\n",
    "fumble_tds = td.loc[(td.play_text.str.contains(ftds))]\n",
    "\n",
    "fbtd_ids = list(fumble_tds.id.values)\n",
    "df.loc[df.id.isin(fbtd_ids),'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "# rest are just fumble recoveries\n",
    "td = df.loc[(df.play_type == 'Pass Completion') & (df.play_text.str.contains('fumbled')) & (df.drive_result=='FUMBLE TD')]\n",
    "td_ids = list(td.id.values)\n",
    "df.loc[df.id.isin(td_ids),'play_type'] = 'Fumble Recovery (Opponent)'\n",
    "\n",
    "del td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.play_type == 'Pass Completion') & (df.play_text.str.contains('fumbled')) & (df.drive_result=='FUMBLE RETURN TD'), 'play_type'] = 'Passing Touchdown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only defensive returned touchdown in set\n",
    "df.loc[df.id==272932393004, 'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "pa = df.loc[(df.play_type == 'Pass Completion') & (df.play_text.str.contains('fumbled'))]\n",
    "\n",
    "fumbles = pa.loc[pa.drive_result=='Fumble']\n",
    "\n",
    "fum_ids = list(fumbles.id.values)\n",
    "df.loc[df.id.isin(fum_ids), 'play_type'] = 'Fumble Recovery (Opponent)'\n",
    "\n",
    "pa = df.loc[(df.play_type == 'Pass Completion') & (df.play_text.str.contains('fumbled')) & (df.drive_result == 'Uncategorized')]\n",
    "\n",
    "\n",
    "\n",
    "# individual fixes\n",
    "fr_own = ['UTEP','Arkansas State','Colorado','Notre Dame','Iowa State','Penn St.','TCU','Florida Atlantic']\n",
    "\n",
    "fr_o = pa.loc[pa.offense.isin(fr_own)]\n",
    "fr_o_ids = list(fr_o.id.values)\n",
    "\n",
    "df.loc[df.id.isin(fr_o_ids), 'play_type'] = 'Fumble Recovery (Own)'\n",
    "\n",
    "\n",
    "fr_opp = pa.loc[~pa.offense.isin(fr_own)]\n",
    "fr_opp_ids = list(fr_opp.id.values)\n",
    "df.loc[df.id.isin(fr_opp_ids), 'play_type'] = 'Fumble Recovery (Opponent)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.play_type == 'Pass Completion') & (df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD')), 'play_type']='Passing Touchdown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfg = df.loc[(df.play_type=='Field Goal Missed')&(df.play_text.str.contains('Blocked|BLOCKED|blocked'))]\n",
    "\n",
    "bfg_td = bfg.loc[bfg.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD')]\n",
    "\n",
    "bfg_td_ids = list(bfg_td.id.values)\n",
    "\n",
    "bfg = bfg.loc[~bfg.id.isin(bfg_td_ids)]\n",
    "bfg_ids = list(bfg.id.values)\n",
    "\n",
    "df.loc[df.id.isin(bfg_td_ids), 'play_type'] = 'Blocked Field Goal Touchdown'\n",
    "df.loc[df.id.isin(bfg_ids), 'play_type'] = 'Blocked Field Goal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now punts\n",
    "\n",
    "bfg = df.loc[(df.play_type=='Punt')&(df.play_text.str.contains('Blocked|BLOCKED|blocked'))]\n",
    "\n",
    "bfg_td = bfg.loc[bfg.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD')]\n",
    "\n",
    "\n",
    "bfg_td_ids = list(bfg_td.id.values)\n",
    "\n",
    "bfg = bfg.loc[~bfg.id.isin(bfg_td_ids)]\n",
    "bfg_ids = list(bfg.id.values)\n",
    "\n",
    "df.loc[df.id.isin(bfg_td_ids), 'play_type'] = 'Blocked Punt Touchdown'\n",
    "df.loc[df.id.isin(bfg_ids), 'play_type'] = 'Blocked Punt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# punt return touchdowns\n",
    "\n",
    "prtd = df.loc[(df.play_type=='Punt')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "# check for penalties\n",
    "words = ['penalty','accepted']\n",
    "called_back = base.format(''.join(expr.format(w) for w in words))\n",
    "prtd = prtd.loc[~prtd.play_text.str.contains(called_back, regex=True)]\n",
    "\n",
    "prtd = prtd.loc[~prtd.play_text.str.contains('fumbled|TTD')]\n",
    "prtd = prtd.loc[~prtd.play_text.str.contains('NO PLAY')]\n",
    "\n",
    "prtd_ids = list(prtd.id.values)\n",
    "\n",
    "df.loc[df.id.isin(prtd_ids), 'play_type'] = 'Punt Return Touchdown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lastly, fix declined penalties\n",
    "# seem to be mostly right except some rushes\n",
    "# decline = df.loc[(df.play_type=='Penalty')&(df.play_text.str.contains('declined|DECLINED'))]\n",
    "# print(len(decline))\n",
    "\n",
    "# rush = decline.loc[(decline.play_text.str.contains('rush|rushed'))&~(decline.play_text.str.contain)]\n",
    "\n",
    "# comp = decline.loc[decline.play_text.str.contains('pass complete')]\n",
    "\n",
    "# incomp = decline.loc[decline.play_text.str.contains('incomplete')]\n",
    "\n",
    "# for pt in list(decline.play_text.values):\n",
    "#     print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) fix \"uncategorized\" play type (check)\n",
    "2) aggregate, clean, validate all play types (check)\n",
    "3) fix \"uncategorized\" drive results\n",
    "4) aggregate, clean, validate all drive results\n",
    "5) compare play types to drive results to make sure they match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = df.groupby(['play_type'])['down'].count()\n",
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make expected drive results to compare to given drive result data\n",
    "pass_tds = df.loc[df.play_type == 'Passing Touchdown']\n",
    "ptd_ids = list(pass_tds.drive_id.unique())\n",
    "del pass_tds\n",
    "\n",
    "rush_tds = df.loc[df.play_type == 'Rushing Touchdown']\n",
    "rtd_ids = list(rush_tds.drive_id.unique())\n",
    "del rush_tds\n",
    "\n",
    "fgg = df.loc[df.play_type == 'Field Goal Good']\n",
    "fgg_ids = list(fgg.drive_id.unique())\n",
    "del fgg\n",
    "\n",
    "fgm = df.loc[df.play_type == 'Field Goal Missed']\n",
    "fgm_ids = list(fgm.drive_id.unique())\n",
    "del fgm\n",
    "\n",
    "sf = df.loc[df.play_type == 'Safety']\n",
    "sf_ids = list(sf.drive_id.unique())\n",
    "del sf\n",
    "\n",
    "intn = df.loc[df.play_type == 'Pass Interception']\n",
    "int_ids = list(intn.drive_id.unique())\n",
    "del intn\n",
    "\n",
    "fropp = df.loc[df.play_type == 'Fumble Recovery (Opponent)']\n",
    "fropp_ids = list(fropp.drive_id.unique())\n",
    "del fropp\n",
    "\n",
    "ftd = ['Missed Field Goal Return Touchdown','Blocked Field Goal Touchdown']\n",
    "fg_td = df.loc[df.play_type.isin(ftd)]\n",
    "ftd_ids = list(fg_td.drive_id.unique())\n",
    "del fg_td\n",
    "\n",
    "prtd = ['Punt Return Touchdown','Blocked Punt Touchdown']\n",
    "punt_td = df.loc[df.play_type.isin(prtd)]\n",
    "prtd_ids = list(punt_td.drive_id.unique())\n",
    "del punt_td\n",
    "\n",
    "punts = df.loc[df.play_type =='Punt']\n",
    "punt_ids = list(punts.drive_id.unique())\n",
    "del punts\n",
    "\n",
    "df['exp_drive_result'] = np.nan\n",
    "\n",
    "drs = [ptd_ids, rtd_ids,fgg_ids,fgm_ids,sf_ids,int_ids,fropp_ids,ftd_ids,prtd_ids,punt_ids]\n",
    "\n",
    "df.loc[df.drive_id.isin(ptd_ids), 'exp_drive_result'] = 'PASSING TD'\n",
    "df.loc[df.drive_id.isin(rtd_ids), 'exp_drive_result'] = 'RUSHING TD'\n",
    "df.loc[df.drive_id.isin(fgg_ids), 'exp_drive_result'] = 'FG GOOD'\n",
    "df.loc[df.drive_id.isin(fgm_ids), 'exp_drive_result'] = 'FG MISSED'\n",
    "df.loc[df.drive_id.isin(sf_ids), 'exp_drive_result'] = 'SF'\n",
    "df.loc[df.drive_id.isin(int_ids), 'exp_drive_result'] = 'INT'\n",
    "df.loc[df.drive_id.isin(fropp_ids), 'exp_drive_result'] = 'FUMBLE'\n",
    "df.loc[df.drive_id.isin(ftd_ids), 'exp_drive_result'] = 'FG MISSED TD'\n",
    "df.loc[df.drive_id.isin(prtd_ids), 'exp_drive_result'] = 'PUNT RETURN TD'\n",
    "df.loc[df.drive_id.isin(punt_ids), 'exp_drive_result'] = 'PUNT'\n",
    "\n",
    "# print(len(df))\n",
    "# most = df.dropna(subset=['exp_drive_result'])\n",
    "# print(len(most))\n",
    "\n",
    "# del most\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to clean/validate/aggregate drive results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = df.groupby(['drive_result'])['down'].count()\n",
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ = df.loc[(df.drive_result == 'PUNT') & (df.play_type=='Punt Return Touchdown')]\n",
    "targ_ids = list(targ.drive_id.values)\n",
    "\n",
    "df.loc[df.drive_id.isin(targ_ids), 'drive_result'] = 'PUNT RETURN TD'\n",
    "\n",
    "# muffed punts recovered by return team\n",
    "\n",
    "targ = df.loc[(df.exp_drive_result=='FUMBLE')&(df.drive_result == 'PUNT') & (df.play_type=='Punt')]\n",
    "targ_ids = list(targ.drive_id.values)\n",
    "df.loc[df.drive_id.isin(targ_ids), 'drive_result'] = 'PUNT'\n",
    "\n",
    "# safeties that are called punts because of the punt afterward\n",
    "\n",
    "targ = df.loc[(df.exp_drive_result=='PUNT')&(df.drive_result == 'SF')]\n",
    "targ_ids = list(targ.drive_id.values)\n",
    "df.loc[df.drive_id.isin(targ_ids), 'exp_drive_result'] = 'SF'\n",
    "\n",
    "# weird \n",
    "targ = df.loc[(df.exp_drive_result=='FG GOOD')&(df.drive_result == 'FG MISSED') & (df.play_type=='Field Goal Good')]\n",
    "targ_ids = list(targ.drive_id.values)\n",
    "df.loc[df.drive_id.isin(targ_ids), 'drive_result'] = 'FG GOOD'\n",
    "\n",
    "# counting punt returns and blocked punts in same category\n",
    "targ = df.loc[(df.drive_result == 'PUNT')&(df.exp_drive_result=='PUNT RETURN TD')& (df.play_type=='Blocked Punt Touchdown')]\n",
    "targ_ids = list(targ.drive_id.values)\n",
    "df.loc[df.drive_id.isin(targ_ids), 'drive_result'] = 'PUNT RETURN TD'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = ['PASSING TD','RUSHING TD','FG GOOD','FG MISSED','SF','INT','FUMBLE','FG MISSED TD','PUNT RETURN TD','PUNT']\n",
    "\n",
    "comp = df.loc[df.drive_result.isin(compare)].copy()\n",
    "\n",
    "comp['match'] = np.where(comp['drive_result']==comp['exp_drive_result'],1,0)\n",
    "\n",
    "print(\"What pct of drives sampled match our expected drive result?\")\n",
    "print(str(np.round((comp.match.sum()/len(comp))*100,1))+'%')\n",
    "\n",
    "comp['exp_drive_result'] = comp['exp_drive_result'].fillna(comp['drive_result'])\n",
    "\n",
    "\n",
    "# TTD abbreviation threw everything off\n",
    "comp['exp_drive_result'] = np.where(comp['exp_drive_result'].str.contains('TTD'),comp['drive_result'],comp['exp_drive_result'])\n",
    "\n",
    "comp['match'] = np.where(comp['drive_result']==comp['exp_drive_result'],1,0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = comp.loc[comp.match==0].copy()\n",
    "\n",
    "print(wrong[['drive_result','exp_drive_result','play_type','drive_id']])\n",
    "for pt in list(wrong.play_text.values):\n",
    "    print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop games that are clearly off\n",
    "gb = wrong.groupby(['game_id'])['drive_result'].count()\n",
    "gb = gb.loc[gb > 15]\n",
    "bad_games = list(gb.index.values)\n",
    "\n",
    "df = df.loc[~df.game_id.isin(bad_games)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"intercepted\" - interceptions\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb = df.groupby(['game_id','drive_id'])['offense','tr_game'].first().reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
