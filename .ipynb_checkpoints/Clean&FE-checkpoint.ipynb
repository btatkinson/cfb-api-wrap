{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "import datetime\n",
    "gc.collect()\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:32<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2031893, 41)\n",
      "2031893 plays were loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load play by play & drive data\n",
    "years = list(range(2005, int(datetime.datetime.now().year)))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year in tqdm(years):\n",
    "    path = './output/'+str(year)+'/'+str(year)+'_pbp.csv'\n",
    "    sea_df = pd.read_csv(path)\n",
    "    \n",
    "    drive_path = './output/'+str(year)+'/'+str(year)+'_drives.csv'\n",
    "    drive_df = pd.read_csv(drive_path)\n",
    "    \n",
    "    drive_df = drive_df.rename(columns={'id':'drive_id'})\n",
    "    \n",
    "    sea_df = pd.merge(left=sea_df, right=drive_df, how='left', on=['drive_id','drive_id'])\n",
    "    df = pd.concat([df,sea_df])\n",
    "\n",
    "num_plays = len(df)\n",
    "print(df.shape)\n",
    "print(str(num_plays) + \" plays were loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offense_x seems to be correct while offense_y is not\n",
    "\n",
    "df = df.drop(columns=['defense_y','defense_conference_y','offense_y','offense_conference_y'])\n",
    "\n",
    "df = df.rename(columns={'defense_x':'defense','defense_conference_x':'defense_conference','offense_x':'offense','offense_conference_x':'offense_conference'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix yard_line, it's w.r.t the home team\n",
    "df = df.rename(columns={'yard_line':'wrong_yardline'})\n",
    "\n",
    "df['yard_line'] = np.where(df['offense']==df['home'],df['wrong_yardline'],100-df['wrong_yardline'])\n",
    "# print(df[['home','offense','yard_line','wrong_yardline']].head(50))\n",
    "df = df.drop(columns=['wrong_yardline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Teams\n",
    "\n",
    "I'll do special teams and overtimes in future work. Right now, keeping it simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2031893\n",
      "1871043\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "nah = ['2pt Conversion','Kickoff','Kickoff Return (Offense)','Kickoff Return Touchdown',\n",
    "      'Offensive 1pt Safety','Defensive 2pt Conversion','Extra Point Good','Extra Point Missed']\n",
    "\n",
    "df = df.loc[~df.play_type.isin(nah)]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1864121\n"
     ]
    }
   ],
   "source": [
    "# also drop overtime\n",
    "\n",
    "df = df.loc[(df.period > 0) & (df.period <= 4)]\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clock\n",
    "\n",
    "Clock data is unreliable because maybe 25% of the games have only have one time for each play, and that time is when the drive started. I played with trying to predict time per play based on play type, but the data was very messy. So I decided to get the total time of each drive, and then assume each play took the same amount of time. EPA shouldn't be significantly affected most of the time, i.e. a 70 yard pass will be considered a good play no matter what. The only time it might have an adverse effect is toward the end of a game, when seconds matter. I think that in college football, when the clock stops for a first down, and incompletions, that all pass plays probably do take a somewhat similar amount of time. Drives in this situation will consist mostly of the same play type, and plays of the same play type likely take similar amounts of time. I'll compare it to the clock data I do have to make sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix clock data first so drives can be figured out\n",
    "time_cols = ['clock.minutes','clock.seconds','start_time.minutes','start_time.seconds',\n",
    "            'end_time.minutes','end_time.seconds']\n",
    "for tc in time_cols:\n",
    "    df[tc] = df[tc].fillna(0)\n",
    "\n",
    "# get time remaining in game\n",
    "df['tr_game'] = (4-df['period']) * 900 + (df['clock.minutes'] * 60) + df['clock.seconds']\n",
    "df['tr_half'] = np.where(df['period']>2,df['tr_game'], df['tr_game']-1800)\n",
    "\n",
    "df = df.drop(columns=['clock.minutes','clock.seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill empties\n",
    "df['elapsed.minutes'] = df['elapsed.minutes'].copy().fillna(0)\n",
    "df['elapsed.seconds'] = df['elapsed.seconds'].copy().fillna(0)\n",
    "df['drive_time'] = 60*df['elapsed.minutes'] + df['elapsed.seconds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8969\n",
      "275461\n",
      "146.12538980109707\n"
     ]
    }
   ],
   "source": [
    "# a lot of those drive times are negative... and other problems. so here's an alt drive time\n",
    "# alt clock\n",
    "\n",
    "# these get the start and end time of every drive\n",
    "maxs = df.groupby(['game_id','drive_id'])['tr_game'].max().reset_index()\n",
    "mins = df.groupby(['game_id','drive_id'])['tr_game'].min().reset_index()\n",
    "maxs = maxs.rename(columns={'tr_game':'drive_start'})\n",
    "mins = mins.rename(columns={'tr_game':'drive_end'})\n",
    "\n",
    "# sometimes the drive end time is the same as the drive start. in that case, I use the next drive start\n",
    "maxs = maxs.sort_values(by=['game_id','drive_start'],ascending=False)\n",
    "next_max = maxs.groupby(['game_id'])['drive_start'].shift(-1)\n",
    "next_max = pd.Series(next_max, name='next_drive_start')\n",
    "new_max = pd.concat([maxs, next_max], axis=1)\n",
    "new_max['next_drive_start'] = new_max['next_drive_start'].fillna(0)\n",
    "\n",
    "# sometimes (rarely, 2%ish of the time) both the next drive start and the drive end are the same as the drive start\n",
    "# in that case, as a last resort, i use the next drive end time. \n",
    "# i'm fairly sure most of the time it's when a timeout or something divides the same drive into two.\n",
    "# i can explore this more in future work\n",
    "mins = mins.sort_values(by=['game_id','drive_end'],ascending=False)\n",
    "next_min = mins.groupby(['game_id'])['drive_end'].shift(-1)\n",
    "next_min = pd.Series(next_min, name='next_drive_end')\n",
    "new_min = pd.concat([mins, next_min], axis=1)\n",
    "new_min['next_drive_end'] = new_min['next_drive_end'].fillna(0)\n",
    "new_min = new_min.drop(columns='game_id')\n",
    "times = pd.merge(left=new_max,right=new_min,on=['drive_id','drive_id'],how='left')\n",
    "\n",
    "\n",
    "# attempt 1 (works on ~95.5% of data)\n",
    "times['drive_time_1'] = times['drive_start']-times['next_drive_start']\n",
    "# plan B (95.8% of data)\n",
    "times['drive_time'] = np.where(times['drive_time_1']>0,times['drive_time_1'],(times['drive_start']-times['drive_end']))\n",
    "# last resort (didn't implement)\n",
    "# times['drive_time'] = np.where(times['drive_time_2']>0,times['drive_time_2'],(times['drive_start']-times['next_drive_end']))\n",
    "\n",
    "not_good = times.loc[times.drive_time<=0]\n",
    "print(len(not_good))\n",
    "\n",
    "good = times.loc[times.drive_time>0]\n",
    "print(len(good))\n",
    "\n",
    "print(good.drive_time.mean())\n",
    "\n",
    "times = times[['drive_id','drive_time']]\n",
    "times = times.rename(columns={'drive_time':'alt_drive_time'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=df,right=times,how='left',on=['drive_id','drive_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1844449\n",
      "correlation between primary and approximate drive time\n",
      "                    drive_time  alt_drive_time  correct_drive_time\n",
      "drive_time            1.000000        0.855643            0.991407\n",
      "alt_drive_time        0.855643        1.000000            0.863110\n",
      "correct_drive_time    0.991407        0.863110            1.000000\n"
     ]
    }
   ],
   "source": [
    "# longest drive in CFB history is 882. so need to drop anything above 900\n",
    "# also drop anything below or equal to 0\n",
    "\n",
    "df['correct_time_1'] = np.where(df['drive_time'] > 0, df['drive_time'], df['alt_drive_time'])\n",
    "\n",
    "df = df.loc[df['correct_time_1'] > 0]\n",
    "\n",
    "df['correct_drive_time'] = np.where(df['drive_time'] < 900, df['drive_time'], df['alt_drive_time'])\n",
    "\n",
    "df = df.loc[df['correct_drive_time'] < 900]\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "print(\"correlation between primary and approximate drive time\")\n",
    "print(df[['drive_time','alt_drive_time','correct_drive_time']].corr())\n",
    "\n",
    "df = df.drop(columns=['drive_time','alt_drive_time','correct_time_1'])\n",
    "df = df.rename(columns={'correct_drive_time':'drive_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1844449\n",
      "1844189\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df.dropna(subset=['play_text'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some objectives\n",
    "\n",
    "1) fix \"uncategorized\" play type  \n",
    "2) aggregate, clean, validate all play types  \n",
    "3) fix \"uncategorized\" drive results  \n",
    "4) aggregate, clean, validate all drive results  \n",
    "5) compare play types to drive results to make sure they match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing uncategorized play types\n",
    "\n",
    "base = r'^{}'\n",
    "expr = '(?=.*{})'\n",
    "words = ['End', 'of', 'Quarter']\n",
    "end_period = base.format(''.join(expr.format(w) for w in words))\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains(end_period,regex=True)), 'play_type'] = 'End Period'\n",
    "\n",
    "words = ['fumbled','run', 'for']\n",
    "fumbles = base.format(''.join(expr.format(w) for w in words))\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains(fumbles,regex=True)), 'play_type'] = 'Fumble Recovery (Own)'\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains('Penalty')), 'play_type'] = 'Penalty'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many uncategorized plays are left?\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# fix individual\n",
    "# many of the ones left are fumbles, and then something\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains('recovered by UTEP Aaron Jones')), 'play_type'] = 'Penalty'\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains('intercepted')), 'play_type'] = 'Pass Interception'\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains('SAFETY')), 'play_type'] = 'Safety'\n",
    "\n",
    "words = ['fumbled','pass', 'complete']\n",
    "complete = base.format(''.join(expr.format(w) for w in words))\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains(complete,regex=True)), 'play_type'] = 'Pass Completion'\n",
    "\n",
    "words = ['TD','punt', 'blocked']\n",
    "td_pb = base.format(''.join(expr.format(w) for w in words))\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains(td_pb,regex=True)), 'play_type'] = 'Blocked Punt Touchdown'\n",
    "\n",
    "\n",
    "words = ['run','for', 'TD']\n",
    "run_td = base.format(''.join(expr.format(w) for w in words))\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains(run_td,regex=True)), 'play_type'] = 'Rushing Touchdown'\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.down==4), 'play_type'] = 'Punt'\n",
    "\n",
    "words = ['return','for', 'TD']\n",
    "fumb_td = base.format(''.join(expr.format(w) for w in words))\n",
    "df.loc[(df.play_type=='Uncategorized')&(df.play_text.str.contains(fumb_td,regex=True)), 'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&df.play_text.str.contains('return for'), 'play_type'] = 'Fumble Recovery (Opponent)'\n",
    "\n",
    "df.loc[(df.play_type=='Uncategorized')&df.play_text.str.contains('run for'), 'play_type'] = 'Rush'\n",
    "\n",
    "print(\"how many uncategorized plays are left?\")\n",
    "print(len(df.loc[df['play_type']=='Uncategorized']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these plays don't have anything important\n",
    "nah_part_2 = ['End Period','End of Half','End of Game']\n",
    "bs = df.loc[df.play_type.isin(nah_part_2)&df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD')]\n",
    "del bs\n",
    "df = df.loc[~df.play_type.isin(nah_part_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize\n",
    "df.loc[df.play_type=='Interception', 'play_type'] = 'Pass Interception'\n",
    "df.loc[df.play_type=='Pass Interception Return', 'play_type'] = 'Pass Interception'\n",
    "\n",
    "df.loc[df.play_type=='Pass Reception', 'play_type'] = 'Pass Completion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "play_type\n",
       "Blocked Field Goal                       435\n",
       "Blocked Field Goal Touchdown              35\n",
       "Blocked Punt                             255\n",
       "Blocked Punt Touchdown                   111\n",
       "Field Goal Good                        24014\n",
       "Field Goal Missed                       8756\n",
       "Fumble Recovery (Opponent)              3699\n",
       "Fumble Recovery (Own)                   4444\n",
       "Fumble Return Touchdown                 1438\n",
       "Interception                            1132\n",
       "Interception Return Touchdown            921\n",
       "Missed Field Goal Return                  20\n",
       "Missed Field Goal Return Touchdown         3\n",
       "Pass Completion                       390409\n",
       "Pass Incompletion                     261974\n",
       "Pass Interception                      18083\n",
       "Passing Touchdown                      15593\n",
       "Penalty                               109818\n",
       "Punt                                  107878\n",
       "Punt Return Touchdown                     52\n",
       "Rush                                  657905\n",
       "Rushing Touchdown                     113392\n",
       "Sack                                   39116\n",
       "Safety                                   732\n",
       "Timeout                                67048\n",
       "Name: down, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = df.groupby(['play_type'])['down'].count()\n",
    "gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) fix uncategorized play type (check)  \n",
    "2) clean/validate/aggregate play types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a few!\n",
      "11\n",
      "All are defensive scores\n"
     ]
    }
   ],
   "source": [
    "# start with the top: blocked FG. make sure none are touchdowns\n",
    "bfg = df.loc[(df.play_type=='Blocked Field Goal')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "print(\"There are a few!\")\n",
    "print(len(bfg))\n",
    "print(\"All are defensive scores\")\n",
    "\n",
    "df.loc[((df.play_type=='Blocked Field Goal')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))), 'play_type']='Blocked Field Goal Touchdown'\n",
    "\n",
    "del bfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "punts to fix\n",
      "fixed\n"
     ]
    }
   ],
   "source": [
    "# same thing for blocked punt\n",
    "bp = df.loc[(df.play_type=='Blocked Punt')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "print(len(bp))\n",
    "print(\"punts to fix\")\n",
    "\n",
    "# pretty safe to assume these are all defensive\n",
    "df.loc[((df.play_type=='Blocked Punt')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))), 'play_type']='Blocked Punt Touchdown'\n",
    "\n",
    "print('fixed')\n",
    "del bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "fumble recoveries that were TDs\n"
     ]
    }
   ],
   "source": [
    "# regular FG missed, verify they weren't blocked/touchdown (all good)\n",
    "# mfg = df.loc[(df.play_type=='FG Missed')&(df.play_text.str.contains('Blocked|BLOCKED|blocked'))]\n",
    "# mfg = df.loc[(df.play_type=='FG Missed')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "# check Fumble Recovery (Opponent)\n",
    "fro = df.loc[(df.play_type=='Fumble Recovery (Opponent)')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "print(len(fro))\n",
    "print(\"fumble recoveries that were TDs\")\n",
    "\n",
    "# i think all but 1 or two are defensive, don't know a good way to sort those out\n",
    "df.loc[(df.play_type=='Fumble Recovery (Opponent)')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD')), 'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "del fro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "own fumble recoveries that were TDs\n"
     ]
    }
   ],
   "source": [
    "fro = df.loc[(df.play_type=='Fumble Recovery (Own)')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "print(len(fro))\n",
    "print(\"own fumble recoveries that were TDs\")\n",
    "\n",
    "df.loc[(df.play_type=='Fumble Recovery (Own)')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD')), 'play_type'] = 'Rushing Touchdown'\n",
    "\n",
    "# missed field goal returns are gucci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check pass for random stuff\n",
    "pa = df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "#TTD is a team abbreviation that gets picked up\n",
    "pa = pa.loc[(~pa.play_text.str.contains('intercepted|Intercepted|INTERCEPTED'))&\n",
    "            (~pa.play_text.str.contains('fumbled'))&\n",
    "            (~pa.play_text.str.contains('Penalty|PENALTY|penalty'))&\n",
    "            (~pa.play_text.str.contains('TTD'))]\n",
    "\n",
    "pa_ids = list(pa.id.values)\n",
    "\n",
    "df.loc[df.id.isin(pa_ids), 'play_type'] = 'Passing Touchdown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "pa = pa.loc[((pa.play_text.str.contains('Penalty|PENALTY|penalty'))&\n",
    "        (pa.play_text.str.contains('ACCEPTED|accepted|Accepted')))]\n",
    "\n",
    "pa_ids = list(pa.id.values)\n",
    "df.loc[df.id.isin(pa_ids), 'play_type'] = 'Penalty'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "pa = pa.loc[pa.play_text.str.contains('intercepted|Intercepted|INTERCEPTED')]\n",
    "\n",
    "pa_ids = list(pa.id.values)\n",
    "df.loc[df.id.isin(pa_ids), 'play_type'] = 'Interception Return Touchdown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "pa = pa.loc[pa.play_text.str.contains('fumbled')]\n",
    "\n",
    "fbr_ids = list(pa.loc[pa.drive_result=='FUMBLE RETURN TD'].id.values)\n",
    "df.loc[df.id.isin(fbr_ids),'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "fbr_ids = list(pa.loc[pa.drive_result=='PASSING TD'].id.values)\n",
    "df.loc[df.id.isin(fbr_ids),'play_type'] = 'Passing Touchdown'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa = df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "\n",
    "pa = pa.loc[pa.play_text.str.contains('fumbled')]\n",
    "\n",
    "# slightly guessing but i think it's right\n",
    "\n",
    "ptd = pa.loc[pa.play_text.str.contains('pass complete')]\n",
    "ptd_ids = list(ptd.id.values)\n",
    "df.loc[df.id.isin(ptd_ids), 'play_type'] = 'Passing Touchdown'\n",
    "\n",
    "pa = df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "pa_ids = list(pa.id.values)\n",
    "df.loc[df.id.isin(pa_ids), 'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "del pa\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change rushing tds categorized as 'rush' to rushing tds\n",
    "rush = df.loc[(df.play_type=='Rush')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "# for penalties that don't stop a touchdown\n",
    "words = ['0 yard','accepted']\n",
    "pens = base.format(''.join(expr.format(w) for w in words))\n",
    "rush_tds = rush.loc[(~rush.play_text.str.contains('Penalty|PENALTY|penalty')) | (rush.play_text.str.contains('declined|DECLINED') | (rush.play_text.str.contains(pens)))]\n",
    "rush_tds = rush_tds.loc[~rush.play_text.str.contains('fumbled')]\n",
    "rtd_ids = list(rush_tds.id.values)\n",
    "df.loc[df.id.isin(rtd_ids),'play_type'] = 'Rushing Touchdown'\n",
    "\n",
    "del rush_tds\n",
    "# rtd_ids = list(rush_tds.id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some fumble 6 rushes that need to be categorized as such\n",
    "\n",
    "rush = df.loc[(df.play_type=='Rush')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))]\n",
    "words = ['fumbled','returned by']\n",
    "ftds = base.format(''.join(expr.format(w) for w in words))\n",
    "fumble_tds = rush.loc[(rush.play_text.str.contains(ftds))]\n",
    "\n",
    "fbtd_ids = list(fumble_tds.id.values)\n",
    "df.loc[df.id.isin(fbtd_ids),'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "words = ['fumbled','loss of']\n",
    "ftds = base.format(''.join(expr.format(w) for w in words))\n",
    "fumble_tds = rush.loc[(rush.play_text.str.contains(ftds))]\n",
    "\n",
    "fbtd_ids = list(fumble_tds.id.values)\n",
    "df.loc[df.id.isin(fbtd_ids),'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "# subset of fumble 6s always say 'to the {other team} 0' \n",
    "words = ['to the','0']\n",
    "ftds = base.format(''.join(expr.format(w) for w in words))\n",
    "fumble_tds = rush.loc[(rush.play_text.str.contains(ftds))]\n",
    "\n",
    "fbtd_ids = list(fumble_tds.id.values)\n",
    "df.loc[df.id.isin(fbtd_ids),'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "df.loc[((df.play_type=='Rush')&(df.play_text.str.contains('penalty|PENALTY|Penalty'))), 'play_type'] = 'Penalty'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard to determine which fumbles go for offensive TD vs defensive TD from just play text\n",
    "# lean on drive result\n",
    "\n",
    "df.loc[(df.play_type=='Rush')&(df.drive_result=='RUSHING TD'), 'play_type'] = 'Rushing Touchdown'\n",
    "\n",
    "df.loc[(df.play_type=='Rush')&(df.drive_result=='FUMBLE RETURN TD'), 'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "# i verified these\n",
    "df.loc[((df.play_type=='Rush')&(df.yard_line>90)&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))), 'play_type'] = 'Rushing Touchdown'\n",
    "\n",
    "# rest seem to be defensive. might be one or two offensive that leaked through\n",
    "df.loc[((df.play_type=='Rush')&(df.play_text.str.contains('TOUCHDOWN|touchdown|Touchdown|TD'))), 'play_type'] = 'Fumble Return Touchdown'\n",
    "                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "clean = ['Pass','Rush']\n",
    "sa = df.loc[(df.play_type.isin(clean))&(df.play_text.str.contains('Safety|safety|SAFETY'))]\n",
    "sa_ids = list(sa.id.values)\n",
    "print(len(sa))\n",
    "df.loc[df.id.isin(sa_ids), 'play_type'] = 'Safety'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide up the \"pass\" play type\n",
    "df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('incomplete')), 'play_type'] = 'Pass Incompletion'\n",
    "df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('complete')), 'play_type'] = 'Pass Completion'\n",
    "df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('intercepted')), 'play_type'] = 'Interception'\n",
    "df.loc[(df.play_type=='Pass')&(df.play_text.str.contains('sacked')), 'play_type'] = 'Sack'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = df.loc[(df.play_type=='Pass')]\n",
    "\n",
    "# only things left are fumbles\n",
    "# lean on drive result, tough to know who recovered fumble \n",
    "\n",
    "li = ['FUMBLE','Uncategorized']\n",
    "\n",
    "fro = pa.loc[~pa.drive_result.isin(li)]\n",
    "fro_ids = list(fro.id.values)\n",
    "df.loc[df.id.isin(fro_ids), 'play_type'] = 'Fumble Recovery (Own)'\n",
    "\n",
    "fum = pa.loc[pa.drive_result == 'FUMBLE']\n",
    "fum_ids = list(fum.id.values)\n",
    "df.loc[df.id.isin(fum_ids), 'play_type'] = 'Fumble Recovery (Opponent)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncategorized\n",
    "pa = df.loc[(df.play_type=='Pass')]\n",
    "\n",
    "df.loc[df.id==253370030087, 'play_type'] = 'Fumble Recovery (Opponent)'\n",
    "df = df.loc[df.id != 262590259175]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = ['FUMBLE RETURN TD','FUMBLE TD']\n",
    "\n",
    "td = df.loc[(df.play_type == 'Sack') & (df.play_text.str.contains('fumbled')) & (df.drive_result.isin(tds))]\n",
    "td_ids = list(td.id.values)\n",
    "\n",
    "df.loc[df.id.isin(td_ids), 'play_type'] = 'Fumble Return Touchdown'\n",
    "del tds\n",
    "\n",
    "sa = df.loc[(df.play_type == 'Sack') & (df.play_text.str.contains('fumbled'))]\n",
    "\n",
    "li = ['FUMBLE','Uncategorized']\n",
    "\n",
    "fro = sa.loc[~sa.drive_result.isin(li)]\n",
    "fro_ids = list(fro.id.values)\n",
    "df.loc[df.id.isin(fro_ids), 'play_type'] = 'Fumble Recovery (Own)'\n",
    "\n",
    "fum = sa.loc[sa.drive_result == 'FUMBLE']\n",
    "fum_ids = list(fum.id.values)\n",
    "df.loc[df.id.isin(fum_ids), 'play_type'] = 'Fumble Recovery (Opponent)'\n",
    "\n",
    "sa = df.loc[(df.play_type=='Sack')&(df.play_text.str.contains('fumbled'))]\n",
    "\n",
    "# only recovery by the defense\n",
    "df.loc[df.id==322450120161, 'play_type'] = 'Fumble Recovery (Opponent)'\n",
    "\n",
    "df.loc[(df.play_type=='Sack')&(df.play_text.str.contains('fumbled')), 'play_type'] = 'Fumble Recovery (Own)'\n",
    "\n",
    "del sa\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = df.loc[(df.play_type == 'Pass Completion') & (df.play_text.str.contains('fumbled')) & (df.drive_result=='FUMBLE TD')]\n",
    "\n",
    "words = ['to the','0']\n",
    "ftds = base.format(''.join(expr.format(w) for w in words))\n",
    "fumble_tds = td.loc[(td.play_text.str.contains(ftds))]\n",
    "\n",
    "fbtd_ids = list(fumble_tds.id.values)\n",
    "df.loc[df.id.isin(fbtd_ids),'play_type'] = 'Fumble Return Touchdown'\n",
    "\n",
    "# rest are just fumble recoveries\n",
    "td = df.loc[(df.play_type == 'Pass Completion') & (df.play_text.str.contains('fumbled')) & (df.drive_result=='FUMBLE TD')]\n",
    "td_ids = list(td.id.values)\n",
    "df.loc[df.id.isin(td_ids),'play_type'] = 'Fumble Recovery (Opponent)'\n",
    "\n",
    "del td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.play_type == 'Pass Completion') & (df.play_text.str.contains('fumbled')) & (df.drive_result=='FUMBLE RETURN TD'), 'play_type'] = 'Passing Touchdown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danny Embick pass complete to Casey McGahee for 6 yards, fumbled by Casey McGahee at the OKSt 34, forced by Calvin Mickens, recovered by Team to the OKSt 34 for a 1ST down, tackled by Calvin Mickens.\n",
      "Drew Stanton pass complete to Jerramy Scott for 3 yards, fumbled at the MSU 44, forced by Travis Thomas, recovered by Kyle Cook at the MSU 44, tackled by Travis Thomas.\n",
      "Anthony Morelli pass complete to Andrew Quarless for 6 yards, fumbled at the PnnSt 41, forced by Stanford Keglar, recovered by PnnSt at the PnnSt 41, tackled by Stanford Keglar.\n",
      "Andy Dalton pass complete to Ervin Dickerson for 19 yards, fumbled at the AFA 6, forced by John Rabold, recovered by Justin Watts at the AFA 6 for a 1ST down, tackled by John Rabold.\n",
      "Wayne Younger pass complete to A'mod Ned for a loss of 2 yards, fumbled at the Kans 37, forced by Joe Mortensen, recovered by Darrell Stuckey at the Kans 46, tackled by Joe Mortensen and Michael Dominguez.\n",
      "Corey Leonard pass complete to Kevin Jones for 7 yards, fumbled at the ArkSt 42, forced by Alex Suber, recovered by Rod Issac for a TOUCHDOWN, tackled by Alex Suber.\n",
      "Michael Desormeaux pass complete to Tyrell Fenroy for 5 yards, fumbled at the MTnSt 15, forced by Andrew Harrington, recovered by N/A at the MTnSt 15, tackled by Andrew Harrington.\n",
      "Jake Phillips pass complete to Chase Hill, fumbled, forced by DeAndre Morgan, recovered by NCSt Nate Irving at the WmMry 26, Nate Irving for 13 yards, to the WmMry 13, tackled by Terrence Riggins.\n",
      "Kellen Moore pass complete to Richie Brockel for 12 yards, fumbled, recovered by Oregn Terrell Turner at the Oregn 39.\n",
      "Austen Arnaud pass complete to Sedrick Johnson, fumbled, forced by Byron Landor, recovered by IowSt N/A at the Bayl 1, N/A for no gain, to the Bayl 4, tackled by Tracy Robertson.\n",
      "Jimmy Clausen pass complete to John Goodman for 10 yards, fumbled, recovered by NDame at the USC 43 for a 1ST down.\n",
      "Aaron Murray pass complete to Washaun Ealey for 20 yards, fumbled, forced by Nickoe Whitley, recovered by MisSt Nickoe Whitley in the endzone.\n",
      "Cody Hawkins pass complete to Toney Clemons, fumbled, recovered by Colo Ethan Adkins at the Colo 44, fumbled, recovered by Colo Nate Solder at the Colo 38 for 7 yards, lateral to Cody Hawkins for 7 yards, lateral to Ethan Adkins for a loss of 6 yards, to t\n",
      "Michael Paulus pass complete to D.J. Mangas, fumbled, forced by Dom Joseph, recovered by Virg Steve Greer at the Virg 48, Steve Greer for 3 yards, to the WmMry 49, tackled by Mikal Abdul-Saboor.\n",
      "Ryan Aplin pass complete to Julian Jones for 14 yards, fumbled, forced by Lamar Moore, recovered by ArkSt N/A at the CArk 32 out-of-bounds for a 1ST down.\n",
      "Jameill Showers pass complete to Eric Tomlinson for 9 yards, fumbled, forced by Davis Cazares, recovered by UTEP at the UTEP 45 for a 1ST down.\n"
     ]
    }
   ],
   "source": [
    "pa = df.loc[(df.play_type == 'Pass Completion') & (df.play_text.str.contains('fumbled'))]\n",
    "\n",
    "fumbles = pa.loc[pa.drive_result=='Fumble']\n",
    "\n",
    "fum_ids = list(fumbles.id.values)\n",
    "df.loc[df.id.isin(fum_ids), 'play_type'] = 'Fumble Recovery (Opponent)'\n",
    "\n",
    "pa = df.loc[(df.play_type == 'Pass Completion') & (df.play_text.str.contains('fumbled')) & (df.drive_result == 'Uncategorized')]\n",
    "\n",
    "pa = \n",
    "\n",
    "for pt in list(pa.play_text.values):\n",
    "    print(pt)\n",
    "# print(pa.groupby(['drive_result'])['down'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
