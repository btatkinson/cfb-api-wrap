{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "import datetime\n",
    "import random\n",
    "gc.collect()\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:29<00:00,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2031893, 41)\n",
      "2031893 plays were loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load play by play & drive data\n",
    "years = list(range(2005, int(datetime.datetime.now().year)))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year in tqdm(years):\n",
    "    path = './output/'+str(year)+'/'+str(year)+'_pbp.csv'\n",
    "    sea_df = pd.read_csv(path)\n",
    "    \n",
    "    drive_path = './output/'+str(year)+'/'+str(year)+'_drives.csv'\n",
    "    drive_df = pd.read_csv(drive_path)\n",
    "    \n",
    "    drive_df = drive_df.rename(columns={'id':'drive_id'})\n",
    "    \n",
    "    sea_df = pd.merge(left=sea_df, right=drive_df, how='left', on=['drive_id','drive_id'])\n",
    "    df = pd.concat([df,sea_df])\n",
    "\n",
    "num_plays = len(df)\n",
    "print(df.shape)\n",
    "print(str(num_plays) + \" plays were loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offense_x seems to be correct while offense_y is not\n",
    "\n",
    "df = df.drop(columns=['defense_y','defense_conference_y','offense_y','offense_conference_y'])\n",
    "\n",
    "df = df.rename(columns={'defense_x':'defense','defense_conference_x':'defense_conference','offense_x':'offense','offense_conference_x':'offense_conference'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix yard_line, it's w.r.t the home team\n",
    "df = df.rename(columns={'yard_line':'wrong_yardline'})\n",
    "\n",
    "df['yard_line'] = np.where(df['offense']==df['home'],df['wrong_yardline'],100-df['wrong_yardline'])\n",
    "# print(df[['home','offense','yard_line','wrong_yardline']].head(50))\n",
    "df = df.drop(columns=['wrong_yardline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alt_game_id'] = df['game_id'].copy().astype(str)\n",
    "df['alt_drive_id'] = df['drive_id'].copy().astype(str)\n",
    "\n",
    "def replace_id(x,y):\n",
    "    return x.replace(y,'')\n",
    "df['alt_drive_id'] = df.apply(lambda row: replace_id(row['alt_drive_id'], row['alt_game_id']), axis=1)\n",
    "\n",
    "#  strip leading zeros from 1-9 drive numbers\n",
    "df['alt_drive_id'] = df['alt_drive_id'].str.lstrip(\"0\")\n",
    "\n",
    "# this also eliminates drive \"zeros\", so replace empty space with zero\n",
    "df['alt_drive_id'] = df['alt_drive_id'].replace(r'^\\s*$', '0', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Teams\n",
    "\n",
    "Overtimes are for future work, doing point afters last here (or maybe not at all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df))\n",
    "pat = ['2pt Conversion','Offensive 1pt Safety','Defensive 2pt Conversion','Extra Point Good','Extra Point Missed']\n",
    "\n",
    "df = df.loc[~df.play_type.isin(pat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1979243"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also drop overtime\n",
    "\n",
    "df = df.loc[(df.period > 0) & (df.period <= 4)]\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1978969"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and plays with no play text\n",
    "df = df.dropna(subset=['play_text'])\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clock\n",
    "\n",
    "Clock data is unreliable because maybe 25% of the games have only have one time for each play, and that time is when the drive started. I played with trying to predict time per play based on play type, but the data was very messy. So I decided to get the total time of each drive, and then assume each play took the same amount of time. EPA shouldn't be significantly affected most of the time, i.e. a 70 yard pass will be considered a good play no matter what. The only time it might have an adverse effect is toward the end of a game, when seconds matter. I think that in college football, when the clock stops for a first down, and incompletions, that all pass plays probably do take a somewhat similar amount of time. Drives in this situation will consist mostly of the same play type, and plays of the same play type likely take similar amounts of time. I'll compare it to the clock data I do have to make sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix clock data first so drives can be figured out\n",
    "time_cols = ['clock.minutes','clock.seconds','start_time.minutes','start_time.seconds',\n",
    "            'end_time.minutes','end_time.seconds']\n",
    "for tc in time_cols:\n",
    "    df[tc] = df[tc].fillna(0)\n",
    "\n",
    "# get time remaining in game\n",
    "df['tr_game'] = (4-df['period']) * 900 + (df['clock.minutes'] * 60) + df['clock.seconds']\n",
    "df['tr_half'] = np.where(df['period']>2,df['tr_game'], df['tr_game']-1800)\n",
    "\n",
    "df = df.drop(columns=['clock.minutes','clock.seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill empties\n",
    "df['elapsed.minutes'] = df['elapsed.minutes'].copy().fillna(0)\n",
    "df['elapsed.seconds'] = df['elapsed.seconds'].copy().fillna(0)\n",
    "df['drive_time'] = 60*df['elapsed.minutes'] + df['elapsed.seconds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11341\n",
      "277555\n",
      "145.282859253121\n"
     ]
    }
   ],
   "source": [
    "# a lot of those drive times are negative... and other problems. so here's an alt drive time\n",
    "# alt clock\n",
    "\n",
    "# these get the start and end time of every drive\n",
    "maxs = df.groupby(['game_id','drive_id'])['tr_game'].max().reset_index()\n",
    "mins = df.groupby(['game_id','drive_id'])['tr_game'].min().reset_index()\n",
    "maxs = maxs.rename(columns={'tr_game':'drive_start'})\n",
    "mins = mins.rename(columns={'tr_game':'drive_end'})\n",
    "\n",
    "# sometimes the drive end time is the same as the drive start. in that case, I use the next drive start\n",
    "maxs = maxs.sort_values(by=['game_id','drive_start'],ascending=False)\n",
    "next_max = maxs.groupby(['game_id'])['drive_start'].shift(-1)\n",
    "next_max = pd.Series(next_max, name='next_drive_start')\n",
    "new_max = pd.concat([maxs, next_max], axis=1)\n",
    "new_max['next_drive_start'] = new_max['next_drive_start'].fillna(0)\n",
    "\n",
    "# sometimes (rarely, 2%ish of the time) both the next drive start and the drive end are the same as the drive start\n",
    "# i can explore this more in future work\n",
    "# i'm fairly sure most of the time it's when a timeout or something divides the same drive into two.\n",
    "\n",
    "mins = mins.sort_values(by=['game_id','drive_end'],ascending=False)\n",
    "next_min = mins.groupby(['game_id'])['drive_end'].shift(-1)\n",
    "next_min = pd.Series(next_min, name='next_drive_end')\n",
    "new_min = pd.concat([mins, next_min], axis=1)\n",
    "new_min['next_drive_end'] = new_min['next_drive_end'].fillna(0)\n",
    "new_min = new_min.drop(columns='game_id')\n",
    "times = pd.merge(left=new_max,right=new_min,on=['drive_id','drive_id'],how='left')\n",
    "\n",
    "\n",
    "# attempt 1 (works on ~95.5% of data)\n",
    "times['drive_time_1'] = times['drive_start']-times['next_drive_start']\n",
    "# plan B (95.8% of data)\n",
    "times['drive_time'] = np.where(times['drive_time_1']>0,times['drive_time_1'],(times['drive_start']-times['drive_end']))\n",
    "# last resort (didn't implement)\n",
    "# times['drive_time'] = np.where(times['drive_time_2']>0,times['drive_time_2'],(times['drive_start']-times['next_drive_end']))\n",
    "\n",
    "not_good = times.loc[times.drive_time<=0]\n",
    "print(len(not_good))\n",
    "\n",
    "good = times.loc[times.drive_time>0]\n",
    "print(len(good))\n",
    "\n",
    "print(good.drive_time.mean())\n",
    "\n",
    "times = times[['drive_id','drive_time']]\n",
    "times = times.rename(columns={'drive_time':'alt_drive_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=df,right=times,how='left',on=['drive_id','drive_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1957877\n",
      "correlation between primary and approximate drive time\n",
      "                    drive_time  alt_drive_time  correct_drive_time\n",
      "drive_time            1.000000        0.855134            0.991361\n",
      "alt_drive_time        0.855134        1.000000            0.862633\n",
      "correct_drive_time    0.991361        0.862633            1.000000\n"
     ]
    }
   ],
   "source": [
    "# longest drive in CFB history is 882. so need to drop anything above 900\n",
    "# also drop anything below or equal to 0\n",
    "\n",
    "df['correct_time_1'] = np.where(df['drive_time'] > 0, df['drive_time'], df['alt_drive_time'])\n",
    "\n",
    "df = df.loc[df['correct_time_1'] > 0]\n",
    "\n",
    "df['correct_drive_time'] = np.where(df['drive_time'] < 900, df['drive_time'], df['alt_drive_time'])\n",
    "\n",
    "df = df.loc[df['correct_drive_time'] < 900]\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "print(\"correlation between primary and approximate drive time\")\n",
    "print(df[['drive_time','alt_drive_time','correct_drive_time']].corr())\n",
    "\n",
    "df = df.drop(columns=['drive_time','alt_drive_time','correct_time_1'])\n",
    "df = df.rename(columns={'correct_drive_time':'drive_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['start_time.minutes','start_time.seconds','end_time.minutes','end_time.seconds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring Changes\n",
    "\n",
    "Scoring changes are probably the most reliable data in the dataset. And also the most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from what I can tell, sorting by ID gets the plays in order. Thank sweet baby jesus, because I'm not sure there's another way\n",
    "df = df.sort_values(by=['game_id','id'],ascending=True)\n",
    "\n",
    "df['away_score'] = np.where(df['away']==df['offense'], df['offense_score'], df['defense_score'])\n",
    "df['home_score'] = np.where(df['away']==df['defense'], df['offense_score'], df['defense_score'])\n",
    "\n",
    "df['prev_home_score'] = df.groupby(['game_id'])['home_score'].shift(1)\n",
    "df['prev_away_score'] = df.groupby(['game_id'])['away_score'].shift(1)\n",
    "\n",
    "df['home_score_change'] =  df['home_score'] - df['prev_home_score']\n",
    "df['away_score_change'] = df['away_score'] - df['prev_away_score'] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on kickoffs, sometimes the score doesn't fill in yet, and so you get a lot of -7s and -3s\n",
    "# there are a bunch of random other positives and negatives because occasionally random plays will have 0-0 scores\n",
    "tds = [6,7]\n",
    "df['home_td']=0\n",
    "df['away_td']=0\n",
    "df['home_fg']=0\n",
    "df['away_fg']=0\n",
    "\n",
    "df.loc[df.home_score_change.isin(tds), 'home_td'] = 1\n",
    "df.loc[df.home_score_change == 3, 'home_fg'] = 1\n",
    "\n",
    "df.loc[df.away_score_change.isin(tds), 'away_td'] = 1\n",
    "df.loc[df.away_score_change == 3, 'away_fg'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "play_type\n",
       "Blocked Field Goal                       446\n",
       "Blocked Field Goal Touchdown              24\n",
       "Blocked Punt                             347\n",
       "Blocked Punt Touchdown                    18\n",
       "End Period                              9206\n",
       "End of Game                             3414\n",
       "End of Half                             4303\n",
       "Field Goal Good                        24014\n",
       "Field Goal Missed                       8754\n",
       "Fumble Recovery (Opponent)              3664\n",
       "Fumble Recovery (Own)                   4313\n",
       "Fumble Return Touchdown                  144\n",
       "Interception                               2\n",
       "Interception Return Touchdown            822\n",
       "Kickoff                               110779\n",
       "Kickoff Return (Offense)                2749\n",
       "Kickoff Return Touchdown                 138\n",
       "Missed Field Goal Return                  20\n",
       "Missed Field Goal Return Touchdown         3\n",
       "Pass                                   41589\n",
       "Pass Completion                       225699\n",
       "Pass Incompletion                     246860\n",
       "Pass Interception                      11401\n",
       "Pass Interception Return                6682\n",
       "Pass Reception                        144382\n",
       "Passing Touchdown                      13824\n",
       "Penalty                                97531\n",
       "Punt                                  107876\n",
       "Punt Return Touchdown                     52\n",
       "Rush                                  769509\n",
       "Rushing Touchdown                      14990\n",
       "Sack                                   36512\n",
       "Safety                                   727\n",
       "Timeout                                67047\n",
       "Uncategorized                             36\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pt = ['Rushing Touchdown','Passing Touchdown']\n",
    "# tds = \n",
    "\n",
    "# df.groupby(['play_type'])['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72055\n",
      "12132\n"
     ]
    }
   ],
   "source": [
    "df['offensive_td'] = np.where(((df['home_td']==1)&(df['home']==df['offense'])), 1, 0)\n",
    "df['offensive_td'] = np.where(((df['away_td']==1)&(df['away']==df['offense'])), 1, df['offensive_td'])\n",
    "\n",
    "df['defensive_td'] = np.where(((df['home_td']==1)&(df['home']==df['defense'])), 1, 0)\n",
    "df['defensive_td'] = np.where(((df['away_td']==1)&(df['away']==df['defense'])), 1, df['defensive_td'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defensive_td = df.loc[df.play_type=='Fumble Return Touchdown']\n",
    "game_ids = list(weird.game_id.values)\n",
    "sample = random.choice(game_ids)\n",
    "               \n",
    "test_game = df.loc[df.game_id==sample]\n",
    "\n",
    "test_game.to_csv('sample.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard Part\n",
    "\n",
    "Need to make sure drive result, play text, and play type are all consistent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify each play type by play text\n",
    "\n",
    "df['fumble'] = np.where(df['play_text'].str.contains('fumble'),1,0)\n",
    "df['interception'] = np.where(df['play_text'].str.contains('interception'),1,0)\n",
    "df['completion'] = np.where(df['play_text'].str.contains('pass complete'),1,0)\n",
    "df['incompletion'] = np.where(df['play_text'].str.contains('incomplete'),1,0)\n",
    "df['sack'] = np.where(df['play_text'].str.contains('sack'),1,0)\n",
    "df['touchdown'] = np.where(df['play_text'].str.contains('Touchdown|TOUCHDOWN|touchdown'),1,0)\n",
    "df['touchdown'] = np.where(df['play_text'].str.contains('/^TD$/'),1,df['touchdown'])\n",
    "df['rush'] = np.where(df['play_text'].str.contains('run|rush'),1,0)\n",
    "df['punt'] = np.where(df['play_text'].str.contains('punt'),1,0)\n",
    "# safties fixed now\n",
    "df['safety'] = np.where(df['play_text'].str.contains('safety|SAFETY|Safety'),1,0)\n",
    "df['punt_block'] = np.where(df['play_text'].str.contains('punt blocked'),1,0)\n",
    "base = r'^{}'\n",
    "expr = '(?=.*{})'\n",
    "words = ['FG', 'GOOD']\n",
    "fg_made = base.format(''.join(expr.format(w) for w in words))\n",
    "df['fg_made'] = np.where(df.play_text.str.contains(fg_made,regex=True),1,0)\n",
    "words = ['Field Goal', 'GOOD']\n",
    "df['fg_made'] = np.where(df.play_text.str.contains(fg_made,regex=True),1,df['fg_made'])\n",
    "words = ['FG', 'MISSED']\n",
    "fg_missed = base.format(''.join(expr.format(w) for w in words))\n",
    "df['fg_missed'] = np.where(df.play_text.str.contains(fg_missed,regex=True),1,0)\n",
    "words = ['Field Goal', 'MISSED']\n",
    "df['fg_missed'] = np.where(df.play_text.str.contains(fg_made,regex=True),1,df['fg_missed'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'rush'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-89f512f6f8a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# where everything agrees, let's go ahead and standardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrush\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'rush'"
     ]
    }
   ],
   "source": [
    "# where everything agrees, let's go ahead and standardize\n",
    "print(df.rush.sum())\n",
    "print(df.completion.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from what I can tell, sorting by ID gets the plays in order. Thank sweet baby jesus, because I'm not sure there's another way\n",
    "df = df.sort_values(by=['game_id','id'],ascending=True)\n",
    "\n",
    "defensive_td = df.loc[df.play_type=='Fumble Return Touchdown']\n",
    "game_ids = list(defensive_td.game_id.values)\n",
    "sample = random.choice(game_ids)\n",
    "               \n",
    "test_game = df.loc[df.game_id==sample]\n",
    "\n",
    "test_game.to_csv('sample.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kickoffs = ['Kickoff','Kickoff Return (Offense)','Kickoff Return Touchdown']\n",
    "\n",
    "nok = df.loc[~df['play_type'].isin(kickoffs)]\n",
    "\n",
    "# adding columns to markt the first and last play of drives to help with categorizing things like fumbles\n",
    "firsts = nok.groupby(['game_id','drive_id'])['id'].first().reset_index()\n",
    "\n",
    "lasts = nok.groupby(['game_id','drive_id'])['id'].last().reset_index()\n",
    "\n",
    "first_ids = list(firsts.id.values)\n",
    "last_ids = list(lasts.id.values)\n",
    "\n",
    "df['first_play'] = 0\n",
    "df['last_play'] = 0\n",
    "df.loc[df.id.isin(first_ids),'first_play'] = 1\n",
    "df.loc[df.id.isin(last_ids),'last_play'] = 1\n",
    "\n",
    "del nok \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "play_type\n",
       "Blocked Field Goal                       446\n",
       "Blocked Field Goal Touchdown              24\n",
       "Blocked Punt                             325\n",
       "Blocked Punt Touchdown                    18\n",
       "End Period                              9206\n",
       "End of Game                             3414\n",
       "End of Half                             4303\n",
       "Field Goal Good                        24014\n",
       "Field Goal Missed                       8754\n",
       "Fumble Recovery (Opponent)              3664\n",
       "Fumble Recovery (Own)                   4313\n",
       "Fumble Return Touchdown                  144\n",
       "Interception                               2\n",
       "Interception Return Touchdown            822\n",
       "Kickoff                               110779\n",
       "Kickoff Return (Offense)                2749\n",
       "Kickoff Return Touchdown                 138\n",
       "Missed Field Goal Return                  20\n",
       "Missed Field Goal Return Touchdown         3\n",
       "Pass                                   41588\n",
       "Pass Completion                       225699\n",
       "Pass Incompletion                     246860\n",
       "Pass Interception                      11401\n",
       "Pass Interception Return                6682\n",
       "Pass Reception                        144380\n",
       "Passing Touchdown                      13824\n",
       "Penalty                                97531\n",
       "Punt                                  107875\n",
       "Punt Return Touchdown                     52\n",
       "Rush                                  769507\n",
       "Rushing Touchdown                      14989\n",
       "Sack                                   36512\n",
       "Safety                                   749\n",
       "Timeout                                67047\n",
       "Uncategorized                             43\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['play_type'])['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix fumbles\n",
    "['Fumble','Fumble Recovery (Opponent)', 'Fumble Recovery (Own)', 'Fumble Return Touchdown']\n",
    "# fumbles = \n",
    "wrong = df.loc[(df.play_type=='Fumble')&(df.fumble==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix safeties\n",
    "\n",
    "df.loc[(df.play_type=='Safety') & (df.play_text.str.contains('intentional grounding')), 'safety'] = 1\n",
    "\n",
    "\n",
    "df.loc[(df['play_type']=='Safety')&(df['safety']==0), 'play_type'] = 'Uncategorized'\n",
    "\n",
    "\n",
    "df.loc[(df['play_type']!='Safety')&(df['safety']==1), 'play_type'] = 'Safety'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
