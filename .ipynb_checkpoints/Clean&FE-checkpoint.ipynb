{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "import datetime\n",
    "gc.collect()\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:48<00:00,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2122188, 41)\n",
      "2122188 plays were loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load play by play & drive data\n",
    "years = list(range(2004, int(datetime.datetime.now().year)))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year in tqdm(years):\n",
    "    path = './output/'+str(year)+'/'+str(year)+'_pbp.csv'\n",
    "    sea_df = pd.read_csv(path)\n",
    "    \n",
    "    drive_path = './output/'+str(year)+'/'+str(year)+'_drives.csv'\n",
    "    drive_df = pd.read_csv(drive_path)\n",
    "    \n",
    "    drive_df = drive_df.rename(columns={'id':'drive_id'})\n",
    "    \n",
    "    sea_df = pd.merge(left=sea_df, right=drive_df, how='left', on=['drive_id','drive_id'])\n",
    "    df = pd.concat([df,sea_df])\n",
    "\n",
    "num_plays = len(df)\n",
    "print(df.shape)\n",
    "print(str(num_plays) + \" plays were loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix clock data first so drives can be figured out\n",
    "time_cols = ['clock.minutes','clock.seconds','start_time.minutes','start_time.seconds',\n",
    "            'end_time.minutes','end_time.seconds']\n",
    "for tc in time_cols:\n",
    "    df[tc] = df[tc].fillna(0)\n",
    "\n",
    "# get time remaining in game\n",
    "df['tr_game'] = (4-df['period']) * 900 + (df['clock.minutes'] * 60) + df['clock.seconds']\n",
    "df['tr_half'] = np.where(df['period']>2,df['tr_game'], df['tr_game']-1800)\n",
    "\n",
    "df = df.drop(columns=['clock.minutes','clock.seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5580\n",
      "27            Extra point by Ryan Killeen (USC) is good.\n",
      "38      35 yard field goal by Brandon Pace (VT) is good.\n",
      "46     35 yard field goal by Ryan Killeen (USC) is no...\n",
      "61                             Start of the 2nd quarter.\n",
      "71             Extra point by Brandon Pace (VT) is good.\n",
      "117           Extra point by Ryan Killeen (USC) is good.\n",
      "122                            Start of the 4th quarter.\n",
      "132     42 yard field goal by Brandon Pace (VT) is good.\n",
      "148           Extra point by Ryan Killeen (USC) is good.\n",
      "166    40 yard field goal by Ryan Killeen (USC) is good.\n",
      "Name: play_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# fix uncategorized\n",
    "uncat = df.loc[df['play_type']=='Uncategorized']\n",
    "print(len(uncat))\n",
    "print(uncat.play_text.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rush' 'Pass Incompletion' 'Timeout' 'Penalty' 'Punt Return'\n",
      " 'Pass Interception' 'Pass Completion' 'Uncategorized'\n",
      " 'Kickoff Return (Offense)' 'End Period' 'Fumble Recovery (Own)' 'Sack'\n",
      " 'Fumble Recovery (Opponent)' 'Interception Return Touchdown'\n",
      " 'Blocked Punt' 'Safety' 'Two Point Pass' 'Kickoff Return Touchdown'\n",
      " 'Two Point Rush' 'Blocked Field Goal' 'Blocked Punt Touchdown'\n",
      " 'Blocked PAT' 'Punt Return Touchdown' 'Fumble Return Touchdown'\n",
      " 'Kickoff Return (Defense)' 'Blocked Field Goal Touchdown' 'Punt' 'Pass'\n",
      " 'Kickoff' 'Extra Point Good' 'Field Goal Good' 'Field Goal Missed'\n",
      " 'Extra Point Missed' '2pt Conversion' 'Offensive 1pt Safety'\n",
      " 'Pass Reception' 'Passing Touchdown' 'Rushing Touchdown'\n",
      " 'Pass Interception Return' 'End of Half' 'End of Game'\n",
      " 'Defensive 2pt Conversion' 'Missed Field Goal Return' 'Interception'\n",
      " 'Missed Field Goal Return Touchdown']\n"
     ]
    }
   ],
   "source": [
    "print(df.play_type.unique())\n",
    "def fix_uncat(play_type, play_text):\n",
    "    if play_type != 'Uncategorized':\n",
    "        return play_type\n",
    "    else:\n",
    "        if isinstance(play_text,str):\n",
    "            if \"Start of the 2nd quarter.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"Start of the 3rd quarter.\" in play_text:\n",
    "                return \"End of Half\"\n",
    "            elif \"Start of the 4th quarter.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"Start of overtime.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"End of the game.\" in play_text:\n",
    "                return \"End of Game\"\n",
    "            elif \"Extra point\" in play_text:\n",
    "                if \"is good\" in play_text:\n",
    "                    return \"Extra Point Good\"\n",
    "                elif \"is no good.\" in play_text[-13:]:\n",
    "                    return \"Extra Point Missed\"\n",
    "                else:\n",
    "                    return play_type\n",
    "            elif \"field goal\" in play_text:\n",
    "                if \"is good\" in play_text:\n",
    "                    return \"Field Goal Good\"\n",
    "                elif \"is no good.\" in play_text[-13:]:\n",
    "                    return \"Field Goal Missed\"\n",
    "                else:\n",
    "                    print(play_text)\n",
    "                    return play_type\n",
    "            elif \"missed PAT returned.\" in play_text:\n",
    "                return \"Extra Point Missed\"\n",
    "            elif \"took lateral and rushed\" in play_text:\n",
    "                return \"Rush\"\n",
    "            # mostly fumbled snaps recovered by own team\n",
    "            elif \"fumbled\" in play_text:\n",
    "                return \"Fumble Recovery (Own)\"\n",
    "            elif \"return for\" in play_text:\n",
    "                return \"Punt Return\"\n",
    "            elif \"End of\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"run for\" in play_text:\n",
    "                return \"Rush\"\n",
    "            elif \"SAFETY\" in play_text:\n",
    "                return \"Safety\"\n",
    "            elif \"Penalty\" in play_text:\n",
    "                return \"Penalty\"\n",
    "            else:\n",
    "                return play_type\n",
    "    return play_type\n",
    "\n",
    "df['play_type'] = df.apply(lambda row: fix_uncat(row['play_type'], row['play_text']),axis=1)\n",
    "\n",
    "# uncat = df.loc[df.play_type=='Uncategorized']\n",
    "# print(len(uncat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate extra point attempts\n",
    "xp_cats = ['Two Point Pass','Two Point Rush','Blocked PAT','Extra Point Good','Extra Point Missed', '2pt Conversion',\n",
    "          'Offensive 1pt Safety','Defensive 2pt Conversion']\n",
    "xps = df.loc[df['play_type'].isin(xp_cats)]\n",
    "df = df.loc[~df['play_type'].isin(xp_cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate kickoffs\n",
    "kickoffs_cats = ['Kickoff Return (Offense)', 'Kickoff Return Touchdown', 'Kickoff Return (Defense)', 'Kickoff']\n",
    "kickoff_penalty_plays = ['KICKOFF', 'KICKOFF RETURN TD']\n",
    "kickoffs = df.loc[(df['play_type'].isin(kickoffs_cats)) | (df['drive_result']).isin(kickoff_penalty_plays)]\n",
    "df = df.loc[~df['play_type'].isin(kickoffs_cats)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate OT\n",
    "ot = df.loc[(df['period'] > 4) | (df['drive_result'] == 'POSSESSION (FOR OT DRIVES)')]\n",
    "df = df.loc[(df['period'] <= 4) & (df['period'] >0)]\n",
    "df = df.loc[df.drive_result != 'POSSESSION (FOR OT DRIVES)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop end of period plays\n",
    "\n",
    "eop = ['End of Game','End of Half','End Period']\n",
    "df = df.loc[~df['play_type'].isin(eop)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate\n",
    "# bad = df.loc[df['offense_x']!=df['offense_y']]\n",
    "# print(bad[['tr_game','play_text','offense_x','offense_y']].head(25))\n",
    "# offense_x seems to be correct while offense_y is not\n",
    "\n",
    "df = df.drop(columns=['defense_y','defense_conference_y','offense_y','offense_conference_y'])\n",
    "\n",
    "df = df.rename(columns={'defense_x':'defense','defense_conference_x':'defense_conference','offense_x':'offense','offense_conference_x':'offense_conference'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix bad distances\n",
    "\n",
    "zeros = df.loc[df['distance'] == 0]\n",
    "# print(len(zeros))\n",
    "# print(zeros.groupby(['play_type'])['distance'].count())\n",
    "# print(zeros.play_text.tail(50))\n",
    "\n",
    "# drop negative distances. change 0 distances to 0.5 yard\n",
    "df = df.loc[df['distance']>=0]\n",
    "\n",
    "df = df.rename(columns={'distance':'wrong_distance'})\n",
    "df['distance'] = np.where(df['wrong_distance']>0,df['wrong_distance'],0.5)\n",
    "df = df.drop(columns=['wrong_distance'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441\n"
     ]
    }
   ],
   "source": [
    "# fix bad downs\n",
    "zero_down = df.loc[df['down']==0]\n",
    "print(len(zero_down))\n",
    "\n",
    "# impute down + 1 from previous play, to max of 4\n",
    "df['down'] = np.where(df['down']>0,df['down'],df['down'].shift()+1)\n",
    "# still 18 bad\n",
    "\n",
    "df = df.loc[(df['down']>0)&(df['down']<5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clock\n",
    "Also, sometimes clock data is wrong. I messed with trying to predict time per play based on play type, but the data was prohibitively messy. Instead I'll just assume every play takes up the same percentage of drive time. The worst effect this will have is it will make incompletions look worse in late game situations, because incompletions will have the same time elapsed as completion. I guess this matters less in college football, because the clock stops on a first down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['away', 'defense', 'defense_conference', 'defense_score', 'down', 'drive_id', 'home', 'id', 'offense', 'offense_conference', 'offense_score', 'period', 'play_text', 'play_type', 'yard_line', 'yards_gained', 'season', 'week', 'season_type', 'drive_result', 'elapsed.minutes', 'elapsed.seconds', 'end_period', 'end_time.minutes', 'end_time.seconds', 'end_yardline', 'game_id', 'plays', 'scoring', 'start_period', 'start_time.minutes', 'start_time.seconds', 'start_yardline', 'yards', 'tr_game', 'tr_half', 'distance', 'drive_time']\n"
     ]
    }
   ],
   "source": [
    "# fix negative drive times first, they mostly contain actual plays\n",
    "df['elapsed.minutes'] = df['elapsed.minutes'].copy().fillna(0)\n",
    "df['elapsed.seconds'] = df['elapsed.seconds'].copy().fillna(0)\n",
    "df['drive_time'] = 60*df['elapsed.minutes'] + df['elapsed.seconds']\n",
    "cols = list(df)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can't find systematic error, just going to reverse start and end time. the reversed data\n",
    "# seems to make sense\n",
    "\n",
    "\n",
    "negs = df.loc[df.drive_time < 0].copy()\n",
    "negs = negs[cols]\n",
    "neg_ids = list(negs.drive_id.unique())\n",
    "df = df.loc[~df.drive_id.isin(neg_ids)]\n",
    "\n",
    "negs = negs.rename(columns={'elapsed.minutes':'wrong_em','elapsed.seconds':'wrong_es',\n",
    "                            'start_time.minutes':'wrong_sm','start_time.seconds':'wrong_ss',\n",
    "                            'end_time.minutes':'wrong_etm','end_time.seconds':'wrong_ets',\n",
    "                            'drive_time':'wrong_dt'\n",
    "                           })\n",
    "\n",
    "negs['start_time.minutes'] = negs['wrong_etm'].copy()\n",
    "negs['start_time.seconds'] = negs['wrong_ets'].copy()\n",
    "\n",
    "negs['end_time.minutes'] = negs['wrong_sm'].copy()\n",
    "negs['end_time.seconds'] = negs['wrong_ss'].copy()\n",
    "\n",
    "negs['elapsed.minutes'] = negs['wrong_em'].copy().abs()\n",
    "negs['elapsed.seconds'] = negs['wrong_es'].copy().abs()\n",
    "negs['drive_time'] = negs['wrong_dt'].copy().abs()\n",
    "\n",
    "drop_cols = ['wrong_em','wrong_es','wrong_sm','wrong_ss','wrong_etm','wrong_ets','wrong_dt']\n",
    "negs = negs.drop(columns=drop_cols)\n",
    "\n",
    "negs = negs[cols]\n",
    "df = pd.concat([df,negs],sort=False)\n",
    "df = df.sort_values(by=['game_id','tr_game','drive_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now work on fixing nan drive timea\n",
    "df['drive_time'] = 60*df['elapsed.minutes'] + df['elapsed.seconds']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = df.loc[df.drive_time == 0]\n",
    "zgb = zeros.groupby(['plays'])['start_time.minutes'].count()\n",
    "\n",
    "# zero play drives are fumble recoveries by the other team or punt returns\n",
    "# fumble recoveries are on the first play of the drive and are actually correct\n",
    "# need to fix punt returns\n",
    "\n",
    "# print(zplay.drive_id.head())\n",
    "\n",
    "zpunts = zeros.loc[(zeros.plays==0)&(zeros.play_type=='Punt Return')]\n",
    "\n",
    "zp_dids = list(zpunts.drive_id.unique())\n",
    "zp_mo = [(x-1) for x in zp_dids]\n",
    "\n",
    "if len(zp_dids) > 0:\n",
    "    df.loc[df.drive_id.isin(zp_mo), 'drive_result'] = 'Punt'\n",
    "    df.loc[df.drive_id.isin(zp_dids), 'drive_time'] = 500\n",
    "    print(df.loc[df['drive_id'].isin(zp_dids)].head())\n",
    "    df.loc[df['drive_id'].isin(zp_dids), 'drive_id'] = df['drive_id'].subtract(1)\n",
    "    print(df.loc[df['drive_id'].isin(zp_dids)].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I try to fix drive times of zero seconds with more than zero plays. My idea was get the time remaining of the next drive, and subtract that from the time remaining of the current drive. Unfortunately that only worked for about half the drives. And, most of the drives it did work on, only resulted in drive times of under a minute. That seemed off and I didn't see an obvious reason why. I decided just to drop these drives. That's about 3% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now fix drives with more than zero plays\n",
    "# mplays = zeros.loc[zeros.plays>0]\n",
    "# # print(len(mplays))\n",
    "\n",
    "# # get the time remaining for the next drive\n",
    "# mp_dids = list(mplays.drive_id.unique())\n",
    "# mp_next = [(x+1) for x in mp_dids]\n",
    "# # print(len(mp_dids))\n",
    "\n",
    "# next_df = df.loc[df.drive_id.isin(mp_next)]\n",
    "\n",
    "# ngb = next_df.groupby(['drive_id'])['tr_game'].max().reset_index()\n",
    "# ngb['drive_id'] = ngb['drive_id'] - 1\n",
    "# ngb = ngb.rename(columns={'tr_game':'end_drive_time'})\n",
    "\n",
    "# mgb = mplays.groupby(['drive_id'])['tr_game'].min().reset_index()\n",
    "# mgb = pd.merge(left=mgb, right=ngb, on=['drive_id','drive_id'], how='left')\n",
    "# mgb = mgb.rename(columns={'tr_game':'start_drive_time'})\n",
    "\n",
    "# mgb['new_elapsed'] = mgb['start_drive_time'] - mgb['end_drive_time']\n",
    "\n",
    "# new_dt = mgb.loc[mgb['new_elapsed'] > 0]\n",
    "\n",
    "# ndt_ids = list(new_dt.drive_id.unique())\n",
    "\n",
    "# test = df.loc[df.drive_id.isin(ndt_ids)]\n",
    "# print(test.groupby(['play_type'])['down'].count())\n",
    "\n",
    "# # mplays = pd.merge(left=mplays, right=ngb, on=['drive_id','drive_id'], how='left')\n",
    "\n",
    "# # mplays['new_elapsed'] = mplays['tr_game'] - mplays['end_drive_time']\n",
    "\n",
    "# # new = mplays.loc[mplays['new_elapsed'] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1927091\n",
      "1878447\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df.loc[df['drive_time']>0]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Bad Drive Results, Standardize Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix drive result kickoffs\n",
    "kos = df.loc[(df['drive_result']=='KICKOFF')]\n",
    "dids = list(kos.drive_id.unique())\n",
    "\n",
    "fgs = df.loc[(df['drive_id'].isin(dids))&df['play_text'].str.contains('Field Goal')]\n",
    "fg_ids = list(fgs.drive_id.unique())\n",
    "\n",
    "df.loc[df.drive_id.isin(fg_ids), 'drive_result'] = 'FG GOOD'\n",
    "\n",
    "\n",
    "punts = [4005483434]\n",
    "end_of_half = [40054770815]\n",
    "\n",
    "df.loc[df.drive_id.isin(punts), 'drive_result'] = 'PUNT'\n",
    "df.loc[df.drive_id.isin(end_of_half), 'drive_result'] = 'END OF HALF'\n",
    "\n",
    "# special cases\n",
    "\n",
    "df.loc[df.drive_id == 24269009911, 'drive_result'] = 'RUSHING TD'\n",
    "df.loc[df.drive_id == 24269009911, 'drive_id'] = 24269009912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix Fg missed TDs\n",
    "brt = df.loc[(df['drive_result']=='FG MISSED TD')&df['play_text'].str.contains('BLOCKED')]\n",
    "brt_ids = list(brt.drive_id.unique())\n",
    "\n",
    "df.loc[df['drive_id'].isin(brt_ids), 'drive_result'] = 'BLOCKED FG (TD) TD'\n",
    "\n",
    "brt = df.loc[(df['drive_result']=='FG MISSED TD')&df['play_text'].str.contains('blocked')]\n",
    "brt_ids = list(brt.drive_id.unique())\n",
    "\n",
    "df.loc[df['drive_id'].isin(brt_ids), 'drive_result'] = 'BLOCKED FG (TD) TD'\n",
    "\n",
    "brt = df.loc[(df['drive_result']=='FG MISSED TD')&df['play_text'].str.contains('blocked,')]\n",
    "brt_ids = list(brt.drive_id.unique())\n",
    "\n",
    "df.loc[df['drive_id'].isin(brt_ids), 'drive_result'] = 'BLOCKED FG (TD) TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge 'FG' and 'FG GOOD'\n",
    "df.loc[df['drive_result']=='FG', 'drive_result'] = 'FG GOOD' \n",
    "df.loc[df['drive_result']=='MADE FG', 'drive_result'] = 'FG GOOD' \n",
    "\n",
    "df.loc[df['drive_result']=='MISSED FG', 'drive_result'] = 'FG MISSED' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix 'end of half TD'\n",
    "end_of_half = [29290230615,29304013515,32259006215,32308025415,32315015219,33250230613,33285263815,33327000821,40060388027]\n",
    "fumble_tds = [30279211614]\n",
    "int_tds = [30282006815,40079088219]\n",
    "rush_tds = [30247263316,30268006217,32243211716,32301000917,40054794315]\n",
    "pass_tds = [30324002112,32329023512]\n",
    "block_fg_td = [40054834612]\n",
    "\n",
    "df.loc[df['drive_id'].isin(end_of_half), 'drive_result'] = 'END OF HALF'\n",
    "df.loc[df['drive_id'].isin(fumble_tds), 'drive_result'] = 'FUMBLE RETURN TD'\n",
    "df.loc[df['drive_id'].isin(int_tds), 'drive_result'] = 'INT TD'\n",
    "df.loc[df['drive_id'].isin(rush_tds), 'drive_result'] = 'RUSHING TD'\n",
    "df.loc[df['drive_id'].isin(pass_tds), 'drive_result'] = 'PASSING TD'\n",
    "df.loc[df['drive_id'].isin(block_fg_td), 'drive_result'] = 'BLOCKED FG (TD) TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix \"end of game TD\"\n",
    "int_tds = [30324020406,40087609227]\n",
    "fumble_tds = [40076354226,40086912120]\n",
    "end_of_game = [40078746229,40094526122]\n",
    "\n",
    "df.loc[df['drive_id'].isin(int_tds), 'drive_result'] = 'INT TD'\n",
    "df.loc[df['drive_id'].isin(fumble_tds), 'drive_result'] = 'FUMBLE RETURN TD'\n",
    "df.loc[df['drive_id'].isin(end_of_game), 'drive_result'] = 'END OF GAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix \"downs TD\"\n",
    "passing_tds = [40054825721,4007635338,40076343011,40086953320,4010133465,4010128564]\n",
    "rushing_tds = [40054786022,40060392118,40086953316]\n",
    "interception_tds = [4005482704,40075690213,40076355220,4008696135,40086963817]\n",
    "\n",
    "df.loc[df['drive_id'].isin(passing_tds), 'drive_result'] = 'PASSING TD'\n",
    "df.loc[df['drive_id'].isin(rushing_tds), 'drive_result'] = 'RUSHING TD'\n",
    "df.loc[df['drive_id'].isin(interception_tds), 'drive_result'] = 'INT TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix 'FG TD' drive result\n",
    "df.loc[((df.drive_id == 40054786811)&(df.offense=='Baylor')), 'drive_result'] = 'FG GOOD'\n",
    "df.loc[((df.drive_id == 40054786811)&(df.offense=='Baylor')), 'drive_id'] = 4005478681100\n",
    "\n",
    "df.loc[(df.drive_id == 40054786811), 'drive_result'] = 'RUSHING TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix \"end of 4th\"\n",
    "df.loc[df['drive_result']=='END OF 4TH QUARTER', 'drive_result'] = 'END OF GAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex from a duplicate axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b2309a88046a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drive_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_fix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'drive_result'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'BLOCKED FG (TD) TD'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drive_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbfg_dids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'drive_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drive_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_align_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0minfo_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minfo_axis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_align_series\u001b[0;34m(self, indexer, ser, multiindex_indexer)\u001b[0m\n\u001b[1;32m    738\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_ix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# 2 dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m   3736\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3737\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3738\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3740\u001b[0m     def drop(self, labels=None, axis=0, index=None, columns=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4354\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4355\u001b[0m         return self._reindex_axes(axes, level, limit, tolerance, method,\n\u001b[0;32m-> 4356\u001b[0;31m                                   fill_value, copy).__finalize__(self)\n\u001b[0m\u001b[1;32m   4357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4358\u001b[0m     def _reindex_axes(self, axes, level, limit, tolerance, method, fill_value,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   4372\u001b[0m             obj = obj._reindex_with_indexers({axis: [new_index, indexer]},\n\u001b[1;32m   4373\u001b[0m                                              \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4374\u001b[0;31m                                              copy=copy, allow_dups=False)\n\u001b[0m\u001b[1;32m   4375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4376\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4488\u001b[0m                                                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4489\u001b[0m                                                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4490\u001b[0;31m                                                 copy=copy)\n\u001b[0m\u001b[1;32m   4491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   3085\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3087\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3089\u001b[0m     def reindex(self, target, method=None, level=None, limit=None,\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"
     ]
    }
   ],
   "source": [
    "# more blocked field goals\n",
    "bfg_ids = [242550275,242760259,243250150,243250344]\n",
    "bfg_dids = [24255027512,24276025916,24325015008,24325034420]\n",
    "to_fix = [(x-1) for x in bfg_dids]\n",
    "\n",
    "df.loc[df['drive_id'].isin(to_fix), 'drive_result'] = 'BLOCKED FG (TD) TD' \n",
    "df.loc[df['drive_id'].isin(bfg_dids), 'drive_id'] = df['drive_id'].copy().subtract(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blocked punts\n",
    "bps = list(df.loc[df['drive_result']=='BLOCKED PUNT TD'].drive_id.unique())\n",
    "to_fix = [(x-1) for x in bps]\n",
    "\n",
    "df.loc[df['drive_id'].isin(to_fix), 'drive_result'] = 'BLOCKED PUNT TD' \n",
    "df.loc[df['drive_id'].isin(bps), 'drive_id'] = df.drive_id.copy() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the drive data in these games seems very off\n",
    "bad_ids = [252602572,272560120,272562005]\n",
    "df = df.loc[~df.game_id.isin(bad_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## attempt to predict clock, can ignore\n",
    "\n",
    "# going to try to build a model to approximate off good data\n",
    "\n",
    "# drop drives when they have the same clock for more than 8 plays\n",
    "# gb = df[['game_id','drive_id','tr_game','down','plays']]\n",
    "# mode = gb.groupby(['drive_id','tr_game'])['plays'].count().reset_index()\n",
    "# mode = mode.sort_values(by='plays',ascending=False)\n",
    "\n",
    "# bad_drives = mode.loc[mode['plays']>=8]\n",
    "# print(len(bad_drives))\n",
    "# bd_list = list(bad_drives.drive_id.unique())\n",
    "\n",
    "\n",
    "# drop bad drives from data\n",
    "# clock = df.loc[~df['drive_id'].isin(bd_list)]\n",
    "# print(len(clock))\n",
    "\n",
    "# only use long drives in model (this also drops small drives with still clock)\n",
    "# clock = clock.loc[clock.plays>=10]\n",
    "# print(len(clock))\n",
    "\n",
    "# need time elapsed\n",
    "# clock = clock.sort_values(by=['game_id','drive_id','tr_game'],ascending=False)\n",
    "# clock['tr_game_next'] = clock.groupby(['drive_id'])['tr_game'].transform(lambda x:x.shift(-1))\n",
    "\n",
    "# print(clock[['drive_id','tr_game','tr_game_next']])\n",
    "\n",
    "# clock['tr_game_next'] = clock['tr_game_next'].fillna(3600)\n",
    "# clock = clock.dropna(subset=['tr_game_next'])\n",
    "\n",
    "# clock['play_time'] = clock['tr_game'] - clock['tr_game_next']\n",
    "\n",
    "# # drop values that are still bad\n",
    "# clock = clock.loc[(clock.play_time>=1)&(clock.play_time <= 80)]\n",
    "\n",
    "# print(clock[['tr_game','tr_game_next','play_time']].head(50))\n",
    "\n",
    "# print(clock.groupby(['play_type'])['play_time'].mean())\n",
    "# print(clock.groupby(['play_type'])['play_time'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "### Need 6 Features:\n",
    "-Down (check)  \n",
    "-Seconds left in half (check)  \n",
    "-Yards to go for touchdown (log?)  \n",
    "-Yards to go for first down (log?)    \n",
    "-Goal to goal indicator  \n",
    "-Under 2 minutes indicator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix yard_line, it's w.r.t the home team\n",
    "df = df.rename(columns={'yard_line':'wrong_yardline'})\n",
    "df['yard_line'] = np.where(df['offense']==df['home'],df['wrong_yardline'],100-df['wrong_yardline'])\n",
    "# print(df[['home','offense','yard_line','wrong_yardline']].head(50))\n",
    "df = df.drop(columns=['wrong_yardline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get log 10 of distance\n",
    "df['l10_dist'] = np.log10(df['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal to go\n",
    "df['GTG'] = np.where((df['yard_line']+df['distance']>=100),1,0)\n",
    "\n",
    "\n",
    "# under two min in half\n",
    "df['UTM'] = np.where(df['tr_half']<=120,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './output/processed.csv'\n",
    "df.to_csv(PATH,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
