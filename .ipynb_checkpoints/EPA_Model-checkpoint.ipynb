{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "import requests\n",
    "gc.collect()\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:17<00:00,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2122188 plays were loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "years = list(range(2004, int(datetime.datetime.now().year)))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year in tqdm(years):\n",
    "    path = './output/'+str(year)+'/'+str(year)+'_pbp.csv'\n",
    "    sea_df = pd.read_csv(path)\n",
    "    df = pd.concat([df,sea_df])\n",
    "\n",
    "num_plays = len(df)\n",
    "print(str(num_plays) + \" plays were loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-12a60c97042e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2018\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://api.collegefootballdata.com/drives?seasonType=regular&year='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "year = 2018\n",
    "\n",
    "drive_data = pd.DataFrame(requests.get('https://api.collegefootballdata.com/drives?seasonType=regular&year=' + str(year)).json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(drive_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rush', 'Pass Incompletion', 'Timeout', 'Penalty', 'Punt Return', 'Pass Interception', 'Pass Completion', 'Uncategorized', 'Kickoff Return (Offense)', 'End Period', 'Fumble Recovery (Own)', 'Sack', 'Fumble Recovery (Opponent)', 'Interception Return Touchdown', 'Blocked Punt', 'Safety', 'Two Point Pass', 'Kickoff Return Touchdown', 'Two Point Rush', 'Blocked Field Goal', 'Blocked Punt Touchdown', 'Blocked PAT', 'Punt Return Touchdown', 'Fumble Return Touchdown', 'Kickoff Return (Defense)', 'Blocked Field Goal Touchdown', 'Punt', 'Pass', 'Kickoff', 'Extra Point Good', 'Field Goal Good', 'Field Goal Missed', 'Extra Point Missed', '2pt Conversion', 'Offensive 1pt Safety', 'Pass Reception', 'Passing Touchdown', 'Rushing Touchdown', 'Pass Interception Return', 'End of Half', 'End of Game', 'Defensive 2pt Conversion', 'Missed Field Goal Return', 'Interception', 'Missed Field Goal Return Touchdown']\n"
     ]
    }
   ],
   "source": [
    "# print(list(df))\n",
    "print(list(df.play_type.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for no play text\n",
    "df['play_text'] = df['play_text'].to_string()\n",
    "\n",
    "# nans = df.loc[df['play_text']=='NaN']\n",
    "df['empties'] = np.where(len(df['play_text'])<4,1,0)\n",
    "empties = df.loc[df['empties']==1]\n",
    "\n",
    "print(empties.play_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5580\n"
     ]
    }
   ],
   "source": [
    "# fix Uncategorized play types \n",
    "# 5,580\n",
    "\n",
    "uncat = df.loc[df['play_type']=='Uncategorized']\n",
    "print(len(uncat))\n",
    "print(uncat.play_text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate kickoffs\n",
    "kickoffs_cats = ['Kickoff Return (Offense)', 'Kickoff Return Touchdown', 'Kickoff Return (Defense)', 'Kickoff']\n",
    "kickoffs = df.loc[df['play_type'].isin(kickoffs_cats)]\n",
    "df = df.loc[~df['play_type'].isin(kickoffs_cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate extra point attempts\n",
    "xp_cats = ['Two Point Pass','Two Point Rush','Blocked PAT','Extra Point Good','Extra Point Missed', '2pt Conversion',\n",
    "          'Offensive 1pt Safety','Defensive 2pt Conversion']\n",
    "xps = df.loc[df['play_type'].isin(xp_cats)]\n",
    "df = df.loc[~df['play_type'].isin(xp_cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96193\n",
      "['Extra point by Ryan Killeen (USC) is good.'\n",
      " 'Trojans fumble by Alex Holmes (USC), recovered by Alex Holmes (USC), advanced for no gain.'\n",
      " 'Extra point by Brandon Pace (VT) is good.' ...\n",
      " 'Riley Lees 4 Yd pass from Clayton Thorson (Charlie Kuhbander Kick)'\n",
      " 'Jared McGee 82 Yd Fumble Return (Charlie Kuhbander Kick)'\n",
      " 'Riley Lees 8 Yd Run (Charlie Kuhbander Kick)']\n"
     ]
    }
   ],
   "source": [
    "zeros = df.loc[df['distance']==0]\n",
    "print(len(zeros))\n",
    "print(zeros.play_text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "3940     DeAngelo Hall (VT) took lateral and rushed for...\n",
      "11077    Terrence Biggers (MSU) took lateral and rushed...\n",
      "11092    Derek Abney (UK) took lateral and rushed for 1...\n",
      "13313    Terrance Phillips (PSU) took lateral and rushe...\n",
      "28227    Andrico Hines (MTSU) took lateral and rushed f...\n",
      "30739    Lance Pendleton (BYU) took lateral and rushed ...\n",
      "31087    Chris Bruhn (WSU) took lateral and rushed for ...\n",
      "33853    Tim Blackwell (USM) took lateral and rushed fo...\n",
      "36684    Bruce Gradkowski (TOL) took lateral and rushed...\n",
      "39523    Michael Turner (NIU) took lateral and rushed f...\n",
      "43241    Jason Samples (TSU) took lateral and rushed fo...\n",
      "48186    Steve Breaston (MICH) took lateral and rushed ...\n",
      "52925    Duane Coleman (CLEM) took lateral and rushed f...\n",
      "53764    Scott Lunde (WSU) took lateral and rushed for ...\n",
      "63806    Aric Williams (OSU) took lateral and rushed fo...\n",
      "75692    Garrett Lepisto (UCLA) took lateral and rushed...\n",
      "83122    Sean Taylor (MIA) took lateral and rushed for ...\n",
      "88638    Mike Williams (USC) took lateral and rushed fo...\n",
      "93369    Leon Washington (FSU) took lateral and rushed ...\n",
      "94973    Mark Bradley (OKLA) took lateral and rushed fo...\n",
      "1037                                           Begin Drive\n",
      "1040                                           Begin Drive\n",
      "1047                                           Begin Drive\n",
      "1626     Carlos Ousley (ARK) took lateral and rushed fo...\n",
      "16304    Kelvin Hayden (ILL) took lateral and rushed fo...\n",
      "20855    Norval McKenzie (VAN) took lateral and rushed ...\n",
      "21039                                          Begin Drive\n",
      "23547    Jason Leach (USC) took lateral and rushed for ...\n",
      "24342                                          Begin Drive\n",
      "26454    Jemalle Cornelius (FLA) took lateral and rushe...\n",
      "30534                                          Begin Drive\n",
      "30768    Marcus Rucker (RICE) took lateral and rushed f...\n",
      "31293    Eric Green (VT) took lateral and rushed for 47...\n",
      "35455                                          Begin Drive\n",
      "37355                                          Begin Drive\n",
      "37725    Tres Moses (RU) took lateral and rushed for no...\n",
      "38305    Sid Slater (CAL) took lateral and rushed for 1...\n",
      "42191                                          Begin Drive\n",
      "42201                                          Begin Drive\n",
      "46312    Roscoe Parrish (MIA) took lateral and rushed f...\n",
      "51256    Brian Brosnan (ILL) took lateral and rushed fo...\n",
      "57130                                          Begin Drive\n",
      "57723    Chris Leak (FLA) took lateral and rushed for 5...\n",
      "57724    O.J. Small (FLA) took lateral and rushed for -...\n",
      "59586    Chris Markey (UCLA) took lateral and rushed fo...\n",
      "61266                                          Begin Drive\n",
      "61275                                          Begin Drive\n",
      "61289                                          Begin Drive\n",
      "62967    Darrell Blackman (NCST) took lateral and rushe...\n",
      "63273                                          Begin Drive\n",
      "Name: play_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def fix_uncat(play_type, play_text):\n",
    "    if play_type != 'Uncategorized':\n",
    "        return play_type\n",
    "    else:\n",
    "        if isinstance(play_text,str):\n",
    "            if \"Start of the 1st quarter.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"Start of the 2nd quarter.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"Start of the 3rd quarter.\" in play_text:\n",
    "                return \"End of Half\"\n",
    "            elif \"Start of the 4th quarter.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"Start of overtime.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"End of the game.\" in play_text:\n",
    "                return \"End of Game\"\n",
    "            elif \"Extra point\" in play_text:\n",
    "                if \"is good\" in play_text:\n",
    "                    return \"Extra Point Good\"\n",
    "                elif \"is no good.\" in play_text[-13:]:\n",
    "                    return \"Extra Point Missed\"\n",
    "                else:\n",
    "                    return play_type\n",
    "            elif \"field goal\" in play_text:\n",
    "                if \"is good\" in play_text:\n",
    "                    return \"Field Goal Good\"\n",
    "                elif \"is no good.\" in play_text[-13:]:\n",
    "                    return \"Field Goal Missed\"\n",
    "                else:\n",
    "                    print(play_text)\n",
    "                    return play_type\n",
    "            elif \"missed PAT returned.\" in play_text:\n",
    "                return \"Extra Point Missed\"\n",
    "            else:\n",
    "                return play_type\n",
    "    return play_type\n",
    "\n",
    "df['play_type'] = df.apply(lambda row: fix_uncat(row['play_type'], row['play_text']),axis=1)\n",
    "\n",
    "uncat = df.loc[df.play_type=='Uncategorized']\n",
    "print(len(uncat))\n",
    "print(uncat.play_text.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need Separate Model for XP, Kickoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2223578\n",
      "272728\n",
      "1950850\n"
     ]
    }
   ],
   "source": [
    "# drop_cols\n",
    "separate = ['End Period', 'Kickoff Return (Offense)', 'Extra Point Good', 'Timeout',\n",
    " 'End of Half', 'End of Game', 'Two Point Pass', 'Two Point Rush', \n",
    " 'Kickoff Return (Defense)', 'Uncategorized', 'Kickoff Return Touchdown', 'Blocked PAT','Kickoff', \n",
    " 'Extra Point Missed', '2pt Conversion', 'Defensive 2pt Conversion', 'Offensive 1pt Safety']\n",
    "\n",
    "print(len(df))\n",
    "sep_df = df.loc[df.play_type.isin(separate)]\n",
    "print(len(sep_df))\n",
    "df = df.loc[~df.play_type.isin(separate)]\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950850\n",
      "1944000\n"
     ]
    }
   ],
   "source": [
    "# drop overtime and 61 period 0 entries\n",
    "print(len(df))\n",
    "df = df.loc[df.period.isin([1,2,3,4])]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 25.0, 45.0, 30.0, 11.0, 15.0, 40.0, 55.0, 18.0, 22.0, 54.0, 23.0, 33.0, 44.0, 20.0, 34.0, 4.0, 10.0, 53.0, 56.0, 51.0, 21.0, 6.0, 16.0, 46.0, 3.0, 58.0, 7.0, 47.0, 27.0, 57.0, 17.0, 48.0, 37.0, 24.0, 14.0, 50.0, 5.0, 35.0, 43.0, 39.0, 52.0, 26.0, 36.0, 42.0, 12.0, 2.0, 32.0, 28.0, 8.0, 31.0, 19.0, 9.0, 29.0, 13.0, 41.0, 59.0, 38.0, 49.0, 1.0]\n",
      "clock.seconds\n",
      "0.0     198033\n",
      "30.0     68195\n",
      "45.0     55273\n",
      "50.0     49608\n",
      "15.0     49477\n",
      "20.0     48352\n",
      "40.0     47525\n",
      "55.0     46692\n",
      "10.0     44460\n",
      "25.0     39756\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# instead of zero its nan for clock.seconds and clock.minutes\n",
    "df['clock.seconds'] = df['clock.seconds'].fillna(0)\n",
    "df['clock.minutes'] = df['clock.minutes'].fillna(0)\n",
    "\n",
    "print(list(df['clock.seconds'].unique()))\n",
    "\n",
    "gb = df.groupby(['clock.seconds'])['id'].count()\n",
    "gb = gb.sort_values(ascending=False)\n",
    "print(gb.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   period  clock.minutes  clock.seconds  tr_half  tr_game\n",
      "2       1           14.0            0.0   1740.0   3540.0\n",
      "3       1           14.0           25.0   1765.0   3565.0\n",
      "4       1           14.0           45.0   1785.0   3585.0\n",
      "5       1           13.0           30.0   1710.0   3510.0\n",
      "6       1           11.0           11.0   1571.0   3371.0\n"
     ]
    }
   ],
   "source": [
    "# # calculate time remaining in half\n",
    "def tr_half(period, minutes, seconds):\n",
    "    tr = 0\n",
    "    if period in [1,3]:\n",
    "        # add a quarter of time remaining\n",
    "        tr += 900\n",
    "    tr += (60 * minutes + seconds)\n",
    "    return tr\n",
    "\n",
    "def tr_game(period, minutes, seconds):\n",
    "    quarters_left = 4-period\n",
    "    added_secs = 15*60*quarters_left\n",
    "    return (60*minutes + seconds + added_secs)\n",
    "\n",
    "df['tr_half'] = df.apply(lambda row: tr_half(row['period'],row['clock.minutes'],row['clock.seconds']),axis=1)\n",
    "df['tr_game'] = df.apply(lambda row: tr_game(row['period'],row['clock.minutes'],row['clock.seconds']),axis=1)\n",
    "\n",
    "print(df[['period','clock.minutes','clock.seconds','tr_half','tr_game']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop clock numbers, not needed anymore \n",
    "df = df.drop(columns=['clock.minutes','clock.seconds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Desired Features\n",
    "\n",
    "Need 6 feature variables. 2 weighting variables. and one target.\n",
    "\n",
    "6 features:  \n",
    "-Down  \n",
    "-Seconds left in half  \n",
    "-Yards to go for touchdown (log?)  \n",
    "-Yards to go for first down (log?)  \n",
    "-Goal to goal indicator  \n",
    "-Under 2 minutes indicator  \n",
    "\n",
    "2 weights:  \n",
    "-number of drives to next score\n",
    "-absolute score differential\n",
    "\n",
    "Also need target variable, next score relative to current offense.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944000\n",
      "1943642\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df.dropna(subset=['play_text'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tds(play_type, play_text):\n",
    "    if play_type != 'Penalty':\n",
    "        if isinstance(play_text, str):\n",
    "            if 'Touchdown' in play_type:\n",
    "                return 1\n",
    "            elif 'touchdown' in play_text:\n",
    "                return 1\n",
    "            elif 'for a TD' in play_text:\n",
    "                return 1\n",
    "    return 0\n",
    "    \n",
    "df['touchdown'] = df.apply(lambda row: add_tds(row['play_type'],row['play_text']), axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pass Completion', 'Blocked Punt Touchdown', 'Rush', 'Fumble Recovery (Own)', 'Interception Return Touchdown', 'Punt Return Touchdown', 'Fumble Return Touchdown', 'Blocked Field Goal Touchdown', 'Missed Field Goal Return Touchdown', 'Sack', 'Pass Incompletion', 'Passing Touchdown', 'Rushing Touchdown', 'Punt', 'Fumble Recovery (Opponent)', 'Pass Reception', 'Blocked Punt', 'Pass Interception Return', 'Blocked Field Goal']\n"
     ]
    }
   ],
   "source": [
    "td_plays = df.loc[df['touchdown']==1]\n",
    "print(list(td_plays.play_type.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "defensive_tds = ['Blocked Punt Touchdown', 'Interception Return Touchdown','Punt Return Touchdown',\n",
    "            'Fumble Return Touchdown','Blocked Field Goal Touchdown','Missed Field Goal Return Touchdown',\n",
    "             'Sack']\n",
    "\n",
    "not_touchdowns = ['Pass Incompletion']\n",
    "\n",
    "# create list for faster comparison\n",
    "dtd_nt = defensive_tds + not_touchdowns\n",
    "\n",
    "offensive_tds = ['Pass Completion','Rush','Fumble Recovery (Own)','Rushing Touchdown','Passing Touchdown']\n",
    "\n",
    "# split into offensive and defensive touchdowns\n",
    "\n",
    "df['offensive_TD'] = np.where(((~df['play_type'].isin(dtd_nt)) & (df['touchdown']==1)),1,0)\n",
    "\n",
    "df['defensive_TD'] = np.where(((df['play_type'].isin(defensive_tds)) & (df['touchdown']==1)),1,0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add field goals and safeties\n",
    "\n",
    "df['fg'] = np.where(df['play_type'] == 'Field Goal Good',1,0)\n",
    "df['safety'] = np.where(df['play_type'] == 'Safety',1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 32266005905 remove safety, it was on kickoff somehow\n",
    "df = df.loc[df['id']!=322660059036]\n",
    "\n",
    "## 4010320813 has two plays from 4010320812\n",
    "df.loc[df['id'] == 401032081101874002, ['drive_id']] = 4010320812\n",
    "df.loc[df['id'] == 401032081101907203, ['drive_id']] = 4010320812\n",
    "\n",
    "## 40054786811 has two drives\n",
    "df.loc[(df['drive_id']==40054786811) & (df['offense']=='Baylor'), ['drive_id']] = 4005478681100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_gb = df.groupby(['drive_id'])['offensive_TD','defensive_TD','fg','safety'].max().reset_index()\n",
    "\n",
    "drive_gb['drive_score'] = 7 * drive_gb['offensive_TD'] + -7 * drive_gb['defensive_TD'] + 3 * drive_gb['fg'] + -2 * drive_gb['safety']\n",
    "drive_gb['drive_score'] = drive_gb['drive_score'].astype(int)\n",
    "drive_gb = drive_gb[['drive_id','drive_score']]\n",
    "\n",
    "df = pd.merge(left=df, right=drive_gb, how='left', on=['drive_id','drive_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     drive_id  avg_drive_time\n",
      "0  4005476401         3518.75\n",
      "1  4005476402         3361.00\n",
      "2  4005476403         3255.25\n",
      "3  4005476404         3145.60\n",
      "4  4005476405         3064.50\n"
     ]
    }
   ],
   "source": [
    "# since clock numbers aren't consistent for some plays, I am sorting drives by average time remaining \n",
    "# of all plays on the drive\n",
    "\n",
    "tr = df.groupby(['drive_id'])['tr_game'].mean().reset_index()\n",
    "\n",
    "tr = tr.rename(columns={'tr_game':'avg_drive_time'})\n",
    "print(tr.head(5))\n",
    "\n",
    "df = pd.merge(left=df, right=tr, how='left', on=['drive_id','drive_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['half'] = np.where(df['period'] < 3, 1, 2)\n",
    "df['is_scoring_drive'] = np.where(df['drive_score'] != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# games=df.groupby(['game_id'])\n",
    "# print(len(games))\n",
    "\n",
    "# del df\n",
    "# gc.collect()\n",
    "\n",
    "# new_df = pd.DataFrame()\n",
    "\n",
    "# counter = 0\n",
    "# for game, game_plays in games:\n",
    "#     counter += 1\n",
    "#     if counter % 1000 == 0:\n",
    "#         print(counter)\n",
    "#     # sort by time remaining to order them\n",
    "#     ordered = game_plays.sort_values(by=['avg_drive_time'],ascending=False)\n",
    "#     # label drive numbers\n",
    "#     i = ordered.drive_id\n",
    "#     ordered['drive_no'] = i.ne(i.shift()).cumsum()\n",
    "    \n",
    "#     scoring_drives_1H = ordered.loc[(ordered['is_scoring_drive']==1)&(ordered['half']==1)].copy()\n",
    "#     scoring_drives_2H = ordered.loc[(ordered['is_scoring_drive']==1)&(ordered['half']==2)].copy()\n",
    "    \n",
    "#     # get last score of half drive number\n",
    "#     last_score_1H = scoring_drives_1H.drive_no.max()\n",
    "#     last_score_2H = scoring_drives_2H.drive_no.max()\n",
    "    \n",
    "#     # need drive numbers, drive scores, and drive offenses for each scoring drive for each half\n",
    "#     sdn_1H = scoring_drives_1H.drive_no.values\n",
    "#     sdn_2H = scoring_drives_2H.drive_no.values\n",
    "    \n",
    "#     ds_1H = scoring_drives_1H.drive_score.values\n",
    "#     ds_2H = scoring_drives_2H.drive_score.values\n",
    "    \n",
    "#     sdo_1H = scoring_drives_1H.offense.values\n",
    "#     sdo_2H = scoring_drives_2H.offense.values\n",
    "    \n",
    "#     # also need to split plays into first and second half\n",
    "#     drives_1H = ordered.loc[ordered['half']==1].copy()\n",
    "#     drives_2H = ordered.loc[ordered['half']==2].copy()\n",
    "    \n",
    "#     if len(drives_1H) < 1:\n",
    "#         continue\n",
    "#     if len(drives_2H) < 1:\n",
    "#         continue\n",
    "    \n",
    "#     # drive numbers for first half\n",
    "#     dn_1H = drives_1H.drive_no.values\n",
    "#     dn_2H = drives_2H.drive_no.values\n",
    "    \n",
    "#     # if last drive of half is not scoring drive, add dummy scoring drive with zeros\n",
    "#     # also treat cases where there are no scoring drives\n",
    "#     if len(sdn_1H) == 0:\n",
    "#         sdn_1H = np.append(sdn_1H, dn_1H[-1])\n",
    "#         ds_1H = np.append(ds_1H, 0)\n",
    "#         sdo_1H = np.append(sdo_1H, \"Dummy Offense\")\n",
    "#     elif sdn_1H[-1] < dn_1H[-1]:\n",
    "#         sdn_1H = np.append(sdn_1H, dn_1H[-1])\n",
    "#         ds_1H = np.append(ds_1H, 0)\n",
    "#         sdo_1H = np.append(sdo_1H, sdo_1H[-1])\n",
    "\n",
    "#     if len(sdn_2H) == 0:\n",
    "#         sdn_2H = np.append(sdn_2H, dn_2H[-1])\n",
    "#         ds_2H = np.append(ds_2H, 0)\n",
    "#         sdo_2H = np.append(sdo_2H, \"Dummy Offense\")\n",
    "#     elif sdn_2H[-1] < dn_2H[-1]:\n",
    "#         sdn_2H = np.append(sdn_2H, dn_2H[-1])\n",
    "#         ds_2H = np.append(ds_2H, 0)\n",
    "#         sdo_2H = np.append(sdo_2H, sdo_2H[-1])\n",
    "    \n",
    "#     # get index to lookup drive numbers, drive scores, and drive offenses\n",
    "#     drives_1H['next_idx'] = np.searchsorted(sdn_1H,dn_1H,'left')\n",
    "#     drives_2H['next_idx'] = np.searchsorted(sdn_2H,dn_2H,'left')\n",
    "    \n",
    "#     drives_1H['next_sd'] = sdn_1H[drives_1H.next_idx.values]\n",
    "#     drives_1H['dtns'] = drives_1H['next_sd'].astype(int) - drives_1H['drive_no'].astype(int)\n",
    "    \n",
    "#     drives_2H['next_sd'] = sdn_2H[drives_2H.next_idx.values]\n",
    "#     drives_2H['dtns'] = drives_2H['next_sd'].astype(int) - drives_2H['drive_no'].astype(int)\n",
    "    \n",
    "#     drives_1H['next_score'] = ds_1H[drives_1H.next_idx.values]\n",
    "#     drives_1H['ns_offense'] = sdo_1H[drives_1H.next_idx.values]\n",
    "    \n",
    "#     drives_2H['next_score'] = ds_2H[drives_2H.next_idx.values]\n",
    "#     drives_2H['ns_offense'] = sdo_2H[drives_2H.next_idx.values]\n",
    "    \n",
    "#     new_df = pd.concat([new_df,drives_1H])\n",
    "#     new_df = pd.concat([new_df,drives_2H])\n",
    "    \n",
    "    \n",
    "\n",
    "# print(len(new_df))\n",
    "# PATH = './output/master.csv'\n",
    "# new_df.to_csv(PATH,index=False)\n",
    "# del new_df\n",
    "# gc.collect()\n",
    "\n",
    "PATH = './output/master.csv'\n",
    "\n",
    "df= pd.read_csv(PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['away', 'defense', 'defense_conference', 'defense_score', 'distance', 'down', 'drive_id', 'home', 'id', 'offense', 'offense_conference', 'offense_score', 'period', 'play_text', 'play_type', 'yard_line', 'yards_gained', 'game_id', 'tr_half', 'tr_game', 'touchdown', 'offensive_TD', 'defensive_TD', 'fg', 'safety', 'drive_score', 'avg_drive_time', 'half', 'is_scoring_drive', 'drive_no', 'next_idx', 'next_sd', 'dtns', 'next_score', 'ns_offense']\n"
     ]
    }
   ],
   "source": [
    "print(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix/validate yardline log?\n",
    "df['offense_yard_line'] = np.where(df['home'] == df['offense'],df['yard_line'],(100-df['yard_line']))\n",
    "              \n",
    "df = df.drop(columns=['yard_line'])                                  \n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal to go\n",
    "df['GTG'] = np.where((df['offense_yard_line']+df['distance']==100),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# under two min in half\n",
    "df['UTM'] = np.where(df['tr_half']<=120,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1941622\n",
      "1936696\n"
     ]
    }
   ],
   "source": [
    "# indicator for kneels/drop them\n",
    "print(len(df))\n",
    "df = df[~df['play_text'].str.contains(\"kneel\")]\n",
    "df = df[~df['play_text'].str.contains(\"TEAM run for a loss\")]\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute score differential\n",
    "# scale\n",
    "# zero for more than 30\n",
    "\n",
    "df['score_diff'] = df['offense_score'] - df['defense_score']\n",
    "df['abs_SD'] = df['score_diff'].abs()\n",
    "df['SD_weight'] = np.maximum((30-df['abs_SD'])/(30),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dtns  dtns_weight  next_score\n",
      "0      8          0.0           7\n",
      "1      8          0.0           7\n",
      "2      8          0.0           7\n",
      "3      8          0.0           7\n",
      "4      8          0.0           7\n",
      "5      8          0.0           7\n",
      "6      8          0.0           7\n",
      "7      8          0.0           7\n",
      "8      8          0.0           7\n",
      "9      7          0.0           7\n",
      "10     7          0.0           7\n",
      "11     7          0.0           7\n",
      "12     7          0.0           7\n",
      "13     6          0.0           7\n",
      "14     6          0.0           7\n",
      "15     5          0.0           7\n",
      "16     5          0.0           7\n",
      "17     5          0.0           7\n",
      "18     5          0.0           7\n",
      "19     4          0.2           7\n",
      "20     4          0.2           7\n",
      "21     4          0.2           7\n",
      "22     4          0.2           7\n",
      "23     4          0.2           7\n",
      "24     4          0.2           7\n",
      "25     4          0.2           7\n",
      "26     4          0.2           7\n",
      "27     3          0.4           7\n",
      "28     3          0.4           7\n",
      "29     3          0.4           7\n",
      "..   ...          ...         ...\n",
      "45     0          1.0           7\n",
      "46     0          1.0           7\n",
      "47     0          1.0           7\n",
      "48     0          1.0           7\n",
      "49     0          1.0           7\n",
      "50     0          1.0           7\n",
      "51     1          0.8           3\n",
      "52     1          0.8           3\n",
      "53     0          1.0           3\n",
      "54     0          1.0           3\n",
      "55     0          1.0           3\n",
      "56     0          1.0           3\n",
      "57     0          1.0           7\n",
      "58     0          1.0           7\n",
      "59     0          1.0           7\n",
      "60     2          0.6           7\n",
      "61     2          0.6           7\n",
      "62     2          0.6           7\n",
      "63     2          0.6           7\n",
      "64     2          0.6           7\n",
      "65     2          0.6           7\n",
      "66     1          0.8           7\n",
      "67     1          0.8           7\n",
      "68     1          0.8           7\n",
      "69     1          0.8           7\n",
      "70     0          1.0           7\n",
      "71     0          1.0           7\n",
      "72     0          1.0           7\n",
      "73     0          1.0           7\n",
      "74     1          0.8           3\n",
      "\n",
      "[75 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# add weight for drives till next score\n",
    "df['dtns_weight'] = np.maximum((5-df['dtns'])/(5),0)\n",
    "\n",
    "print(df[['dtns','dtns_weight','next_score']].head(75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1936696\n",
      "1854667\n"
     ]
    }
   ],
   "source": [
    "# drop bad data\n",
    "print(len(df))\n",
    "df = df.loc[df['distance'] >= 0.5]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st down YTG log?\n",
    "# field YTG log?\n",
    "\n",
    "df['FD_YTG_log'] = np.log10(df['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Larry Johnson (PSU) rushed left side for 17 yards.'\n",
      " 'Horned Frogs fumble by Sean Stilley (TCU), recovered by Drew Wood (CSU), 7 yard return.'\n",
      " 'Fabian Walker (FSU) pass right side intercepted by Bruce Thornton (GA). Returned for a 71 yard touchdown.'\n",
      " ... 'Napoleon Maxwell run for 1 yd to the FlaIn 36'\n",
      " 'LeVante Bellamy run for 11 yds to the WMich 37 LeVante Bellamy fumbled, recovered by Toled Jamal Hines'\n",
      " 'Charlie Brewer pass intercepted Shea Campbell return for 2 yds to the Bayl 33']\n"
     ]
    }
   ],
   "source": [
    "drives = df.groupby(['drive_id'])['dtns','drive_score'].count().reset_index()\n",
    "\n",
    "drive_ids = drives.loc[drives['dtns']==1]\n",
    "\n",
    "di_ones = list(drive_ids.drive_id.values)\n",
    "\n",
    "one_play = df.loc[df['drive_id'].isin(di_ones)]\n",
    "\n",
    "print(one_play.play_text.values)\n",
    "\n",
    "# gb = drives.groupby(['drive_score']).count().reset_index()\n",
    "# gb['rate'] = gb['drive_id']/(gb['drive_id'].sum())\n",
    "# print(gb)\n",
    "# print(drives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
