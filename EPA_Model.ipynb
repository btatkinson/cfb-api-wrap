{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:22<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2223578 plays were loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "years = list(range(2004, int(datetime.datetime.now().year)))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year in tqdm(years):\n",
    "    path = './output/'+str(year)+'/'+str(year)+'_pbp.csv'\n",
    "    sea_df = pd.read_csv(path)\n",
    "    df = pd.concat([df,sea_df])\n",
    "\n",
    "num_plays = len(df)\n",
    "print(str(num_plays) + \" plays were loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['away', 'clock.minutes', 'clock.seconds', 'defense', 'defense_conference', 'defense_score', 'distance', 'down', 'drive_id', 'home', 'id', 'offense', 'offense_conference', 'offense_score', 'period', 'play_text', 'play_type', 'yard_line', 'yards_gained', 'game_id']\n",
      "['Uncategorized', 'Kickoff Return (Offense)', 'Sack', 'Rush', 'Punt Return', 'Penalty', 'Pass Completion', 'Pass Incompletion', 'Safety', 'End Period', 'Pass Interception', 'Blocked Punt Touchdown', 'Fumble Recovery (Own)', 'Timeout', 'Fumble Recovery (Opponent)', 'Two Point Pass', 'Two Point Rush', 'Interception Return Touchdown', 'Blocked Punt', 'Punt Return Touchdown', 'Blocked Field Goal', 'Kickoff Return (Defense)', 'Fumble Return Touchdown', 'Kickoff Return Touchdown', 'Blocked PAT', 'Blocked Field Goal Touchdown', 'Missed Field Goal Return Touchdown', 'Punt', 'Pass', 'Kickoff', 'Extra Point Good', 'Field Goal Good', 'Field Goal Missed', 'Extra Point Missed', '2pt Conversion', 'Offensive 1pt Safety', 'Pass Reception', 'Passing Touchdown', 'Rushing Touchdown', 'Pass Interception Return', 'End of Half', 'End of Game', 'Defensive 2pt Conversion', 'Missed Field Goal Return', 'Interception']\n"
     ]
    }
   ],
   "source": [
    "print(list(df))\n",
    "print(list(df.play_type.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "3940     DeAngelo Hall (VT) took lateral and rushed for...\n",
      "11077    Terrence Biggers (MSU) took lateral and rushed...\n",
      "11092    Derek Abney (UK) took lateral and rushed for 1...\n",
      "13313    Terrance Phillips (PSU) took lateral and rushe...\n",
      "28227    Andrico Hines (MTSU) took lateral and rushed f...\n",
      "30739    Lance Pendleton (BYU) took lateral and rushed ...\n",
      "31087    Chris Bruhn (WSU) took lateral and rushed for ...\n",
      "33853    Tim Blackwell (USM) took lateral and rushed fo...\n",
      "36684    Bruce Gradkowski (TOL) took lateral and rushed...\n",
      "39523    Michael Turner (NIU) took lateral and rushed f...\n",
      "43241    Jason Samples (TSU) took lateral and rushed fo...\n",
      "48186    Steve Breaston (MICH) took lateral and rushed ...\n",
      "52925    Duane Coleman (CLEM) took lateral and rushed f...\n",
      "53764    Scott Lunde (WSU) took lateral and rushed for ...\n",
      "63806    Aric Williams (OSU) took lateral and rushed fo...\n",
      "75692    Garrett Lepisto (UCLA) took lateral and rushed...\n",
      "83122    Sean Taylor (MIA) took lateral and rushed for ...\n",
      "88638    Mike Williams (USC) took lateral and rushed fo...\n",
      "93369    Leon Washington (FSU) took lateral and rushed ...\n",
      "94973    Mark Bradley (OKLA) took lateral and rushed fo...\n",
      "1037                                           Begin Drive\n",
      "1040                                           Begin Drive\n",
      "1047                                           Begin Drive\n",
      "1626     Carlos Ousley (ARK) took lateral and rushed fo...\n",
      "16304    Kelvin Hayden (ILL) took lateral and rushed fo...\n",
      "20855    Norval McKenzie (VAN) took lateral and rushed ...\n",
      "21039                                          Begin Drive\n",
      "23547    Jason Leach (USC) took lateral and rushed for ...\n",
      "24342                                          Begin Drive\n",
      "26454    Jemalle Cornelius (FLA) took lateral and rushe...\n",
      "30534                                          Begin Drive\n",
      "30768    Marcus Rucker (RICE) took lateral and rushed f...\n",
      "31293    Eric Green (VT) took lateral and rushed for 47...\n",
      "35455                                          Begin Drive\n",
      "37355                                          Begin Drive\n",
      "37725    Tres Moses (RU) took lateral and rushed for no...\n",
      "38305    Sid Slater (CAL) took lateral and rushed for 1...\n",
      "42191                                          Begin Drive\n",
      "42201                                          Begin Drive\n",
      "46312    Roscoe Parrish (MIA) took lateral and rushed f...\n",
      "51256    Brian Brosnan (ILL) took lateral and rushed fo...\n",
      "57130                                          Begin Drive\n",
      "57723    Chris Leak (FLA) took lateral and rushed for 5...\n",
      "57724    O.J. Small (FLA) took lateral and rushed for -...\n",
      "59586    Chris Markey (UCLA) took lateral and rushed fo...\n",
      "61266                                          Begin Drive\n",
      "61275                                          Begin Drive\n",
      "61289                                          Begin Drive\n",
      "62967    Darrell Blackman (NCST) took lateral and rushe...\n",
      "63273                                          Begin Drive\n",
      "Name: play_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def fix_uncat(play_type, play_text):\n",
    "    if play_type != 'Uncategorized':\n",
    "        return play_type\n",
    "    else:\n",
    "        if isinstance(play_text,str):\n",
    "            if \"Start of the 1st quarter.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"Start of the 2nd quarter.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"Start of the 3rd quarter.\" in play_text:\n",
    "                return \"End of Half\"\n",
    "            elif \"Start of the 4th quarter.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"Start of overtime.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"End of the game.\" in play_text:\n",
    "                return \"End of Game\"\n",
    "            elif \"Extra point\" in play_text:\n",
    "                if \"is good\" in play_text:\n",
    "                    return \"Extra Point Good\"\n",
    "                elif \"is no good.\" in play_text[-13:]:\n",
    "                    return \"Extra Point Missed\"\n",
    "                else:\n",
    "                    return play_type\n",
    "            elif \"field goal\" in play_text:\n",
    "                if \"is good\" in play_text:\n",
    "                    return \"Field Goal Good\"\n",
    "                elif \"is no good.\" in play_text[-13:]:\n",
    "                    return \"Field Goal Missed\"\n",
    "                else:\n",
    "                    print(play_text)\n",
    "                    return play_type\n",
    "            elif \"missed PAT returned.\" in play_text:\n",
    "                return \"Extra Point Missed\"\n",
    "            else:\n",
    "                return play_type\n",
    "    return play_type\n",
    "\n",
    "df['play_type'] = df.apply(lambda row: fix_uncat(row['play_type'], row['play_text']),axis=1)\n",
    "\n",
    "uncat = df.loc[df.play_type=='Uncategorized']\n",
    "print(len(uncat))\n",
    "print(uncat.play_text.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need Separate Model for XP, Kickoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2223578\n",
      "272728\n",
      "1950850\n"
     ]
    }
   ],
   "source": [
    "# drop_cols\n",
    "separate = ['End Period', 'Kickoff Return (Offense)', 'Extra Point Good', 'Timeout',\n",
    " 'End of Half', 'End of Game', 'Two Point Pass', 'Two Point Rush', \n",
    " 'Kickoff Return (Defense)', 'Uncategorized', 'Kickoff Return Touchdown', 'Blocked PAT','Kickoff', \n",
    " 'Extra Point Missed', '2pt Conversion', 'Defensive 2pt Conversion', 'Offensive 1pt Safety']\n",
    "\n",
    "print(len(df))\n",
    "sep_df = df.loc[df.play_type.isin(separate)]\n",
    "print(len(sep_df))\n",
    "df = df.loc[~df.play_type.isin(separate)]\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950850\n",
      "1944000\n"
     ]
    }
   ],
   "source": [
    "# drop overtime and 61 period 0 entries\n",
    "print(len(df))\n",
    "df = df.loc[df.period.isin([1,2,3,4])]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 25.0, 45.0, 30.0, 11.0, 15.0, 40.0, 55.0, 18.0, 22.0, 54.0, 23.0, 33.0, 44.0, 20.0, 34.0, 4.0, 10.0, 53.0, 56.0, 51.0, 21.0, 6.0, 16.0, 46.0, 3.0, 58.0, 7.0, 47.0, 27.0, 57.0, 17.0, 48.0, 37.0, 24.0, 14.0, 50.0, 5.0, 35.0, 43.0, 39.0, 52.0, 26.0, 36.0, 42.0, 12.0, 2.0, 32.0, 28.0, 8.0, 31.0, 19.0, 9.0, 29.0, 13.0, 41.0, 59.0, 38.0, 49.0, 1.0]\n",
      "clock.seconds\n",
      "0.0     198033\n",
      "30.0     68195\n",
      "45.0     55273\n",
      "50.0     49608\n",
      "15.0     49477\n",
      "20.0     48352\n",
      "40.0     47525\n",
      "55.0     46692\n",
      "10.0     44460\n",
      "25.0     39756\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# instead of zero its nan for clock.seconds and clock.minutes\n",
    "df['clock.seconds'] = df['clock.seconds'].fillna(0)\n",
    "df['clock.minutes'] = df['clock.minutes'].fillna(0)\n",
    "\n",
    "print(list(df['clock.seconds'].unique()))\n",
    "\n",
    "gb = df.groupby(['clock.seconds'])['id'].count()\n",
    "gb = gb.sort_values(ascending=False)\n",
    "print(gb.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   period  clock.minutes  clock.seconds  tr_half  tr_game\n",
      "2       1           14.0            0.0   1740.0   3540.0\n",
      "3       1           14.0           25.0   1765.0   3565.0\n",
      "4       1           14.0           45.0   1785.0   3585.0\n",
      "5       1           13.0           30.0   1710.0   3510.0\n",
      "6       1           11.0           11.0   1571.0   3371.0\n"
     ]
    }
   ],
   "source": [
    "# # calculate time remaining in half\n",
    "def tr_half(period, minutes, seconds):\n",
    "    tr = 0\n",
    "    if period in [1,3]:\n",
    "        # add a quarter of time remaining\n",
    "        tr += 900\n",
    "    tr += (60 * minutes + seconds)\n",
    "    return tr\n",
    "\n",
    "def tr_game(period, minutes, seconds):\n",
    "    quarters_left = 4-period\n",
    "    added_secs = 15*60*quarters_left\n",
    "    return (60*minutes + seconds + added_secs)\n",
    "\n",
    "df['tr_half'] = df.apply(lambda row: tr_half(row['period'],row['clock.minutes'],row['clock.seconds']),axis=1)\n",
    "df['tr_game'] = df.apply(lambda row: tr_game(row['period'],row['clock.minutes'],row['clock.seconds']),axis=1)\n",
    "\n",
    "print(df[['period','clock.minutes','clock.seconds','tr_half','tr_game']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop clock numbers, not needed anymore \n",
    "df = df.drop(columns=['clock.minutes','clock.seconds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Desired Features\n",
    "\n",
    "Need 6 feature variables. 2 weighting variables. and one target.\n",
    "\n",
    "6 features:  \n",
    "-Down  \n",
    "-Seconds left in half  \n",
    "-Yards to go for touchdown (log?)  \n",
    "-Yards to go for first down (log?)  \n",
    "-Goal to goal indicator  \n",
    "-Under 2 minutes indicator  \n",
    "\n",
    "2 weights:  \n",
    "-number of drives to next score\n",
    "-absolute score differential\n",
    "\n",
    "Also need target variable, next score relative to current offense.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944000\n",
      "1943642\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df.dropna(subset=['play_text'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tds(play_type, play_text):\n",
    "    if play_type != 'Penalty':\n",
    "        if isinstance(play_text, str):\n",
    "            if 'Touchdown' in play_type:\n",
    "                return 1\n",
    "            elif 'touchdown' in play_text:\n",
    "                return 1\n",
    "            elif 'for a TD' in play_text:\n",
    "                return 1\n",
    "    return 0\n",
    "    \n",
    "df['touchdown'] = df.apply(lambda row: add_tds(row['play_type'],row['play_text']), axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pass Completion', 'Blocked Punt Touchdown', 'Rush', 'Fumble Recovery (Own)', 'Interception Return Touchdown', 'Punt Return Touchdown', 'Fumble Return Touchdown', 'Blocked Field Goal Touchdown', 'Missed Field Goal Return Touchdown', 'Sack', 'Pass Incompletion', 'Passing Touchdown', 'Rushing Touchdown', 'Punt', 'Fumble Recovery (Opponent)', 'Pass Reception', 'Blocked Punt', 'Pass Interception Return', 'Blocked Field Goal']\n"
     ]
    }
   ],
   "source": [
    "td_plays = df.loc[df['touchdown']==1]\n",
    "print(list(td_plays.play_type.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "defensive_tds = ['Blocked Punt Touchdown', 'Interception Return Touchdown','Punt Return Touchdown',\n",
    "            'Fumble Return Touchdown','Blocked Field Goal Touchdown','Missed Field Goal Return Touchdown',\n",
    "             'Sack']\n",
    "\n",
    "not_touchdowns = ['Pass Incompletion']\n",
    "\n",
    "# create list for faster comparison\n",
    "dtd_nt = defensive_tds + not_touchdowns\n",
    "\n",
    "offensive_tds = ['Pass Completion','Rush','Fumble Recovery (Own)','Rushing Touchdown','Passing Touchdown']\n",
    "\n",
    "# split into offensive and defensive touchdowns\n",
    "\n",
    "df['offensive_TD'] = np.where(((~df['play_type'].isin(dtd_nt)) & (df['touchdown']==1)),1,0)\n",
    "\n",
    "df['defensive_TD'] = np.where(((df['play_type'].isin(defensive_tds)) & (df['touchdown']==1)),1,0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add field goals and safeties\n",
    "\n",
    "df['fg'] = np.where(df['play_type'] == 'Field Goal Good',1,0)\n",
    "df['safety'] = np.where(df['play_type'] == 'Safety',1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 32266005905 remove safety, it was on kickoff somehow\n",
    "df = df.loc[df['id']!=322660059036]\n",
    "\n",
    "## 4010320813 has two plays from 4010320812\n",
    "df.loc[df['id'] == 401032081101874002, ['drive_id']] = 4010320812\n",
    "df.loc[df['id'] == 401032081101907203, ['drive_id']] = 4010320812\n",
    "\n",
    "## 40054786811 has two drives\n",
    "df.loc[(df['drive_id']==40054786811) & (df['offense']=='Baylor'), ['drive_id']] = 4005478681100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_gb = df.groupby(['drive_id'])['offensive_TD','defensive_TD','fg','safety'].max().reset_index()\n",
    "\n",
    "drive_gb['drive_score'] = 7 * drive_gb['offensive_TD'] + -7 * drive_gb['defensive_TD'] + 3 * drive_gb['fg'] + -2 * drive_gb['safety']\n",
    "drive_gb['drive_score'] = drive_gb['drive_score'].astype(int)\n",
    "drive_gb = drive_gb[['drive_id','drive_score']]\n",
    "\n",
    "df = pd.merge(left=df, right=drive_gb, how='left', on=['drive_id','drive_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     drive_id  avg_drive_time\n",
      "0  4005476401         3518.75\n",
      "1  4005476402         3361.00\n",
      "2  4005476403         3255.25\n",
      "3  4005476404         3145.60\n",
      "4  4005476405         3064.50\n"
     ]
    }
   ],
   "source": [
    "# since clock numbers aren't consistent for some plays, I am sorting drives by average time remaining \n",
    "# of all plays on the drive\n",
    "\n",
    "tr = df.groupby(['drive_id'])['tr_game'].mean().reset_index()\n",
    "\n",
    "tr = tr.rename(columns={'tr_game':'avg_drive_time'})\n",
    "print(tr.head(5))\n",
    "\n",
    "df = pd.merge(left=df, right=tr, how='left', on=['drive_id','drive_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['half'] = np.where(df['period'] < 3, 1, 2)\n",
    "df['is_scoring_drive'] = np.where(df['drive_score'] != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "    \n",
    "# scoring_drives = np.array([[1,3,'Louisville'],[5,7,'Kentucky'],[6,-7,'Louisville']])\n",
    "\n",
    "# test = pd.DataFrame([[1],[2],[3],[4],[5],[6],[7]],columns=['drive_no'])\n",
    "\n",
    "\n",
    "# last_score = 6\n",
    "# if last_score < test.drive_no.max():\n",
    "#     scoring_drives.append(0)\n",
    "\n",
    "# scoring_drives = np.vstack([scoring_drives, [test.drive_no.max(),0,'Kentucky']])\n",
    "# print(scoring_drives)\n",
    "\n",
    "# drive_numbers = scoring_drives[:,0]\n",
    "# drive_scores = scoring_drives[:,1]\n",
    "# drive_offense = scoring_drives[:,2]\n",
    "\n",
    "# test['next_idx'] = np.searchsorted(scoring_drives[:,0],test.drive_no.values,'left')\n",
    "\n",
    "# test['next_sd'] = drive_numbers[test['next_idx'].values]\n",
    "# test['dtns'] = test['next_sd'].astype(int) - test['drive_no'].astype(int)\n",
    "\n",
    "# test['next_score'] = drive_scores[test['next_idx'].values]\n",
    "# test['ns_offense'] = drive_offense[test['next_idx'].values]\n",
    "\n",
    "\n",
    "\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12119\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "1941622\n",
      "1943641\n"
     ]
    }
   ],
   "source": [
    "# games=df.groupby(['game_id'])\n",
    "# print(len(games))\n",
    "\n",
    "# new_df = pd.DataFrame()\n",
    "\n",
    "# counter = 0\n",
    "# for game, game_plays in games:\n",
    "#     counter += 1\n",
    "#     if counter % 1000 == 0:\n",
    "#         print(counter)\n",
    "#     # sort by time remaining to order them\n",
    "#     ordered = game_plays.sort_values(by=['avg_drive_time'],ascending=False)\n",
    "#     # label drive numbers\n",
    "#     i = ordered.drive_id\n",
    "#     ordered['drive_no'] = i.ne(i.shift()).cumsum()\n",
    "    \n",
    "#     scoring_drives_1H = ordered.loc[(ordered['is_scoring_drive']==1)&(ordered['half']==1)].copy()\n",
    "#     scoring_drives_2H = ordered.loc[(ordered['is_scoring_drive']==1)&(ordered['half']==2)].copy()\n",
    "    \n",
    "#     # get last score of half drive number\n",
    "#     last_score_1H = scoring_drives_1H.drive_no.max()\n",
    "#     last_score_2H = scoring_drives_2H.drive_no.max()\n",
    "    \n",
    "#     # need drive numbers, drive scores, and drive offenses for each scoring drive for each half\n",
    "#     sdn_1H = scoring_drives_1H.drive_no.values\n",
    "#     sdn_2H = scoring_drives_2H.drive_no.values\n",
    "    \n",
    "#     ds_1H = scoring_drives_1H.drive_score.values\n",
    "#     ds_2H = scoring_drives_2H.drive_score.values\n",
    "    \n",
    "#     sdo_1H = scoring_drives_1H.offense.values\n",
    "#     sdo_2H = scoring_drives_2H.offense.values\n",
    "    \n",
    "#     # also need to split plays into first and second half\n",
    "#     drives_1H = ordered.loc[ordered['half']==1].copy()\n",
    "#     drives_2H = ordered.loc[ordered['half']==2].copy()\n",
    "    \n",
    "#     if len(drives_1H) < 1:\n",
    "#         continue\n",
    "#     if len(drives_2H) < 1:\n",
    "#         continue\n",
    "    \n",
    "#     # drive numbers for first half\n",
    "#     dn_1H = drives_1H.drive_no.values\n",
    "#     dn_2H = drives_2H.drive_no.values\n",
    "    \n",
    "#     # if last drive of half is not scoring drive, add dummy scoring drive with zeros\n",
    "#     # also treat cases where there are no scoring drives\n",
    "#     if len(sdn_1H) == 0:\n",
    "#         sdn_1H = np.append(sdn_1H, dn_1H[-1])\n",
    "#         ds_1H = np.append(ds_1H, 0)\n",
    "#         sdo_1H = np.append(sdo_1H, \"Dummy Offense\")\n",
    "#     elif sdn_1H[-1] < dn_1H[-1]:\n",
    "#         sdn_1H = np.append(sdn_1H, dn_1H[-1])\n",
    "#         ds_1H = np.append(ds_1H, 0)\n",
    "#         sdo_1H = np.append(sdo_1H, sdo_1H[-1])\n",
    "\n",
    "#     if len(sdn_2H) == 0:\n",
    "#         sdn_2H = np.append(sdn_2H, dn_2H[-1])\n",
    "#         ds_2H = np.append(ds_2H, 0)\n",
    "#         sdo_2H = np.append(sdo_2H, \"Dummy Offense\")\n",
    "#     elif sdn_2H[-1] < dn_2H[-1]:\n",
    "#         sdn_2H = np.append(sdn_2H, dn_2H[-1])\n",
    "#         ds_2H = np.append(ds_2H, 0)\n",
    "#         sdo_2H = np.append(sdo_2H, sdo_2H[-1])\n",
    "    \n",
    "#     # get index to lookup drive numbers, drive scores, and drive offenses\n",
    "#     drives_1H['next_idx'] = np.searchsorted(sdn_1H,dn_1H,'left')\n",
    "#     drives_2H['next_idx'] = np.searchsorted(sdn_2H,dn_2H,'left')\n",
    "    \n",
    "#     drives_1H['next_sd'] = sdn_1H[drives_1H.next_idx.values]\n",
    "#     drives_1H['dtns'] = drives_1H['next_sd'].astype(int) - drives_1H['drive_no'].astype(int)\n",
    "    \n",
    "#     drives_2H['next_sd'] = sdn_2H[drives_2H.next_idx.values]\n",
    "#     drives_2H['dtns'] = drives_2H['next_sd'].astype(int) - drives_2H['drive_no'].astype(int)\n",
    "    \n",
    "#     drives_1H['next_score'] = ds_1H[drives_1H.next_idx.values]\n",
    "#     drives_1H['ns_offense'] = sdo_1H[drives_1H.next_idx.values]\n",
    "    \n",
    "#     drives_2H['next_score'] = ds_2H[drives_2H.next_idx.values]\n",
    "#     drives_2H['ns_offense'] = sdo_2H[drives_2H.next_idx.values]\n",
    "    \n",
    "#     new_df = pd.concat([new_df,drives_1H])\n",
    "#     new_df = pd.concat([new_df,drives_2H])\n",
    "    \n",
    "    \n",
    "\n",
    "# print(len(new_df))\n",
    "# print(len(df))\n",
    "\n",
    "# new_df.to_csv('./output/new_df.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['away', 'defense', 'defense_conference', 'defense_score', 'distance', 'down', 'drive_id', 'home', 'id', 'offense', 'offense_conference', 'offense_score', 'period', 'play_text', 'play_type', 'yard_line', 'yards_gained', 'game_id', 'tr_half', 'tr_game', 'touchdown', 'offensive_TD', 'defensive_TD', 'fg', 'safety', 'drive_score', 'avg_drive_time', 'half', 'is_scoring_drive', 'drive_no', 'next_idx', 'next_sd', 'dtns', 'next_score', 'ns_offense']\n"
     ]
    }
   ],
   "source": [
    "print(list(new_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix/validate yardline log?\n",
    "new_df['offense_yard_line'] = np.where(new_df['home'] == new_df['offense'],new_df['yard_line'],(100-new_df['yard_line']))\n",
    "              \n",
    "new_df = new_df.drop(columns=['yard_line'])                                  \n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         distance  yards_gained  offense_yard_line  GTG\n",
      "1741            6             6                 94    1\n",
      "1754           10            41                 59    0\n",
      "1768            1             9                 91    0\n",
      "1781           10            32                 68    0\n",
      "1839            2             2                 98    1\n",
      "1848            4            10                 90    0\n",
      "1851            1             1                 99    1\n",
      "1868           10            10                 90    1\n",
      "4035            1             1                 99    1\n",
      "4082            1            17                 83    0\n",
      "3123            2             6                 94    0\n",
      "3136            6             6                 94    1\n",
      "3166            2             2                 98    1\n",
      "3180            1             1                 99    1\n",
      "3228            9             9                 91    1\n",
      "3236            4             4                 96    1\n",
      "3247            2             2                 98    1\n",
      "2974            8            15                 85    0\n",
      "3056            4             4                 96    1\n",
      "4130            5             5                 95    1\n",
      "4161           10            37                 37    0\n",
      "4201           10            40                 60    0\n",
      "4280            4             4                 96    1\n",
      "4295            2             2                 98    1\n",
      "4304            1             1                 99    1\n",
      "4317            1             1                 99    1\n",
      "4337            8             8                 92    1\n",
      "4357           10            33                 67    0\n",
      "4361            1             7                 93    0\n",
      "4371           10            13                 87    0\n",
      "...           ...           ...                ...  ...\n",
      "1887430         1            27                 73    0\n",
      "1887455         4            16                 84    0\n",
      "1891572        10            33                 67    0\n",
      "1891607        10            16                 84    0\n",
      "1891621         1             1                 99    1\n",
      "1887909         6             6                 94    1\n",
      "1887954         5             5                 95    1\n",
      "1892492         6             6                 94    1\n",
      "1892517         4             4                 96    1\n",
      "1892537         1             1                  0    0\n",
      "1892550         1             1                 99    1\n",
      "1892562         7            58                 42    0\n",
      "1888520         8            10                 90    0\n",
      "1888525        10            25                 75    0\n",
      "1888530         2             2                 98    1\n",
      "1893495         1            62                 38    0\n",
      "1893504        10            34                 66    0\n",
      "1893506         9            18                 82    0\n",
      "1893515         3             3                 97    1\n",
      "1893518         1             1                 99    1\n",
      "1893555         8             8                 92    1\n",
      "1886829        10            53                 47    0\n",
      "1890688        10            25                 75    0\n",
      "1890699         8            65                 35    0\n",
      "1890701        10            33                 67    0\n",
      "1890709         1             1                 99    1\n",
      "1890723         2             2                 98    1\n",
      "1890741         1             1                 99    1\n",
      "1890744         1             1                 99    1\n",
      "1890753        12            36                 64    0\n",
      "\n",
      "[34991 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# goal to go\n",
    "new_df['GTG'] = np.where((new_df['offense_yard_line']+new_df['distance']==100),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# under two min in half\n",
    "new_df['UTM'] = np.where(new_df['tr_half']<=120,1,0)\n",
    "\n",
    "print(new_df[['tr_half','UTM']].tail(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicator for kneels/drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute score differential\n",
    "# scale\n",
    "# zero for more than 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st down YTG log?\n",
    "# field YTG log?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
