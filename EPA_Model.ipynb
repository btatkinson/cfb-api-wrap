{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime\n",
    "import math\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:21<00:00,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2223578 plays were loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "years = list(range(2002, int(datetime.datetime.now().year)))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for year in tqdm(years):\n",
    "    path = './output/'+str(year)+'/'+str(year)+'_pbp.csv'\n",
    "    sea_df = pd.read_csv(path)\n",
    "    df = pd.concat([df,sea_df])\n",
    "\n",
    "num_plays = len(df)\n",
    "print(str(num_plays) + \" plays were loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['away', 'clock.minutes', 'clock.seconds', 'defense', 'defense_conference', 'defense_score', 'distance', 'down', 'drive_id', 'home', 'id', 'offense', 'offense_conference', 'offense_score', 'period', 'play_text', 'play_type', 'yard_line', 'yards_gained', 'game_id']\n",
      "['Uncategorized', 'Kickoff Return (Offense)', 'Sack', 'Rush', 'Punt Return', 'Penalty', 'Pass Completion', 'Pass Incompletion', 'Safety', 'End Period', 'Pass Interception', 'Blocked Punt Touchdown', 'Fumble Recovery (Own)', 'Timeout', 'Fumble Recovery (Opponent)', 'Two Point Pass', 'Two Point Rush', 'Interception Return Touchdown', 'Blocked Punt', 'Punt Return Touchdown', 'Blocked Field Goal', 'Kickoff Return (Defense)', 'Fumble Return Touchdown', 'Kickoff Return Touchdown', 'Blocked PAT', 'Blocked Field Goal Touchdown', 'Missed Field Goal Return Touchdown', 'Punt', 'Pass', 'Kickoff', 'Extra Point Good', 'Field Goal Good', 'Field Goal Missed', 'Extra Point Missed', '2pt Conversion', 'Offensive 1pt Safety', 'Pass Reception', 'Passing Touchdown', 'Rushing Touchdown', 'Pass Interception Return', 'End of Half', 'End of Game', 'Defensive 2pt Conversion', 'Missed Field Goal Return', 'Interception']\n"
     ]
    }
   ],
   "source": [
    "print(list(df))\n",
    "print(list(df.play_type.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "3940     DeAngelo Hall (VT) took lateral and rushed for...\n",
      "11077    Terrence Biggers (MSU) took lateral and rushed...\n",
      "11092    Derek Abney (UK) took lateral and rushed for 1...\n",
      "13313    Terrance Phillips (PSU) took lateral and rushe...\n",
      "28227    Andrico Hines (MTSU) took lateral and rushed f...\n",
      "30739    Lance Pendleton (BYU) took lateral and rushed ...\n",
      "31087    Chris Bruhn (WSU) took lateral and rushed for ...\n",
      "33853    Tim Blackwell (USM) took lateral and rushed fo...\n",
      "36684    Bruce Gradkowski (TOL) took lateral and rushed...\n",
      "39523    Michael Turner (NIU) took lateral and rushed f...\n",
      "43241    Jason Samples (TSU) took lateral and rushed fo...\n",
      "48186    Steve Breaston (MICH) took lateral and rushed ...\n",
      "52925    Duane Coleman (CLEM) took lateral and rushed f...\n",
      "53764    Scott Lunde (WSU) took lateral and rushed for ...\n",
      "63806    Aric Williams (OSU) took lateral and rushed fo...\n",
      "75692    Garrett Lepisto (UCLA) took lateral and rushed...\n",
      "83122    Sean Taylor (MIA) took lateral and rushed for ...\n",
      "88638    Mike Williams (USC) took lateral and rushed fo...\n",
      "93369    Leon Washington (FSU) took lateral and rushed ...\n",
      "94973    Mark Bradley (OKLA) took lateral and rushed fo...\n",
      "1037                                           Begin Drive\n",
      "1040                                           Begin Drive\n",
      "1047                                           Begin Drive\n",
      "1626     Carlos Ousley (ARK) took lateral and rushed fo...\n",
      "16304    Kelvin Hayden (ILL) took lateral and rushed fo...\n",
      "20855    Norval McKenzie (VAN) took lateral and rushed ...\n",
      "21039                                          Begin Drive\n",
      "23547    Jason Leach (USC) took lateral and rushed for ...\n",
      "24342                                          Begin Drive\n",
      "26454    Jemalle Cornelius (FLA) took lateral and rushe...\n",
      "30534                                          Begin Drive\n",
      "30768    Marcus Rucker (RICE) took lateral and rushed f...\n",
      "31293    Eric Green (VT) took lateral and rushed for 47...\n",
      "35455                                          Begin Drive\n",
      "37355                                          Begin Drive\n",
      "37725    Tres Moses (RU) took lateral and rushed for no...\n",
      "38305    Sid Slater (CAL) took lateral and rushed for 1...\n",
      "42191                                          Begin Drive\n",
      "42201                                          Begin Drive\n",
      "46312    Roscoe Parrish (MIA) took lateral and rushed f...\n",
      "51256    Brian Brosnan (ILL) took lateral and rushed fo...\n",
      "57130                                          Begin Drive\n",
      "57723    Chris Leak (FLA) took lateral and rushed for 5...\n",
      "57724    O.J. Small (FLA) took lateral and rushed for -...\n",
      "59586    Chris Markey (UCLA) took lateral and rushed fo...\n",
      "61266                                          Begin Drive\n",
      "61275                                          Begin Drive\n",
      "61289                                          Begin Drive\n",
      "62967    Darrell Blackman (NCST) took lateral and rushe...\n",
      "63273                                          Begin Drive\n",
      "Name: play_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def fix_uncat(play_type, play_text):\n",
    "    if play_type != 'Uncategorized':\n",
    "        return play_type\n",
    "    else:\n",
    "        if isinstance(play_text,str):\n",
    "            if \"Start of the 1st quarter.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"Start of the 2nd quarter.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"Start of the 3rd quarter.\" in play_text:\n",
    "                return \"End of Half\"\n",
    "            elif \"Start of the 4th quarter.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"Start of overtime.\" in play_text:\n",
    "                return \"End Period\"\n",
    "            elif \"End of the game.\" in play_text:\n",
    "                return \"End of Game\"\n",
    "            elif \"Extra point\" in play_text:\n",
    "                if \"is good\" in play_text:\n",
    "                    return \"Extra Point Good\"\n",
    "                elif \"is no good.\" in play_text[-13:]:\n",
    "                    return \"Extra Point Missed\"\n",
    "                else:\n",
    "                    return play_type\n",
    "            elif \"field goal\" in play_text:\n",
    "                if \"is good\" in play_text:\n",
    "                    return \"Field Goal Good\"\n",
    "                elif \"is no good.\" in play_text[-13:]:\n",
    "                    return \"Field Goal Missed\"\n",
    "                else:\n",
    "                    print(play_text)\n",
    "                    return play_type\n",
    "            elif \"missed PAT returned.\" in play_text:\n",
    "                return \"Extra Point Missed\"\n",
    "            else:\n",
    "                return play_type\n",
    "    return play_type\n",
    "\n",
    "df['play_type'] = df.apply(lambda row: fix_uncat(row['play_type'], row['play_text']),axis=1)\n",
    "\n",
    "uncat = df.loc[df.play_type=='Uncategorized']\n",
    "print(len(uncat))\n",
    "print(uncat.play_text.head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need Separate Model for XP, Kickoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2223578\n",
      "272728\n",
      "1950850\n"
     ]
    }
   ],
   "source": [
    "# drop_cols\n",
    "separate = ['End Period', 'Kickoff Return (Offense)', 'Extra Point Good', 'Timeout',\n",
    " 'End of Half', 'End of Game', 'Two Point Pass', 'Two Point Rush', \n",
    " 'Kickoff Return (Defense)', 'Uncategorized', 'Kickoff Return Touchdown', 'Blocked PAT','Kickoff', \n",
    " 'Extra Point Missed', '2pt Conversion', 'Defensive 2pt Conversion', 'Offensive 1pt Safety']\n",
    "\n",
    "print(len(df))\n",
    "sep_df = df.loc[df.play_type.isin(separate)]\n",
    "print(len(sep_df))\n",
    "df = df.loc[~df.play_type.isin(separate)]\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950850\n",
      "1944000\n"
     ]
    }
   ],
   "source": [
    "# drop overtime and 61 period 0 entries\n",
    "print(len(df))\n",
    "df = df.loc[df.period.isin([1,2,3,4])]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 25.0, 45.0, 30.0, 11.0, 15.0, 40.0, 55.0, 18.0, 22.0, 54.0, 23.0, 33.0, 44.0, 20.0, 34.0, 4.0, 10.0, 53.0, 56.0, 51.0, 21.0, 6.0, 16.0, 46.0, 3.0, 58.0, 7.0, 47.0, 27.0, 57.0, 17.0, 48.0, 37.0, 24.0, 14.0, 50.0, 5.0, 35.0, 43.0, 39.0, 52.0, 26.0, 36.0, 42.0, 12.0, 2.0, 32.0, 28.0, 8.0, 31.0, 19.0, 9.0, 29.0, 13.0, 41.0, 59.0, 38.0, 49.0, 1.0]\n",
      "clock.seconds\n",
      "59.0     23264\n",
      "39.0     23604\n",
      "29.0     23654\n",
      "19.0     24132\n",
      "26.0     24201\n",
      "57.0     24310\n",
      "31.0     24386\n",
      "6.0      24445\n",
      "37.0     24556\n",
      "36.0     24586\n",
      "3.0      24733\n",
      "9.0      24748\n",
      "34.0     24807\n",
      "4.0      24893\n",
      "58.0     24915\n",
      "14.0     24915\n",
      "27.0     24955\n",
      "24.0     24977\n",
      "32.0     24984\n",
      "16.0     25026\n",
      "43.0     25026\n",
      "17.0     25185\n",
      "46.0     25213\n",
      "41.0     25230\n",
      "13.0     25291\n",
      "1.0      25308\n",
      "28.0     25311\n",
      "21.0     25325\n",
      "49.0     25463\n",
      "42.0     25633\n",
      "23.0     25657\n",
      "38.0     25704\n",
      "7.0      25739\n",
      "2.0      25808\n",
      "47.0     25844\n",
      "11.0     26020\n",
      "8.0      26148\n",
      "51.0     26210\n",
      "18.0     26332\n",
      "56.0     26556\n",
      "48.0     26706\n",
      "12.0     26760\n",
      "33.0     26767\n",
      "44.0     26783\n",
      "22.0     27057\n",
      "52.0     27534\n",
      "53.0     28265\n",
      "54.0     29190\n",
      "5.0      35863\n",
      "35.0     38610\n",
      "25.0     39756\n",
      "10.0     44460\n",
      "55.0     46692\n",
      "40.0     47525\n",
      "20.0     48352\n",
      "15.0     49477\n",
      "50.0     49608\n",
      "45.0     55273\n",
      "30.0     68195\n",
      "0.0     198033\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# instead of zero its nan for clock.seconds and clock.minutes\n",
    "df['clock.seconds'] = df['clock.seconds'].fillna(0)\n",
    "df['clock.minutes'] = df['clock.minutes'].fillna(0)\n",
    "\n",
    "print(list(df['clock.seconds'].unique()))\n",
    "\n",
    "gb = df.groupby(['clock.seconds'])['id'].count()\n",
    "gb = gb.sort_values()\n",
    "print(gb.head(70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    period  clock.minutes  clock.seconds  tr_half  tr_game\n",
      "2        1           14.0            0.0   1740.0   3540.0\n",
      "3        1           14.0           25.0   1765.0   3565.0\n",
      "4        1           14.0           45.0   1785.0   3585.0\n",
      "5        1           13.0           30.0   1710.0   3510.0\n",
      "6        1           11.0           11.0   1571.0   3371.0\n",
      "7        1           11.0            0.0   1560.0   3360.0\n",
      "8        1           13.0           15.0   1695.0   3495.0\n",
      "9        1           12.0           45.0   1665.0   3465.0\n",
      "10       1           12.0           25.0   1645.0   3445.0\n",
      "11       1           12.0            0.0   1620.0   3420.0\n"
     ]
    }
   ],
   "source": [
    "# # calculate time remaining in half\n",
    "def tr_half(period, minutes, seconds):\n",
    "    tr = 0\n",
    "    if period in [1,3]:\n",
    "        # add a quarter of time remaining\n",
    "        tr += 900\n",
    "    tr += (60 * minutes + seconds)\n",
    "    return tr\n",
    "\n",
    "def tr_game(period, minutes, seconds):\n",
    "    quarters_left = 4-period\n",
    "    added_secs = 15*60*quarters_left\n",
    "    return (60*minutes + seconds + added_secs)\n",
    "\n",
    "df['tr_half'] = df.apply(lambda row: tr_half(row['period'],row['clock.minutes'],row['clock.seconds']),axis=1)\n",
    "df['tr_game'] = df.apply(lambda row: tr_game(row['period'],row['clock.minutes'],row['clock.seconds']),axis=1)\n",
    "\n",
    "print(df[['period','clock.minutes','clock.seconds','tr_half','tr_game']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop clock numbers, not needed anymore \n",
    "df = df.drop(columns=['clock.minutes','clock.seconds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Desired Features\n",
    "\n",
    "Need 6 variables. Well 8.\n",
    "\n",
    "Down  \n",
    "Seconds left in half  \n",
    "Yards to go for touchdown (log?)  \n",
    "Yards to go for first down (log?)  \n",
    "Goal to goal indicator  \n",
    "Under 2 minutes indicator  \n",
    "\n",
    "Using two others to weigh observations\n",
    "-number of drives to next score\n",
    "-absolute score differential\n",
    "\n",
    "Also need target variable. Next Score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944000\n",
      "1943642\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df = df.dropna(subset=['play_text'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tds(play_type, play_text):\n",
    "    if play_type != 'Penalty':\n",
    "        if isinstance(play_text, str):\n",
    "            if 'Touchdown' in play_type:\n",
    "                return 1\n",
    "            elif 'touchdown' in play_text:\n",
    "                return 1\n",
    "            elif 'for a TD' in play_text:\n",
    "                return 1\n",
    "    return 0\n",
    "    \n",
    "df['touchdown'] = df.apply(lambda row: add_tds(row['play_type'],row['play_text']), axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pass Completion', 'Blocked Punt Touchdown', 'Rush', 'Fumble Recovery (Own)', 'Interception Return Touchdown', 'Punt Return Touchdown', 'Fumble Return Touchdown', 'Blocked Field Goal Touchdown', 'Missed Field Goal Return Touchdown', 'Sack', 'Pass Incompletion', 'Passing Touchdown', 'Rushing Touchdown', 'Punt', 'Fumble Recovery (Opponent)', 'Pass Reception', 'Blocked Punt', 'Pass Interception Return', 'Blocked Field Goal']\n"
     ]
    }
   ],
   "source": [
    "td_plays = df.loc[df['touchdown']==1]\n",
    "print(list(td_plays.play_type.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['away', 'defense', 'defense_conference', 'defense_score', 'distance', 'down', 'drive_id', 'home', 'id', 'offense', 'offense_conference', 'offense_score', 'period', 'play_text', 'play_type', 'yard_line', 'yards_gained', 'game_id', 'tr_half', 'tr_game', 'touchdown', 'offensive_TD', 'defensive_TD']\n"
     ]
    }
   ],
   "source": [
    "defensive_tds = ['Blocked Punt Touchdown', 'Interception Return Touchdown','Punt Return Touchdown',\n",
    "            'Fumble Return Touchdown','Blocked Field Goal Touchdown','Missed Field Goal Return Touchdown',\n",
    "             'Sack']\n",
    "\n",
    "not_touchdowns = ['Pass Incompletion']\n",
    "\n",
    "offensive_tds = ['Pass Completion','Rush','Fumble Recovery (Own)','Rushing Touchdown','Passing Touchdown']\n",
    "\n",
    "# split into offensive and defensive touchdowns\n",
    "\n",
    "def cat_offense(play_type, touchdown):\n",
    "    if touchdown == 1:\n",
    "        if play_type not in defensive_tds:\n",
    "            if play_type != 'Pass Incompletion':\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "def cat_defense(play_type, touchdown):\n",
    "    if touchdown ==1:\n",
    "        if play_type in defensive_tds:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df['offensive_TD'] = df.apply(lambda row: cat_offense(row['play_type'],row['touchdown']),axis=1)\n",
    "\n",
    "df['defensive_TD'] = df.apply(lambda row: cat_defense(row['play_type'],row['touchdown']),axis=1)\n",
    "\n",
    "print(list(df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add field goals and safeties\n",
    "def add_fgs(play_type):\n",
    "    if play_type == 'Field Goal Good':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def add_safeties(play_type):\n",
    "    if play_type == 'Safety':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df['fg'] = df.apply(lambda row: add_fgs(row['play_type']),axis=1)\n",
    "\n",
    "df['safety'] = df.apply(lambda row: add_safeties(row['play_type']),axis=1)\n",
    "\n",
    "\n",
    "# weird = non_tds.loc[non_tds['play_type'] == 'Interception Return Touchdown']\n",
    "# for w in list(weird.play_text.values):\n",
    "#     print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           drive_id  offensive_TD  defensive_TD  fg  safety  drive_score\n",
      "37852    4010320813             1             0   1       0           10\n",
      "199623  32266005905             0             0   1       1            1\n",
      "241117  40054786811             1             0   1       0           10\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# add score for each drive\n",
    "drive_gb = df.groupby(['drive_id'])['offensive_TD','defensive_TD','fg','safety'].max().reset_index()\n",
    "\n",
    "drive_gb['drive_score'] = 7 * drive_gb['offensive_TD'] + -7 * drive_gb['defensive_TD'] + 3 * drive_gb['fg'] + -2 * drive_gb['safety']\n",
    "drive_gb['drive_score'] = drive_gb['drive_score'].astype(int)\n",
    "\n",
    "possible = [0, 3, 7, -2, -7]\n",
    "\n",
    "not_possible = drive_gb.loc[~drive_gb['drive_score'].isin(possible)]\n",
    "print(not_possible)\n",
    "print(len(not_possible))\n",
    "\n",
    "drive_ids = list(df.drive_id.unique())\n",
    "# print(len(drive_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 32266005905 remove safety, it was on kickoff somehow\n",
    "df = df.loc[df['id']!=322660059036]\n",
    "\n",
    "## 4010320813 has two plays from 4010320812\n",
    "df.loc[df['id'] == 401032081101874002, ['drive_id']] = 4010320812\n",
    "df.loc[df['id'] == 401032081101907203, ['drive_id']] = 4010320812\n",
    "\n",
    "## 40054786811 has two drives\n",
    "df.loc[(df['drive_id']==40054786811) & (df['offense']=='Baylor'), ['drive_id']] = 4005478681100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     drive_id  avg_drive_time\n",
      "0  4005476401         3518.75\n",
      "1  4005476402         3361.00\n",
      "2  4005476403         3255.25\n",
      "3  4005476404         3145.60\n",
      "4  4005476405         3064.50\n"
     ]
    }
   ],
   "source": [
    "# since clock numbers aren't consistent for some plays, I am sorting drives by average time remaining \n",
    "# of all plays on the drive\n",
    "\n",
    "tr = df.groupby(['drive_id'])['tr_game'].mean().reset_index()\n",
    "\n",
    "tr = tr.rename(columns={'tr_game':'avg_drive_time'})\n",
    "print(tr.head(5))\n",
    "\n",
    "df = pd.merge(left=df, right=tr, how='left', on=['drive_id','drive_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   drive_no     offense  drive_score\n",
      "0         3    Kentucky            3\n",
      "1         5  Louisville            7\n",
      "2         7    Kentucky            3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-b2633da10bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring_drives_1H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdtns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mco\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring_drives_1H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-b2633da10bac>\u001b[0m in \u001b[0;36mget_next\u001b[0;34m(current_drive, current_offense, scoring_drives)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_drive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_offense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring_drives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mscoring_drives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring_drives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'drive_no'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscoring_drives\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drive_no'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mcurrent_drive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'offense'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcurrent_offense\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "def get_next(current_drive, current_offense, scoring_drives):\n",
    "    scoring_drives = scoring_drives.sort_values(by='drive_no',ascending=True)\n",
    "    for index,row in scoring_drives:\n",
    "        if row['drive_no'] >= current_drive:\n",
    "            if row['offense'] == current_offense:\n",
    "                return (row['drive_no'] - current_drive), (row['drive_score'])\n",
    "            else:\n",
    "                return (row['drive_no'] - current_drive), (-1 * row['drive_score'])\n",
    "    return 0,0\n",
    "\n",
    "cd = 6\n",
    "co = 'Kentucky'\n",
    "\n",
    "scoring_drives_1H = pd.DataFrame([[3,'Kentucky',3],[5,'Louisville',7],[7,'Kentucky',3]],columns=['drive_no','offense','drive_score'])\n",
    "\n",
    "print(scoring_drives_1H)\n",
    "dtns = get_next(cd, co, scoring_drives_1H)\n",
    "print(dtns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(1595, 27)\n",
      "20\n",
      "(3316, 27)\n",
      "30\n",
      "(4970, 27)\n",
      "40\n",
      "(6607, 27)\n",
      "50\n",
      "(8291, 27)\n",
      "60\n",
      "(9945, 27)\n",
      "70\n",
      "(11608, 27)\n",
      "80\n",
      "(13284, 27)\n",
      "90\n",
      "(14956, 27)\n",
      "100\n",
      "(16653, 27)\n",
      "110\n",
      "(18338, 27)\n",
      "120\n",
      "(20033, 27)\n",
      "130\n",
      "(21714, 27)\n",
      "140\n",
      "(23335, 27)\n",
      "150\n",
      "(24988, 27)\n",
      "160\n",
      "(26715, 27)\n",
      "170\n",
      "(28352, 27)\n",
      "180\n",
      "(30075, 27)\n",
      "190\n",
      "(31761, 27)\n",
      "200\n",
      "(33451, 27)\n",
      "210\n",
      "(35144, 27)\n",
      "220\n",
      "(36646, 27)\n",
      "230\n",
      "(38350, 27)\n",
      "240\n",
      "(39961, 27)\n",
      "250\n",
      "(41658, 27)\n",
      "260\n",
      "(43234, 27)\n",
      "270\n",
      "(44839, 27)\n",
      "280\n",
      "(46466, 27)\n",
      "290\n",
      "(48132, 27)\n",
      "300\n",
      "(49920, 27)\n",
      "310\n",
      "(51526, 27)\n",
      "320\n",
      "(53288, 27)\n",
      "330\n",
      "(54910, 27)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-efb82758327e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrive_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mordered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'drive_no'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mnew_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mordered\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    226\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                        copy=copy, sort=sort)\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0mndims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(self, inplace)\u001b[0m\n\u001b[1;32m   5154\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inplace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5156\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5158\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5136\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5125\u001b[0m         \"\"\"\n\u001b[1;32m   5126\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5127\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5135\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5136\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5078\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5079\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5080\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5081\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5082\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "games=df.groupby(['game_id'])\n",
    "\n",
    "new_df = []\n",
    "\n",
    "counter = 0\n",
    "for game, game_plays in games:\n",
    "    counter+=1\n",
    "    if counter % 500 == 0:\n",
    "        print(counter)\n",
    "    # sort by time remaining to order them\n",
    "    ordered = game_plays.sort_values(by=['avg_drive_time'],ascending=False)\n",
    "    # label drive numbers\n",
    "    i = ordered.drive_id\n",
    "    ordered['drive_no'] = i.ne(i.shift()).cumsum()\n",
    "    \n",
    "    ordered['is_scoring_drive'] = ordered['drive_score'].where(s != 0, 1, 0)\n",
    "    ordered['half'] = ordered['period'].where(s < 3, 1, 2)\n",
    "    \n",
    "    scoring_drives_1H = ordered.loc[(ordered['is_scoring_drive']==1)&(ordered['half']==1)]\n",
    "    scoring_drives_2H = ordered.loc[(ordered['is_scoring_drive']==1)&(ordered['half']==2)]\n",
    "    \n",
    "    sd_next_1H = scoring_drives_1H[['drive_no','offense','drive_score']]\n",
    "    sd_next_2H = scoring_drives_2H[['drive_no','offense','drive_score']]\n",
    "    \n",
    "    for index, row in ordered.iterrows():\n",
    "        \n",
    "    print(ordered.head())\n",
    "    \n",
    "    new_df = pd.concat([new_df,ordered],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(new_df))\n",
    "print(len(df))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games=df.groupby(['game_id'])\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "counter = 0\n",
    "for game, game_plays in games:\n",
    "    counter+=1\n",
    "    if counter % 1000 == 0:\n",
    "        print(counter)\n",
    "    # sort by time remaining to order them\n",
    "    ordered = game_plays.sort_values(by=['avg_drive_time'],ascending=False)\n",
    "    # label drive numbers\n",
    "    i = ordered.drive_id\n",
    "    ordered['drive_no'] = i.ne(i.shift()).cumsum()\n",
    "    \n",
    "    \n",
    "    new_df = pd.concat([new_df,ordered])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
